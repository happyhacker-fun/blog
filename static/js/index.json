[{"uri":"/post/about-chrome-and-firefox","tags":["chrome","firefox","freedom"],"content":" 自 认为 从 易用性 、 自由度 、 速度 和 资源 占用 方面 ，Firefox（Quantom） 已经 超越 了 Chrome， 但 现在 居然 出现 了 兼容性问题 。 虽然 火狐 优点 很多 ， 但 不 稳定 这 一点 就 足以 让 我 放弃 了 ， 不 知道 是 最近 几次 更新 的 不 稳定 还是 怎样 ， 打开 一会儿 就 假死 ， 在 两台 电脑 上 都 频繁 出现 ， 忍受 不了 ， 还是 用 回 Chrome 了 。 易用性 多 标签 场景 优化 我 的 使用 习惯 是 会 打开 非常 多 的 标签 页 ， 在 使用 Chrome 的 时候 且不说 资源 占用 会 有 多 大 ， 更 大 的 问题 是 Chrome 的 标签 页 过 多 时 只 保留 非常 非常 小 窄 的 tab， 甚至 都 不能 看清 favico， 这样 的 标签 页 留 着 还有 什么 用 呢 ？ 而 Firefox 则 有 一个 相对 更 合适 的 “ 标签 页 最小 宽度 ”， 超过 这个 宽度 之后 会 出现 两个 人性化 的 组件 ： 横向 的 左右 箭头 ， 解决 横向 简单 查找 的 问题 向下 展开 的 标签 页 列表 带 搜索 功能 ， 解决 精确 查找 的 问题 而 Chrome 则 是 一直 挤下去 书签 栏 位置 这个 就 完全 时 个人 习惯 了 ， 个人 一直 不 喜欢 在 书签 栏 放 书签 ， 觉得 影响 了 整体 的 页面 高度 。 但 又 很多 时候 需要 用到 书签 栏 ， 所以 在 Chrome 里 设置 了 只有 在 新 打开 标签 页 时 才 在 显示 书签 栏 。 而 Firefox 的 书签 栏 可以 放在 上下左右 ， 随 你 喜欢 放在 什么 地方 。 我 喜欢 把 它 放在 左侧 ， 需要 用 的 时候 Cmd+B 打开 ， 不 需要 的 时候 关闭 。 主要 是 放在 左侧 不会 像 放在 上方 一样 打开 时 遮挡 大面积 的 网页 。 而且 还有 一个 杀手锏 应用 Firefox Multi-Account Containers， 可以 在 不通 的 标签 页 之间 设置 Cookie 隔离 ， 并 在 标签 页 有 明显 的 提示 ， 本质 上 相当于 手机 的 多 开 应用 ， 同一个 浏览器 登录 多个 不通 的 账号 ， 非常 好 用 。","title":" 简单 说 说 Firefox 和 Chrome","oriTitle":"简单说说Firefox和Chrome","categories":["jabber"],"date":"2020-03-31T02:02:07.000Z"},{"uri":"/post/accelerating-maven-downloading-with-aliyun-mirror","tags":["java","maven","gradle"],"content":" 开发 Java 应用 的 过程 中 通常 需要 依赖 大量 的 第三方 包 ， 而 由于 众所周知 的 原因 ， 我们 访问 这些 资源 的 速度 非常 慢 ， 感谢 阿里 云 给 我们 提供 了 一个 选项 可以 快速访问 这些 资源 。 下面 分别 是 使用 maven 和 gradle 时 的 配置 。maven 将 以下内容 写入 $HOME/.m2/settings.xml 中 。\t -->\t -->\t -->\t -->\t -->\t\t\taliyunmaven\t\t\t*\t\t\t 阿里 云 公共 仓库 \t\t\thttps://maven.aliyun.com/repository/public\t -->\t -->\t\t\tjdk-1.8\t\t\t\ttrue\t\t\t\t1.8\t\t\t\t1.8\t\t\t\t1.8\t\t\t\t1.8\t -->gradle 单个 项目 在 buile.gradle 中 添加 以下 配置 buildscript {    repositories {        maven { url 'https://maven.aliyun.com/repository/google/' }        maven { url 'https://maven.aliyun.com/repository/jcenter/'}    }    dependencies {        classpath 'com.android.tools.build:gradle:2.2.3'        // NOTE: Do not place your application dependencies here; they belong        // in the individual module build.gradle files    }}allprojects {    repositories {        maven { url 'https://maven.aliyun.com/repository/google/' }        maven { url 'https://maven.aliyun.com/repository/jcenter/'}    }} 全局 生效 将 以下内容 写入 $HOME/.gradle/init.gradle 中 。allprojects{    repositories {        def ALIYUNREPOSITORYURL = 'https://maven.aliyun.com/repository/public/'        def ALIYUNJCENTERURL = 'https://maven.aliyun.com/repository/jcenter/'        def ALIYUNGOOGLEURL = 'https://maven.aliyun.com/repository/google/'        def ALIYUNGRADLEPLUGIN_URL = 'https://maven.aliyun.com/repository/gradle-plugin/'        all { ArtifactRepository repo ->            if(repo instanceof MavenArtifactRepository){                def url = repo.url.toString()                if (url.startsWith('https://repo1.maven.org/maven2/')) {                    project.logger.lifecycle \"Repository ${repo.url} replaced by $ALIYUNREPOSITORYURL.\"                    remove repo                }                if (url.startsWith('https://jcenter.bintray.com/')) {                    project.logger.lifecycle \"Repository ${repo.url} replaced by $ALIYUNJCENTERURL.\"                    remove repo                }                if (url.startsWith('https://dl.google.com/dl/android/maven2/')) {                    project.logger.lifecycle \"Repository ${repo.url} replaced by $ALIYUNGOOGLEURL.\"                    remove repo                }                if (url.startsWith('https://plugins.gradle.org/m2/')) {                    project.logger.lifecycle \"Repository ${repo.url} replaced by $ALIYUNGRADLEPLUGIN_URL.\"                    remove repo                }            }        }        maven { url ALIYUNREPOSITORYURL }        maven { url ALIYUNJCENTERURL }        maven { url ALIYUNGOOGLEURL }        maven { url ALIYUNGRADLEPLUGIN_URL }    }}","title":" 使用 阿里 云 加速 依赖 管理 ","oriTitle":"使用阿里云加速依赖管理","categories":["in-action"],"date":"2020-03-28T16:21:43.000Z"},{"uri":"/post/avoid-5s-hangs-before-springboot-starts","tags":["springboot","java","tips"],"content":" 在 macOS 上 开发 Springboot 应用 时 发现 应用 启动 前 总是 等待 5 秒钟 ， 体现 在 应用 启动 的 很 慢 。 具体 的 提示信息 因为 改 完 之后 找 不到 了 ， 就是 一句 提示 ， 说 使用 了 5000 milliseconds， 建议 macOS 用户 修改 /etc/hosts。 但 具体 改 什么 就 没有 提到 。 其实 是因为 应用 启动 时会 查询 域名 ${hostname}， 而 macOS 上 默认 是 没有 配置 这个 域名 的 ， 所以 就要 等到 超时 （5 秒 ） 才能 继续 了 。 知道 了 问题 的 原因 也 就 清楚 如何 解决 了 ， 在 /etc/hosts 中 添加 以下 两行 127.0.0.1 ${hostname}::1 ${hostname} 其中 ${hostname} 要 替换成 你 机器 的 hostname， 要 得到 它 只 需要 执行 hostname 命令 即可 ， 一般 是 一个 以 .local 结尾 的 字符串 。","title":" 避免 Springboot 应用 启动 前 5 秒 的 等待 ","oriTitle":"避免Springboot应用启动前5秒的等待","categories":["springboot"],"date":"2020-05-21T02:41:26.000Z"},{"uri":"/post/centos8-garbled-chars","tags":["centos8","linux"],"content":" 以下 操作 基于 CentOS8,  理论 上 应该 适用 于 其他 版本 的 操作系统 . 现在 终端 默认 的 编码 都 已经 设置 成 了 export LANG=en_US.UTF-8 所以 ,  这里 应该 是 不 需要 改动 的 ,  只 需要 安装 一下 glibc-langpack-* 包 就 可以 了 ,  对于 我们 的 实际 使用 来说 ,  其实 就是 中文包 yum install -y glibc-langpack-zh 即可 .","title":"Centos8 乱码 及 解决 ","oriTitle":"Centos8乱码及解决","categories":["in-action"],"date":"2020-04-03T14:14:19.000Z"},{"uri":"/post/centos8-set-static-network","tags":["centos","linux","运维"],"content":"CentOS 8 又 搞 出 这么 幺 蛾子 ， 不过 这个 接口 还 挺好用 ， 我 喜欢 。AMD 的 黑 苹果 没 办法 安装 Docker， 只好 虚拟机 搞起 了 ， 还要 硬件 性 能够 强 ， 这点 性能 损耗 不算什么 。 装 的 服务器 版本 的 当然 要 ssh 登录 ， 所以 需要 用 桥接 的 网络接口 默认 是 dhcp 的 配置 ， 所以 每次 开机 IP 都 会 变 ， 这样 很 不 方便 ， 于是 要 给 它 一个 固定 的 地址 。 然后 就 发现 CentOS 8 又 搞 了 一个 nmcli， 虽然 又 是 一个 轮子 ， 但 不得不 说 ， 这个 接口 设计 的 还 挺 好 。 预期 配置 下面 是 要 给 虚拟机 的 配置 IP: 192.168.0.108Mask: 255.255.255.0 网关 : 192.168.0.1DNS: 114.114.114.114 命令 不出意外 的话 ， 第一个 网络接口 应该 是 enp0s3， 所以 下面 的 命令 一气呵成 就 可以 配置 成功 了 [root@localhost network-scripts]# nmcli conNAME    UUID                                  TYPE      DEVICEenp0s3  f131fbc3-12a2-4d96-bb3a-623aad5c4fda  ethernet  enp0s3[root@localhost network-scripts]# nmcli con mod enp0s3 ipv4.addresses 192.168.0.108/24 #  配置 IP 和 Mask[root@localhost network-scripts]# nmcli con mod enp0s3 ipv4.gateway 192.168.0.1        #  配置 网关 [root@localhost network-scripts]# nmcli conn mod enp0s3 ipv4.dns \"114.114.114.114\"     #  配置 DNS[root@localhost network-scripts]# nmcli con mod enp0s3 ipv4.method manual              #  取消 dhcp， 使用 静态 地址 [root@localhost network-scripts]# nmcli con up enp0s3                                  #  重启 网络接口 配置 key 登录 然后 就 可以 愉快 的 在 macOS 上 通过 以下 命令 生成 配置 使用 key 登录 虚拟机 了 $ ssh-copy-id frost@192.168.0.108/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"/Users/frost/.ssh/id_rsa.pub\"/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysfrost@192.168.0.108's password:Number of key(s) added:        1Now try logging into the machine, with:   \"ssh 'frost@192.168.0.108'\"and check to make sure that only the key(s) you wanted were added. 配置 快捷 登录 方式 接着 在 macOS 的 $HOME/.ssh/config 中 添加 以下内容 Host *ControlMaster autoControlPath  /tmp/ssh-%r@%hHost devHostName 192.168.0.108User frost 这样 就 可以 通过 ssh dev 这 条 简短 的 命令 登录 了 。 虽然 用 key 做 认证 倒 也 无所谓 ， 不过 通常 还是 配置 上 上述 内容 中 的 前 三行 ， 让 登录 到 同一个 主机 的 ssh 共享 session， 也就是说 在 使用 密码 登录 时 ， 只有 第一次 需要 输入 密码 ， 在 保留 第一个 连接 时 ， 后续 的 连接 都 可以 免 密 。 补充 后来 因为 买 了 块 新 的 硬盘 重新安装 了 macOS， 把 之前 安装 的 CentOS8 虚拟机 拷贝 过来 之后 无法 运行 ， 调整 了 网络 配置 （ 从 BridgeNetwork 调整 到 NAT） 之后 可以 开机 了 但是 无法 联网 ， 不 知道 是 什么 原因 。 由于 之前 是 配置 了 静态 地址 ， 在 NAT 模式 下 想着 还是 配置 成 DHCP 吧 ， 但 发现 nmcli 并 没有 提供 类似 nmcli connection reset 这种 操作 ， 所以 只能 删 了 重新配置 。nmcli connection delete enp0s3nmcli connection add type ethernet con-name home ifname enp3s0nmcli connection up home 即可 联网 了 。 关于 nmcli 还有 很多 细节 的 用法 ， 可以 参考 RedHat 官方 文档 。 总结 每次 配置 ssh 都 想 起来 几年 前 写 的 这个 小 工具 ic， 当时 是 为了 更 简单 的 配置 本地 端口 转发 ， 实现 sftp 上传 文件 ， 后来 公司 不让 用 这种 方式 了 也 就 作罢 了 。 不过 当时 还 研究 了 下 go 语言 和 ssh 的 配置 ， 还有 homebrew 的 打包 方式 ， 虽然 现在 都 不 记得 了 。。。。","title":"CentOS8 配置 静态 地址 ","oriTitle":"CentOS8配置静态地址","categories":["in-action"],"date":"2020-04-17T15:02:34.000Z"},{"uri":"/post/config-hugo-image-path","tags":["vscode","hugo","markdown"],"content":" 不得不 说 Hugo 的 图片 路径 支持 有些 不 友好 ， 网上 也 有 很多 吐 槽 。 简单 说 就是 即便 神 级 的 Markdown 编辑器 Typora 都 无法 适应 Hugo 的 图片 路径 。 由于 Typora 需要 做 日常 的 工作 记录 ， 所以 就 配置 了 一下 VSCode 来 支持 Hugo。Hugo 支持 两种 放置 本地 图片 的 方式 本地 图片 是 相对 网络 图片 而言 ， 如果 你 有 图 床 也 就 无所谓 是否 相对路径 了 content 目录 下      例如 图片 content/a.png， 在 文章 content/post/a.md 中 引用 就 需要 是 ``static 目录 下      例如 图片 static/images/a.png， 在 文章 content/post/a.md 中 引用 就 需要 是 ``>  这里 还是 想 吐 槽 一下 ， 主要 是 第一种 方式 ， 既然 在 文章 中 是 这样 的 写法 ， 其实 就 已经 默认 是从 【 当前 文章 所在 目录 】 向前 查找 了 ， 那 为什么 不能 放在 当前 文章 目录 下 ？ 配置 VSCode 支持 两种 方式 我 还是 比较 倾向 于 内容 和 图片 分离 ， 所以 就 使用 上述 的 第二种 方式 ， 方法 确定 了 其实 配置 方式 差别 不 大 。 依赖 工具 VSCode 扩展 Paste Image ( 作者  mushan） 配置 步骤 配置 图片 文件 存放 路径 Paste Image: Path 中 配置  ${projectRoot}/static/images/ 配置 粘贴 到 文章 中 的 文本 Paste Image: Insert Pattern 中 配置  ${imageSyntaxPrefix}/images/${imageFileName}${imageSyntaxSuffix} 这 一点 我 没有 仔细 看 文档 ， 花费 了 一些 时间 。 效果图 如下 存在 的 问题 当然 这样 配置 还是 解决不了 【 正常 的 Markdown】 编辑器 无法 识别 图片 路径 从而 导致 图片 无法 渲染 的 问题 。 但 好 在 Hugo 有 一个 不错 的 实时 预览 功能 ， 弥补 了 这 一点 。","title":" 配置 Hugo 的 图片 路径 ","oriTitle":"配置Hugo的图片路径","categories":["records"],"date":"2020-03-28T15:44:36.000Z"},{"uri":"/post/cron-issues","tags":["linux","crontab"],"content":" 如果 你 遇到 了 crontab 不能 按 预期 执行 的 问题 ， 可以 参考 本文 的 内容 。crontab 是 运 维 工作 中 经常 需要 做 的 ， 多数 时候 只 需要 执行 crontab -e 来 编辑 即可 ， 当 面对 更 复杂 的 场景 时 ， 这种 方式 就 显得 不够 用 了 。>  关于 crontab 更 多 的 内容 可以 通过 查看 man 8 cron 和 man 5 crontab 来 获取 。crontab 的 分类 一般来说 ，crontab 可以 分为 三种 ， 分别 位于 以下 三个 目录 中 /var/spool/cron//etc/cron.d/etc/cron.{hourly,daily,weekly,monthly} 不同 的 crontab 的 作用 /var/spool/cron/ 这里 就是 存储 我们 最 常用 的 crontab -e 编辑 的 文件 的 地方 了 ， 这里 保存 着 和 执行 这个 命令 的 用户名 相同 的 文件 ， 所以 当 需要 用 某 一个 用户名 执行 cron 时 ， 有 两种 方式 ， 以 用户名 frost 为 例 执行 crontab -evim /var/spool/cron/frost 这 两种 方式 本质 上 是 一样 的 。 值得注意 的 是 ， 它 的 文件 内容 格式 如下 * * * * /path/to/command 先 记住 这个 格式 ， 后面 会 做 对比 。/etc/cron.d 这里 存储 的 是 更 通用 的 配置 ， 每 一行 可以 由 不同 的 用户 执行 ， 没有 了 用户名 做 区分 应该 怎么 做 呢 ？ 这 就是 它 的 文件 内容 和 前面 的 不同 的 地方 了 ， 放在 这个 目录 种 的 cron 文件 想要 被 执行 ， 需要 满足 下面 的 格式 * * * * ${username} /path/to/command 也就是说 ， 在 时间 格式 后面 需要 指定 执行命令 所用 的 用户名 ， 这 是 非常 重要 的 ， 因为 如果 没有 这个 用户名 ， 这 行 命令 就 不会 被 执行 。 个人 认为 ， 这种 方式 其实 更 适合 批量 执行 的 环境 ， 从 中心 节点 下发 crontab 相关 的 配置 时 ， 都 放在 一个 文件 会 导致 该 文件 功能 众多 ， 难以 维护 ， 相反 如果 把 不同 功能 的 配置文件 以 不同 的 名字 下发 到 /etc/cron.d 中 ， 则 更为 清晰 ， 可维护性 更好 。 比如 在 /etc/cron.d 中 可以 有 log, check_db 等 ， 分别 用于 执行 压缩 / 删除 日志 、 检查 数据库 是否 可 访问 等 任务 ， 职责 清晰 明 了 。/etc/cron.{hourly,daily,weekly,monthly} 这里 和 前面 两种 都 不同 ， 因为 它 里面 存放 的 并 不是 任何 类型 的 crontab 的 配置 ， 而是 脚本 ， 从 目录名 也 可以 知道 ， 对应 的 目录 中 的 脚本 会 以 相应 的 时间 间隔 执行 。","title":"crontab 配置 的 一个 常见 错误 ","oriTitle":"crontab配置的一个常见错误","categories":["in-action"],"date":"2020-04-14T14:40:01.000Z"},{"uri":"/post/devops/git-forked-repo-sync-to-origin","tags":["git"],"content":" 有时候 fork 了 一个 项目 ， 过 几天 发现 原 项目 已经 更新 了 ， 这时候 要 保持 和 原始 项目 的 同步 。 比如 原始 项目 是 https://github.com/apache/flink.git， 而 我 fork 的 项目 是 git@github.com:lovelock/flink.git， 这时 在 我 自己 的 本地 仓库 可以 执行 这些 命令 git remote add remote https://github.com/apache/flink.gitgit fetch remote mastergit merge remote/master 上面 两步 也 可以 简化 成  git pull remote mastergit push origin master>  其实 我 觉得 这个 功能 应该 是 让 Github 提供 才 更 合适 ， 干嘛 要 在 本地 操作 呢 ？ 直接 加 个 按钮 ， 同步 上游 代码 不 就行了 。","title":"Fork 的 repo 保持 和 原 repo 同步 ","oriTitle":"Fork的repo保持和原repo同步","categories":["git"],"date":"2021-02-03T04:35:16.000Z"},{"uri":"/post/devops/install-jdk-maven-in-debian","tags":["mvn","java"],"content":" 本文 使用 docker 环境 。 修改 软件 源 sed -i 's/deb.debian.org/mirrors.aliyun.com/g' /etc/apt/sources.listsed -i 's/security.debian.org/mirrors.aliyun.com/g' /etc/apt/sources.list 安装 JDK 和 mavenapt updateapt install openjdk-11-jdk-headless maven vim git curl wget 配置 阿里 云 maven 加速 参考 使用 阿里 云 加速 依赖 管理 创建 一个 Java 应用 使用 maven 创建 一个 应用 骨架 mvn archetype:generate -DgroupId=fun.happyhacker -DartifactId=spring-demo -DarchetypeArtifactId=maven-archetype-quickstart -DarchetypeVersion=1.4 -DinteractiveMode=false 总结 在 一个 全新 的 机器 上 搭建 Java 开发 和 运行 环境 ， 主要 还是 网络 问题 ， 使用 阿里 云 的 加速 服务 能 极大 的 提高 使用 体验 。","title":"Debian Linux 快速 搭建 Java 运行 环境 ","oriTitle":"Debian Linux快速搭建Java运行环境","categories":["in-action"],"date":"2020-08-22T03:57:03.000Z"},{"uri":"/post/devops/install-mysql-with-homebrew","tags":["homebrew","macos","mysql"],"content":" 简单 记录 一下  MySQL  服务 的 安装 方法 。$ brew install mysql mysql-client$ brew services start mysql$ mysqlsecureinstallationSecuring the MySQL server deployment.Connecting to MySQL using a blank password.VALIDATE PASSWORD COMPONENT can be used to test passwordsand improve security. It checks the strength of passwordand allows the users to set only those passwords which aresecure enough. Would you like to setup VALIDATE PASSWORD component?Press y|Y for Yes, any other key for No: yThere are three levels of password validation policy:LOW    Length >= 8MEDIUM Length >= 8, numeric, mixed case, and special charactersSTRONG Length >= 8, numeric, mixed case, special characters and dictionary                  filePlease enter 0 = LOW, 1 = MEDIUM and 2 = STRONG: 0Please set the password for root here.New password:Re-enter new password:Estimated strength of the password: 50Do you wish to continue with the password provided?(Press y|Y for Yes, any other key for No) : yBy default, a MySQL installation has an anonymous user,allowing anyone to log into MySQL without having to havea user account created for them. This is intended only fortesting, and to make the installation go a bit smoother.You should remove them before moving into a productionenvironment.Remove anonymous users? (Press y|Y for Yes, any other key for No) : ySuccess.Normally, root should only be allowed to connect from'localhost'. This ensures that someone cannot guess atthe root password from the network.Disallow root login remotely? (Press y|Y for Yes, any other key for No) : ySuccess.By default, MySQL comes with a database named 'test' thatanyone can access. This is also intended only for testing,and should be removed before moving into a productionenvironment.Remove test database and access to it? (Press y|Y for Yes, any other key for No) : y Dropping test database...Success. Removing privileges on test database...Success.Reloading the privilege tables will ensure that all changesmade so far will take effect immediately.Reload privilege tables now? (Press y|Y for Yes, any other key for No) : ySuccess.All done! 之后 就 可以 通过 mysql -uroot -p 使用 刚刚 设置 的 新密码 登录 服务 了 。 注意 要 保证 /usr/local/var/mysql  目录 是 空 的 ， 不然 会 有 影响 。","title":" 使用 homebrew 安装  MySQL","oriTitle":"使用homebrew安装 MySQL","categories":["in-action"],"date":"2021-01-21T03:04:09.000Z"},{"uri":"/post/devops/nginx-tomcat-hot-deployment","tags":["devops","gitlab","jenkins","java"],"content":" 最终 还是 得 解决 Springboot 应用 热 部署 的 问题 。 背景 基于 Springboot 应用 以 war 包 的 形式 运行 在 tomcat 容器 中 ， 当 更新 war 包 时会 有 一段时间 服务 返回 404， 这 对于 线 上 服务 是 不可 接受 的 。4 层 的 负载 均衡 可以 自动 将 80 端口 关闭 的 节点 下线 ， 但 由于 内 网 服务器 位于 堡垒 机 后方 ， 根据 公司 规定 不能 自行 配置 SSH 服务 ， 所以 无法 执行 远程 脚本 。 所以 只能 通过 别的 方式 实现 。 实验 素材 nginx   作为 web server 和 7 层 负载 均衡 tomcat * 2  作为 应用 后 端 gitlab-ce  代码 版本控制 jenkins   发布 平台 基本原理 基本 的 原理 就是 让 Nginx 后方 有 2 个 Tomcat 容器 ， 其中 1 个 是 active，1 个 是 backup， 正常 情况 下 不会 访问 到 backup 的 容器 ， 但 可以 通过 额外 的 手段 保证 backup 的 容器 是 可以 提供 服务 的 ， 在 发布 前 先 更新 所有 的 backup 节点 ， 验证 没 问题 之后 更新 active 的 容器 ， 来 保证 服务 不会 中断 。 实际操作 创建 springboot 项目 参考 Springboot 使用 内置 和 独立 tomcat 以及 其他 思考 。 编写 同一个 接口 的 不同 版本 // tag v1@RestControllerpublic class HelloController {    @GetMapping(\"/hello\")    public String hello() {        return \"V1\";    }}// tag v2@RestControllerpublic class HelloController {    @GetMapping(\"/hello\")    public String hello() {        return \"V2\";    }} 打包 mvn clean package -Dmaven.test.skip=true 创建 两个 tomcat 容器 docker run -itd --name tomcat-active -v /tmp/tomcat/active:/usr/local/tomcat/webapps -p 32771:8080 tomcatdocker run -itd --name tomcat-backup -v /tmp/tomcat/backup:/usr/local/tomcat/webapps -p 32772:8080 tomcat 将 war 包 拷贝到 容器 中 可能 是 docker toolbox 的 问题 ， 无法 挂载 目录 ， 所以 只好 把 war 包 手动 拷贝 进去 。docker cp ~/workspace/spring-demo/target/spring-demo-0.0.1-SNAPSHOT.war tomcat-active:/usr/local/tomcat/webapps/docker cp ~/workspace/spring-demo/target/spring-demo-0.0.1-SNAPSHOT.war tomcat-backup:/usr/local/tomcat/webapps/ 访问 两个 容器 中 的 服务 稍等片刻 两个 容器 中 的 服务 会 自动 部署 ， 就 可以 分别 通过 相应 的 端口 访问 了 ， 简单 压 测 一下 QPS 可以 达到 2000+ 且 没有 报错 。$ wrk -c 20 -d 10 -t 4 http://192.168.99.100:32771/spring-demo-0.0.1-SNAPSHOT/helloRunning 10s test @ http://192.168.99.100:32771/spring-demo-0.0.1-SNAPSHOT/hello  4 threads and 20 connections  Thread Stats   Avg      Stdev     Max   +/- Stdev    Latency    10.20ms    8.70ms 122.66ms   81.20%    Req/Sec   554.18    167.66     1.04k    63.25%  22088 requests in 10.02s, 2.43MB readRequests/sec:   2203.76Transfer/sec:    247.89KB$ wrk -c 20 -d 10 -t 4 http://192.168.99.100:32772/spring-demo-0.0.1-SNAPSHOT/helloRunning 10s test @ http://192.168.99.100:32772/spring-demo-0.0.1-SNAPSHOT/hello  4 threads and 20 connections  Thread Stats   Avg      Stdev     Max   +/- Stdev    Latency    11.30ms   14.24ms 186.52ms   92.95%    Req/Sec   557.54    207.91     1.24k    67.17%  22025 requests in 10.03s, 2.42MB readRequests/sec:   2196.36Transfer/sec:    247.05KB 配置 Nginxupstream ha {\tserver 192.168.99.100:32771;\tserver 192.168.99.100:32772 backup;}server {\tlisten       80;\tservername  ;\tlocation / {\t\tproxynextupstream http502 http504 http404 error timeout invalidheader;\t\tproxy_pass   http://ha/spring-demo-0.0.1-SNAPSHOT/;\t}} 注意 ： 默认 情况 下 只 会 转发 GET/HEAD/PUT/DELETE/OPTIONS 这种 幂 等 的 请求 ， 而 不会 转发 POST 请求 ， 如果 需要 对 POST 请求 也 做 转发 ， 就 需要 加上 non_idempotent 配置 ， 整体 配置 如下 upstream ha {\tserver 192.168.99.100:32771;\tserver 192.168.99.100:32772 backup;}server {\tlisten       80;\tservername  ;\tlocation / {\t\tproxynextupstream http502 http504 http404 error timeout invalidheader non_idempotent;\t\tproxy_pass   http://ha/spring-demo-0.0.1-SNAPSHOT/;\t}} 注意 proxynextupstream http502 http504 http404 error timeout invalidheader; 这 行 ， 这里 就是 表示 把 访问 当前 的 upstream 返回 了 这些 状态 码 的 请求 转发 到 upstream 中 的 下 一台 机器 ， 在 我们 现在 的 应用 场景 下 ， 当 war 包 发布 时 ， 正在 更新 war 包 的 tomcat 会 返回 404， 也 就是 对应 http_404， 如果 不 配置 这 行 ， 是 不会 做 转发 的 。 但 这样 简单 的 配置 还 会 有 一个 问题 ， 那 就是 Nginx 不会 把 出 问题 的 后 端 从 upstream 中 摘除 ， 也就是说 请求 还 会 访问 到 这个 正在 更新 中 的 realserver， 只是 Nginx 会 再 把 请求 转发 到 下 一台 好 的 realserver 上 ， 这样 会 增加 一些 耗时 。 目前 有 三种 方式 可以 实现 对 Nginx 负载 均衡 的 后 端 节点 服务器进行 健康检查 ， 具体 参考 Nginx 负载 均衡 通过 Nginx 压 测 基本 测试 两个 tomcat 节点均 正常 的 情况 下压 测 $ wrk -c 20 -d 10 -t 4 http://192.168.99.100:32778/helloRunning 10s test @ http://192.168.99.100:32778/hello  4 threads and 20 connections  Thread Stats   Avg      Stdev     Max   +/- Stdev    Latency    57.36ms   32.06ms 335.36ms   71.29%    Req/Sec    89.29     48.20   390.00     85.25%  3577 requests in 10.05s, 562.30KB readRequests/sec:    355.77Transfer/sec:     55.93KB 和 上面 没有 经过 Nginx 的 压 测 相比 ， 最 明显 的 变化 就是 QPS 下降 了 84%， 平均 响应 时间 增加 了 5 倍 ， 猜测 可能 是因为 Nginx 使用 的 默认 配置 中 worker_processes 1; 的 问题 。 在 开始 压 测 后 立即 删除 tomcat-active 容器 中 的 war 包 和 目录 ， 结果 如下 $ wrk -c 20 -d 10 -t 4 http://192.168.99.100:32778/helloRunning 10s test @ http://192.168.99.100:32778/hello  4 threads and 20 connections  Thread Stats   Avg      Stdev     Max   +/- Stdev    Latency    57.29ms   28.69ms 181.88ms   67.38%    Req/Sec    87.93     39.51   240.00     75.25%  3521 requests in 10.05s, 553.50KB readRequests/sec:    350.22Transfer/sec:     55.05KB 同样 没有 非 200 的 响应 ， 而且 整体 和 正常 情况 相当 。 只有 backup 节点 工作 的 情况 下压 测 $ wrk -c 20 -d 10 -t 4 http://192.168.99.100:32778/helloRunning 10s test @ http://192.168.99.100:32778/hello  4 threads and 20 connections  Thread Stats   Avg      Stdev     Max   +/- Stdev    Latency    72.12ms   35.99ms 240.89ms   68.34%    Req/Sec    70.04     31.84   180.00     76.50%  2810 requests in 10.05s, 441.71KB readRequests/sec:    279.48Transfer/sec:     43.93KB 可以 看到 ， 响应 时间 有 明显 的 增加 ，QPS 也 有 明显 的 下降 ， 也 验证 了 上面 说 的 响应 是 404 的 请求 会 被 转发 到 正常 工作 的 节点 ， 但 有 问题 的 节点 不会 被 摘除 导致 的 响应 时间 变 长 的 问题 。 进一步 测试 为了 消除 上面 测试 中 可能 存在 war 包 删除 后 对 服务 的 影响 还 没有 生效 ， 压 测 就 已经 结束 的 可能 ， 将 压 测 时间 调 长 ， 增加 至 60s。 两个 节点 都 正常 的 情况 $ wrk -c 20 -d 60 -t 4 http://192.168.99.100:32778/helloRunning 1m test @ http://192.168.99.100:32778/hello  4 threads and 20 connections  Thread Stats   Avg      Stdev     Max   +/- Stdev    Latency    55.53ms   28.10ms 306.58ms   70.07%    Req/Sec    91.52     39.35   300.00     69.23%  21906 requests in 1.00m, 3.36MB readRequests/sec:    364.66Transfer/sec:     57.32KB 整体 情况 和 上面 10s 的 测试 相同 。 查看 日志 发现 backup 节点 没有 接收 到 任何 请求 。 为了 验证 是否是 worker_processes 配置 导致 的 ， 把 这个 值 改成 4 之后 重新 测试 ， 结果 如下 $ wrk -c 20 -d 60 -t 4 http://192.168.99.100:32778/helloRunning 1m test @ http://192.168.99.100:32778/hello  4 threads and 20 connections  Thread Stats   Avg      Stdev     Max   +/- Stdev    Latency    41.55ms   24.92ms 227.15ms   72.21%    Req/Sec   125.06     46.88   373.00     71.76%  29922 requests in 1.00m, 4.59MB readRequests/sec:    498.11Transfer/sec:     78.29KB 可以 看到 ， 有 了 将近 20% 的 提升 ， 但 还是 不 太 符合 预期 。 开始 测试 后 立即 更新 active 节点 的 war 包 $ wrk -c 20 -d 60 -t 4 http://192.168.99.100:32778/helloRunning 1m test @ http://192.168.99.100:32778/hello  4 threads and 20 connections  Thread Stats   Avg      Stdev     Max   +/- Stdev    Latency    54.40ms   33.76ms 329.73ms   70.53%    Req/Sec    95.85     56.28   420.00     81.60%  22914 requests in 1.00m, 3.52MB readRequests/sec:    381.42Transfer/sec:     59.95KB 没有 明显 变化 ， 测试 开始 后 有 一段时间 backup 节点 收到 请求 ， 后面 请求 又 全部 指向 了 active 节点 。 可能 是因为 服务 太 简单 ， 重新 加载 的 太 快 ， 只有 很 少量 （5750） 的 请求 转发 到 了 backup 节点 ， 所以 对 整体 结果 影响 不 大 。 开始 测试 后 立即 删除 active 节点 的 war 包 $ wrk -c 20 -d 60 -t 4 http://192.168.99.100:32778/helloRunning 1m test @ http://192.168.99.100:32778/hello  4 threads and 20 connections  Thread Stats   Avg      Stdev     Max   +/- Stdev    Latency    72.11ms   34.33ms 346.24ms   69.54%    Req/Sec    70.16     29.78   191.00     67.23%  16813 requests in 1.00m, 2.58MB readRequests/sec:    279.84Transfer/sec:     43.99KB 删除 节点 后 ， 所有 的 请求 都 会 先 请求 active， 然后 被 Nginx 转发 至 backup， 所以 吞吐量 有 明显 下降 ， 延迟 也 有 明显 的 提升 。 效果 测试 直接 访问 active$ wrk -c 20 -d 60 -t 4 http://10.75.1.42:28080/web-0.0.1-SNAPSHOT/helloRunning 1m test @ http://10.75.1.42:28080/web-0.0.1-SNAPSHOT/hello  4 threads and 20 connections  Thread Stats   Avg      Stdev     Max   +/- Stdev    Latency     5.56ms   25.16ms 203.83ms   95.82%    Req/Sec     7.54k     0.91k    8.31k    84.44%  1803421 requests in 1.00m, 217.03MB readRequests/sec:  30006.18Transfer/sec:      3.61MB 服务器 的 性能 果然 还是 比 本地 强 太 多 。 在 进行 性能 压 测 期间 发布 新 版本 $ wrk -c 20 -d 60 -t 4 http://10.75.1.42:28080/web-0.0.1-SNAPSHOT/helloRunning 1m test @ http://10.75.1.42:28080/web-0.0.1-SNAPSHOT/hello  4 threads and 20 connections  Thread Stats   Avg      Stdev     Max   +/- Stdev    Latency     4.47ms   22.31ms 401.95ms   96.67%    Req/Sec     7.58k     0.88k    8.26k    87.12%  1811240 requests in 1.00m, 285.84MB read  Non-2xx or 3xx responses: 72742Requests/sec:  30181.93Transfer/sec:      4.76MB 发布 新 版本 导致 4% 的 请求 失败 。 通过 Nginx 访问 服务 $ wrk -c 20 -d 60 -t 4 http://10.75.1.42:28010/web/helloRunning 1m test @ http://10.75.1.42:28010/web/hello  4 threads and 20 connections  Thread Stats   Avg      Stdev     Max   +/- Stdev    Latency     2.94ms   16.21ms 248.18ms   98.01%    Req/Sec     6.02k   551.52     6.92k    83.38%  1437098 requests in 1.00m, 260.33MB readRequests/sec:  23948.20Transfer/sec:      4.34MB 虽然 服务器 配置 的 worker_processes auto， 实际上 开 了 40 个 进程 ， 但 仍然 达 不到 直接 访问 Java 服务 的 吞吐量 。 通过 Nginx 压 测 期间 发布 新 版本 $ wrk -c 20 -d 60 -t 4 http://10.75.1.42:28010/web/helloRunning 1m test @ http://10.75.1.42:28010/web/hello  4 threads and 20 connections  Thread Stats   Avg      Stdev     Max   +/- Stdev    Latency     4.09ms   20.50ms 402.11ms   97.12%    Req/Sec     5.89k   733.62     6.86k    84.85%  1404463 requests in 1.00m, 253.67MB readRequests/sec:  23401.54Transfer/sec:      4.23MB 可以 看到 ， 延迟 明显 变 大 了 ， 但 总体 的 QPS 没有 明显 下降 ， 还是 因为 存在 一些 转发 。 思考 原来 是 一台 机器 上 运行 一个 tomcat 容器 ， 现在 要 运行 两个 ， 那么 会 对 机器 的 负载 造成 多 大 的 影响 呢 ？ 可以 通过 visualvm 连接 上 远程 tomcat 来 观察 对 内存 和 CPU 的 占用 可以 看到 正常 情况 下 ，backup 容器 对 服务器 的 负载 基本 可以 忽略不计 。 即便 是 在 发布 期间 ，backup 容器 也 只是 在 active 容器 重新 载入 期间 承担 职责 ， 之后 马上 就 恢复 了 。 新 版本 在线 上 正式 运行 之后 为 保证 下 一次 发布 新 版本 时 backup 版本 是 最新 的 ， 需要 再 发布 一下 backup 版本 ， 当然 这时 流量 都 在 active 节点 上 ， 对 backup 节点 的 发布 更新 操作 不会 对 负载 有 什么 影响 。 总结 可以 通过 Nginx 的 backup 机制 可以 保证 服务 不 中断 的 情况 下 发布 新 版本 。 总体 的 发布 流程 如下 ： 发布 新 版本 到 active 容器 确认 发布 的 新 版本 稳定 后 发布 新 版本 到 backup 容器 优势 任意 一台 机器 上 在 任意 时刻 都 保证 有 一个 tomcat 容器 是 可用 的 ， 保证 服务 不 中断 从 直观 上 的 分 机器 上线 改为 直接 全 量 上线 ， 并且 保证 如果 上线 的 新 版本 有 问题 时 也 不会 影响 线 上 服务 劣势 需要 上线 两次 需要 在 tomcat 容器 所在 的 机器 上 安装 Nginx 和 作为 backup 的 tomcat 的 容器 backup 容器 在 “ 待机 ” 时 的 消耗 ","title":"Nginx 和 Tomcat 配合 实现 Java Web 服务 热 部署 ","oriTitle":"Nginx和Tomcat配合实现Java Web服务热部署","categories":["in-action","devops"],"date":"2020-08-22T02:56:59.000Z"},{"uri":"/post/devops/remote-monitor-jvm-with-visualvm","tags":["jvm","visualvm","java"],"content":" 服务器端 没有 可视化 界面 ， 监控 这种 事情 看 CLI 界面 还是 差点 意思 。 方法 需要 看 Tomcat 的 监控 ， 需要 远程 连接 之 ， 只 需要 在 tomcat 启动 前 在 $TOMCAT_HOME/bin 目录 下 添加 setenv.sh 文件 ， 加上 以下内容 即可 JAVA_OPTS=\"-Dcom.sun.management.jmxremote=true \\                  -Dcom.sun.management.jmxremote.port=9090 \\                  -Dcom.sun.management.jmxremote.ssl=false \\                  -Dcom.sun.management.jmxremote.authenticate=false \\                  -Djava.rmi.server.hostname=current ip\" 这样 就 可以 在 本地 看到 这种 监控 图 了 扩展 既然 Tomcat 是 这么 做 ， 其实 我们 自己 的 应用 当然 也 可以 ， 只 需要 在 启动 的 时候 加上 这些 参数 即可 。➜  tomcat vim Hello.java➜  tomcat javac Hello.java➜  tomcat java -Dcom.sun.management.jmxremote=true \\                  -Dcom.sun.management.jmxremote.port=9090 \\                  -Dcom.sun.management.jmxremote.ssl=false \\                  -Dcom.sun.management.jmxremote.authenticate=false \\                  -Djava.rmi.server.hostname=10.75.1.42 Hello 果然 是 可以 的 。 总结 其实 很多 开源 的 Java 软件 ， 都 有 类似 这种 做法 ， 比如 Apache Flink 用 $FLINK_HOME/bin/config.sh 等 ， 通过 这种 方式 可以 很 容易 的 设置 一些 环境变量 。","title":" 使用 VisualVM 监控 远程 JVM 进程 ","oriTitle":"使用VisualVM监控远程JVM进程","categories":["in-action","devops"],"date":"2020-08-22T09:25:53.000Z"},{"uri":"/post/disable-zoom-in-and-out-in-firefox-with-mouse","tags":["firefox"],"content":" 火狐 浏览器 有 个 很 奇怪 的 设定 ， 在 Windows 下 按住 Ctrl（macOS 下 按住 Cmd） 加上 鼠标 滚轮 会 缩放 网页 。 有些 人 可能 觉得 是 个 很 有用 的 功能 ， 但 我 觉得 这个 功能 让 我 很 烦恼 ， 有时候 有 不 自觉 的 放在 Cmd 上 ， 鼠标 滚动 一下 网页 就 变成 了 200%， 原来 是 可以 通过 配置 修改 关闭 这项 功能 的 在 地址栏 输入 about:config 搜索 mousewheel.with_meta.action， 把 3 改成 0 如果 是 windows， 则 搜索 mousewheel.with_control.action， 同样 把 3 改成 0 改 完 立即 生效 ， 不 需要 重启 浏览器 ","title":" 关闭 Firefox 浏览器 中 使用 鼠标 缩放 网页 的 功能 ","oriTitle":"关闭Firefox浏览器中使用鼠标缩放网页的功能","categories":["in-action"],"date":"2020-05-15T16:49:00.000Z"},{"uri":"/post/docker-in-ryzentosh","tags":["docker"],"content":" 本来 选择 AMD 的 黑 苹果 之前 就 已经 做好 了 无法 使用 docker 的 准备 了 ， 没想到 那天 偶然 发现 说 docker-toolbox 是 可以 用 的 。 国内 下载 docker 官方 的 东西 实在 是 太慢 了 ， 还是 从 阿里 云 下载 的 。 这里 多 说 一句 ， 阿里 云 在 开源 软件 镜像 架设 这方面 的 贡献 远远 超过 国内 其他 公司 了 （BT？ 不 存在 的 ） 下载 Docker Toolbox 访问 阿里 云 的 Docker Toolbox 下载 地址 ， 下载 最新 的 安装包 。 这里 同步 是 有点 问题 的 ， 官方 已经 有 19.xx 版本 了 ， 但 阿里 云 的 镜像 这里 还是 18.03， 不过 无所谓 了 ， 快 才 是 王道 。 安装 安装 过程 就 不 说 了 ， 既然 你 找到 这里 了 说明 你 肯定 会 安装 软件 了 。 配置 注意 红色 部分 的 提示 ， 乍一看 是 需要 在 BIOS 里 打开 AMD-v 技术 （ 对 标 Intel 的 VT-x）， 一般 是 叫 SVM， 默认 通常 是 不 开启 的 。 但 我 这里 已经 开启 过 了 ， 还 报 这个 错 只能 说 是 检测 脚本 并 没有 适配 【AMD 黑 苹果 】 这个 可能性 。 所以 直接 忽略 这个 提示 。 然后 需要 创建 一个 默认 的 虚拟机 ， 用 virtualbox 的 驱动 即可 。 这里 要 注意 ， 由于 众所周知 的 原因 ， 我们 下载 docker 的 官方 镜像 非常 慢 ， 所以 要 配置 一下 国内 的 代理 ， 建议 使用 阿里 云 。 注册 登陆 之后 访问 这个 镜像 加速器 ， 按 文档 说明 执行 你 的 命令 即可 >  注意 ： 执行 docker-machine create 命令 的 时候 还是 会 检查 上面 提到 的 有 问题 的 虚拟化 技术 检查 ， 所以 需要 加上 一个 --virtualbox-no-vtx-check 选项 docker-machine create default --engine-registry-mirror=https://yourcode.mirror.aliyuncs.com -d virtualbox --virtualbox-no-vtx-check --virtualbox-memory \"8096\" --virtualbox-cpu-count \"6\"> 2020 年 11 月 添加 ： 后来 使用 过程 中 发现 内存 会 不够 用 ， 因为 默认 是 1G 内存 和 1 个 CPU 核心 ， 这 明显 是 不能 满足 正常 的 使用 需求 的 ， 所以 就 需要 加 一些 资源 了 。 打开 Kitematic 开始 体验 docker 哇 ！ 原来 docker 还 能 这么 用 ？！ 当 你 走 到 这 一步 了 ， 你 一定 知道 我 为什么 会 感叹 。","title":"AMD 黑 苹果 上 的 docker","oriTitle":"AMD黑苹果上的docker","categories":["in-action"],"date":"2020-07-25T15:35:01.000Z"},{"uri":"/post/error-running-junit","tags":["junit","java"],"content":"Java 报错 真是 多 ， 一不小心 单元测试 也 报错 。 代码 是 这样 的 @SpringBootTest@Slf4j@RunWith(SpringJUnit4ClassRunner.class)public class MyTestClass {    @Test    void testShowBatch() {    }} 执行 mvn test -Dtest=MyTestClass#testShowBatch 报错 [INFO] Running MyTestClass[ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.001 s <<< FAILURE! - in MyTestClass[ERROR] initializationError  Time elapsed: 0.001 s  <<< ERROR!org.junit.runners.model.InvalidTestClassError:Invalid test class 'MyTestClass':  No runnable methods... 事实上 这个 并 不是 问题 的 关键 ， 当时 这个 问题 的 原因 在于 本地 代码 上 传到 远 端的 目录 和 我 执行 的 目录 不 在 一个 地方 ， 所以 报错 了 。。。 但 总体 上 在 执行 单元测试 时 的 用法 和 下文 说 的 差不多 ，junit5 不 需要 @RunWith 注解 了 。 明显 是 有 runnable methods 的 啊 ， 原来 是因为 @RunWith(SpringJUnit4ClassRunner.class) 这个 注解 ， 它 是 junit4 的 用法 ， 加上 它 ， 就 会 查找 带有 @org.junit.Test 注解 的 方法 ， 也 就是 所谓 的 runnable methods。 而 我 这里 的 看起来 是 @Test 的 方法 ， 其实 是 @org.junit.jupiter.api.Test， 是 junit5 的 runnable method， 二者 不能 兼容 ， 所以 就 出现 了 上面 的 错误 。 总结 在 测试 Springboot 应用 时 ， 如果 你 需要 Springboot 加载 才能 执行 单元测试 代码 ， 可以 选择 使用 junit4 或者 junit5。 当 使用 junit4    需要 的 类 注解 是         @SpringBootTest    @Slf4j    @RunWith(SpringJUnit4ClassRunner.class)     需要 的 方法 注解 是         @org.junit.Test 当 使用 junit5    需要 的 类 注解 是         @SpringBootTest    @Slf4j     需要 的 方法 注解 是         @org.junit.jupiter.api.Test","title":" 执行 单元测试 时报 错 分析 及 解决 ","oriTitle":"执行单元测试时报错分析及解决","categories":["in-action"],"date":"2020-04-07T16:30:39.000Z"},{"uri":"/post/flink/flink-0x02","tags":["flink","hadoop"],"content":" 本章 重点 解析 一下 flink 的 配置文件 conf/flink-conf.yaml。>  正常 情况 下 一个 TM 挂掉 不会 影响 整个 系统 的 运行 ， 顶多 是 原来 这个 任务 有 8 个 TM， 每个 TM 中 有 2 个 slots， 这样 就 一共 有 16 个 slots， 如果 挂掉 一个 TM 就 只 剩下 14 个 slots 可用 ， 但 整个 系统 还 可以 运行 。 这时 JM 会 尝试 另外 申请 一个 包含 两个 slots 的 TM 来 替代 已经 挂掉 的 那个 TM 来 工作 ， 但 如果 系统资源 不足 ， 申请 不到 ， 则 就 会 一直 少 一个 TM。>  相反 ，JM 如果 挂 了 整个 任务 就 会 挂掉 ， 如果 开启 HA 模式 的 时候 ，JM 会 把 任务 的 快照 发送到 ZK， 这样 如果 JM 挂 了 ，ZK 会 协助 重新启动 一个 JM， 并 将 ZK 内部 存储 的 快照 用于 恢复 任务 执行 。1.  通用 配置 只有 单机 运行 时 才 有用 ， 正常 线 上 这个 配置 是 没有 用 的 ， 也 不 需要 配置 jobmanager.rpc.address: localhostjobmanager.rpc.port: 61232. JobManager 配置 JobManager 的 堆 内存大小 ， 正常 默认 配置 就 够 了 ， 但 如果 任务 的 state 比较 大 ， 可能 就 需要 调整 这个 大小 了 jobmanager.heap.size: 1024m3. TaskManager 配置 整个 TaskManager 可用 的 所有 内存大小 ， 其中 包括 JVM 的 metaspace 和 其他 开销 taskmanager.memory.process.size: 1728mtaskmanager.memory.jvm-metaspace.size: 512m 一个 TaskManager 中 的 TaskSlots 的 个数 。 假设 一个 集群 有 8 台 机器 ， 其中 7 台 是 NodeManager， 每 台 NodeManager 有 8 个 核心 ， 也 就是 每 台 NodeManager 可以 最 多 提供 8 个 Slots， 一共 可以 提供 56 个 TaskSlots。 如果 一个 任务 配置 的 所有 并行度 加 起来 是 50， 按照 默认 配置 ， 就 需要 启动 50 个 TaskManager， 本质 上 每个 TaskManager 都 是 一个 JVM 进程 ， 假设 JVM 的 metaspace 设置 为 256M， 那 应用 启动 的 时候 就 需要 至少  256MB50  的 内存空间 ， 并且 TaskManager 太 多 也 会 增加 它们 之间 通信 的 开销 。 相应 的 ， 每个 TaskManager 都 是 隔离 的 ， 一个 挂 了 对 另外 一个 影响 也 是 最小 的 。 但 如果 把 这个 值 改成 8， 就 只 需要 启动 7 个 TaskManager， 也 就是 7 个 JVM 进程 ， 任务 启动 时 需要 的 metaspace 就是  256MB7  的 内存空间 。（ 注意 7 个 TaskManager 会 有 56 个 TaskSlots， 所以 就 会 有 6 个 空闲 的 ）， 这样 节省 了 内存空间 ， 但 TaskSlots 之间 的 耦合度 增加 了 ， 如果 一个 TaskManager 挂 了 ， 会 导致 8 个 TaskSlots 都 挂 了 。 所以 需要 在 实际 应用 中 对 效率 和 资源 隔离 作出 取舍 。taskmanager.numberOfTaskSlots: 14. CheckPoint 配置 需要 保留 的 CheckPoint 的 数量 ， 默认 保留 最新 的 一个 CheckPoint， 这样 故障 恢复 时 就 只 恢复 最新 的 。 有些 情况 下 发现 数据处理 出错 ， 可能 需要 恢复 几个 小时 前 的 数据 ， 就 需要 保留 多个 CheckPoint 了 。 从 指定 的 CheckPoint 启动 任务 可以 用 ：bin/flink run -s hdfs://namenode01.td.com/flink-1.11.1/flink-checkpoints/582e17d2cc343e6c56255d111bae0191/chk-860/_metadata flink-app-jobs.jar 后面 三个 是 state 保存 的 路径 ， 默认 是 被 注释 掉 的 ， 前期 使用 HDFS(filesystem) 即可 ， 后面 如果 遇到 state 太 大 ， 无法 快速 完成 checkpoint， 可以 尝试 使用 RocksDB 替换 HDFS。 开启 了 savepoint 之后 ， 在 cancel 任务 时会 将 savepoint 写入 指定 的 地址 ， 在 启动 时 指定 该 地址 即可 。 通常 用于 版本升级 过程 。state.checkpoints.num-retained: 20state.backend: filesystemstate.checkpoints.dir: hdfs:///flink-checkpointsstate.savepoints.dir: hdfs:///flink-savepoints5.  重启 策略 这个 参数 就 很 表意 了 ， 按 固定 时间 间隔 尝试 重启 ， 最 多 尝试 10 次 。 可以 根据 需求 调整 配置 。restart-strategy: fixed-delayrestart-strategy.fixed-delay.attempts: 10restart-strategy.fixed-delay.delay: 10s6.  超时 配置 之前 是 没有 想 写 这个 配置 的 ， 但 在 实际 运行 过程 中 确实 发现 了 这个 问题 。 其实 在 前面 也 说 过 了 ， 就是 因为 每个 task 一个 slot， 然后 开 了 100 个 taskmanager， 这样 就 有 100 个 taskmanager 线程 都 需要 和 jobmanager 交互 ， 每个 都 不 超时 的 概率 就 很 低 了 。 所以 改 了 numberOfTaskSlots 来 减少 taskmanager 线程 的 同时 也 调整 了 以下 这个 超时 时间 。akka.ask.timeout: 100 sweb.timeout: 1000007.  高 可用 配置 敬请期待 ","title":"Flink 配置文件 详解 ","oriTitle":"Flink配置文件详解","categories":["bigdata"],"date":"2020-07-27T03:25:19.000Z"},{"uri":"/post/flink/flink-0x03","tags":["flink","hadoop","yarn"],"content":" 通常 Flink 会 运行 在 yarn 上 ， 需要 在 Flink 中 配置 一下 Hadoop 的 安装 路径 。 修改 flink/bin/config.sh， 在 第一行 非 注释 的 内容 前 添加 以下内容 export HADOOPHOME=${HADOOPHOME:-/usr/hdp/3.1.0.0-78/hadoop}export HADOOPCONFDIR=${HADOOPCONFDIR:-/usr/hdp/3.1.0.0-78/hadoop/conf}export HADOOP_CLASSPATH=/usr/hdp/current/hadoop-client/bin/hadoop classpathexport JAVAHOME=/usr/java/jdk1.8.0231-amd64 这里 使用 的 是 cloudera 提供 的 yarn 安装 工具 ， 后面 有 时间 写 一个 教程 介绍 这个 过程 。","title":"Flink 环境 初始化 ","oriTitle":"Flink环境初始化","categories":["bigdata"],"date":"2020-08-06T07:07:48.000Z"},{"uri":"/post/flink/unaligned-checkpoints","tags":["flink"],"content":" 终于 看到 Flink 承认 自己 在 背 压 高 的 时候 Checkpoint 慢 的 事实 了 。 甚至 详细 介绍 的 文章 都 才 只 写 了 第一篇 。 关于 Unaligned Checkpoint（ 非 对齐 检查点 ） 的 详细 介绍 官 网上 已经 有 很多 了 ， 前段时间 刚 发布 了 系列 文章 的 第一篇 [From Aligned to Unaligned Checkpoints - Part 1: Checkpoints, Alignment, and Backpressure](https://flink.apache.org/2020/10/15/from-aligned-to-unaligned-checkpoints-part-1.html)。 其中 明确 提到 了 以下内容 > Despite all these great properties, Flink’s checkpointing method has an Achilles Heel: the speed of a completed checkpoint is determined by the speed at which data flows through the application. When the application backpressures, the processing of checkpoints is backpressured as well (Appendix 1 recaps what is backpressure and why it can be a good thing). In such cases, checkpoints may take longer to complete or even time out completely. 之前 一直 觉得 Flink 在 流式 计算 领域 是 神 一样 的 存在 ， 没有 缺点 。 但 实际 用 了 之后 才 发现 就 这 一点 就 够 喝 一 壶 了 。 所谓 流式 数据 其实 就是 （ 没有 边界 的 ） 消息 队列 了 ， 那么 消息 队列 的 一大 用途 就是 削 峰 填 谷 ， 好 了 ， 这 里面 的 消 峰 就是 在 流量 高峰 的 时候 能 以 其 极 高 的 性能 扛 住 压力 ， 保证 在 数据 压力降 下来 之前 数据 的 不 丢失 。 没错 ，Kafka 在 这里 扛 住 了 ， 但 Flink 掉 链子 了 。 所谓 背 压 （ 有 的 叫 反 压 ， 原文 Back Pressure）， 对于 数据源 （DataSource） 来说 ， 其实 就是 下游 的 消费 能力 不足 ， 导致 上游 数据 无法 完成 整个 流程 （ 从 数据源 流入 数据 汇 DataSink）， 具体 到 Kafka 的 这个 场景 来说 就是 业务 处理 的 流程 慢 。 正常 来说 ， 我们 是 希望 当 数据 流量 大 的 时候 系统 能 加快 处理 ， 比如 设计 处理 能力 是 1000tps， 实际 平时 只有 300tps， 那么 当 流量 上来 时 我们 是 期望 它 能 按 设计 处理 能力 消费 数据 ， 让 数据 高峰 尽快 消散 的 ， 但 实际 情况 是 当 数据量 增大 时 ， 处理 能力 从 300tps 变成 了 2tps。 是 的 ， 堆积 越 多 处理 越慢 。 反过来 处理 越慢 ， 堆积 越 快 。 陷入 了 死循环 。 上面 文章 里 也 说 了 ， 导致 这个 结果 的 原因 并 不是 真的 是 业务 代码 处理 的 慢 ， 确确实实 就是 在 背 压 出现 时 ，Checkpoint 变慢 了 。 所以 在 新 版本 推出 了 非 对齐 检查点 模式 。 这里 有 一个 Inflight-data 的 概念 ， 我 理解 就是 新 的 检查点 方式 是 把 每个 TaskManager 中 处理 的 数据 都 快照 下来 了 ， 也 不用 管 水位 线 什么 的 ， 直接 搞起 ， 完成 一个 删除 上 一个 ， 带来 的 效果 就是 完成 检查点 的 速度 和 背 压 没有 太 直接 的 关系 了 ， 实际 的 使用 也 验证 了 这 一点 。 但 和 预期 还是 有 稍稍 的 不同 ， 从 Kafka 监控 来看 ， 按照 之前 对齐 检查点 方式 ， 每个 检查点 完成 后 立即 就 能 看到 监控 上 的 消费 波峰 ， 但 非 对齐 检查点 的 完成 和 波峰 就 没有 直接 关系 ， 不过 它 起码 比 对齐 检查点 好 在 不会 在 数据 流量 高峰 到来 时 全部 超时 ， 导致系统 瘫痪 。 带来 的 好处 直观 而 明显 ， 但 不 方便 之 处 也 是 有 的 。 对 检查点 存储 后 端的 压力 会 非常 大 。 之前 每个 检查点 大小 是 24K 左右 ， 而 改成 新 的 方式 后 就 达到 了 200MB 左右 ， 对 IO 的 压力 增加 可想而知 ， 不过 由于 我们 用 的 是 rocksdb 后 端 ， 所以 这个 压力 可以 承受 。 这种 情况 下 自动 创建 的 检查点 不能 用来 扩容 / 缩 容 。 由于 没有 对齐 ， 就 没 办法 做 内部 的 rescale， 重启 前后 的 TaskManager 数量 必须 一致 。 但 好 在 可以 通过 人工 生成 SavePoint 的 方式 来 创建 一个 完整 的 保存 点 ， 用 保存 点 保证 重启 过程 的 数据 不 丢失 。 总结 总之 Flink 的 这个 新 功能 还是 非常 有用 的 ， 在 使用 这个 功能 之前 数据量 增大 的 时候 只能 祈祷 它 不 超时 ， 然而 总是 事与愿违 。 看 文档 说 后面 的 目标 是 把 非 对齐 检查点 作为 默认 的 检查点 模式 ， 从 目前 看 还有 很 长 的 路 要 走 。","title":"Flink 的 新 特性 ——Unaligned Checkpoints","oriTitle":"Flink的新特性——Unaligned Checkpoints","categories":["flink"],"date":"2021-02-04T14:55:48.000Z"},{"uri":"/post/go/0x00-introduction","tags":["golang","go"],"content":" 最近 要 写 一个 可以 跨平台 执行 又 不 依赖 运行 时 的 程序 ， 所以 就 把 golang 又 捡起来 了 。 说实话 如果 不是 写 公司 的 项目 ，Java 实在 是 一个 让 人 喜欢 不 起来 的 语言 ， 主要 maven 这 一套 搞 起来 太 麻烦 ， 而且 还 需要 在 运行 的 机器 上 安装 一个 jre， 这 又 增加 了 使用 门槛 ， 如果 要 给 非 开发人员 写 一个 拿来 即 用 的 程序 ，go 确实 是 一个 不错 的 选择 。 我 要 写 的 这个 程序 主要 功能 包括 以下 几 部分 引用 现成 的 包  go mod 有 命令行 交互  cobra 处理 网络 请求 ， 包括 Cookie、Get、Post 请求 以及 不同 的 参数传递 方式  resty/colly 下载 图片 并 展示  resty/exec 识别 图片 验证码 ， 本来 希望 能 完美 识别 ， 但 测试 了 tessocr 之后 觉得 效果 不好 就 没 再 深究 了  tessocr 加快 执行 速度 （ 最 开始 没有 考虑 ） goroutine 处理 配置文件 ， 包括 ini 和 yaml viper 连接 数据库 ， 仅仅 是 检查 连通性  sql 将 配置文件 打包 到 可执行文件 内  packr 所以 我 就 想 就 着 这些 需求 ， 把 这 几天 重温 golang 的 过程 记录 一下 。","title":"0x00  引言 ","oriTitle":"0x00 引言","categories":["go"],"date":"2021-12-15T15:42:00.000Z"},{"uri":"/post/go/0x01-go-modules","tags":["golang","go"],"content":" 本篇 主要 介绍 golang 的 一些 基础 命令 以及 如何 在 大陆 合理 访问 官方 以及 第三方 的 包 。go run 最 简单 的 执行 go 代码 的 方法 ， 不 需 编译 。// main.gopackage mainimport (    \"fmt\")func main() {    fmt.Println(\"Hello World!\")} 上面 的 代码 写 好 之后 就 可以 执行 go run main.go 来 验证 是否 正确 了 。go mod 我 觉得 有 了 mod 的 go 语言 才 真正 算是 现代化 的 语言 了 ， 在此之前 的 第三方 的 方案 不能 说 不好 ， 但 谁 让 你 是 第三方 呢 ？ 初始化 一个 开启 了 go mod 的 项目 go mod init  会 创建 一个 简单 的 go.mod 文件 ， 这 很 像是 Java 的 pom.xml， 但 要 简洁 的 多 的 多 了 。module github.com/lovelock/go-tutorialsgo 1.17 整理 依赖 开发 过程 中 可能 会 尝试 引入 一些 依赖 ， 后来 发现 其实 是 不 需要 的 ，  或者 直接 在 代码 中 引用 了 ， 但 没有 把 它 加入 go.mod 中 ， 可以 通过 go mod tidy 来 一键 整理 项目 的 依赖 。go build> ⚠️  在 GO111MODULE=\"on\" 时 也 就是 开启 了 go 模块 后 ， 需要 先 出 实话 mod 相关 的 配置 才 可以 执行 go build 如果 想 生成 一个 可执行文件 ， 就要 用 编译 / 打包 了 。 这里 想 多 介绍 的 一点 是 交叉 编译 ， 也就是说 在 macOS 上 打包 Windows 上 可以 执行 的 文件 。 在 macOS 或 Linux 上 打包 CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build main.goCGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build main.goCGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build main.go 在 Windows 上 打包 set CGO_ENABLED=0set GOOS=darwinset GOARCH=amd64go build main.go>  想 看 是否 生效 ， 可以 用 go env 查看 go cleango build 之后 会 生成 二进制 可执行文件 ， 执行 go clean 会 把 已经 生成 的 可执行文件 删除 掉 go install 如果 把 go build 比喻 成 mvn package， 那么 go install 就是 mvn install 了 。 会 把 二进制 文件 放在 GOPATH 中 ， 如果 妥善 设置 了 GOPATH， 就 可以 直接 用 了 。go test 执行 单元测试 用 的 ， 可以 用来 做 功能测试 和 性能 测试 ， 所有 测试 文件 以 _test.go 结尾 。 功能测试 的 方法 以 Test 开始 ， 参数 是 (t *testing.T)； 性能 测试 的 方法 以 Benchmark 开始 ， 参数 是 (b *testing.B)。go get 到 这 才 是 go modules 的 关键 ， 它 是 用来 拉 取 依赖 包 的 ， 它 有 一些 控制参数 ， 比如 go get -t 表示 要 打包 要 安装 的 包 的 单元测试 ，go get -u 表示 安装 依赖 包 的 最新 的 小 版本 。 所谓 小 版本 又 涉及 到 语义 化 版本 了 ， 具体 可以 看 这里 ","title":"0x01  基础 命令 以及 go mod","oriTitle":"0x01 基础命令以及go mod","categories":["go"],"date":"2021-12-15T15:50:38.000Z"},{"uri":"/post/hugo-localsearch-support","tags":["hugo","blog","lunr","搜索引擎","站内搜索"],"content":" 这个 博客 也 写 了 不少 东西 了 ， 但 功能 还是 有些 简陋 ， 比如 不 支持 搜索 ， 也 不能 评论 ， 甚至 不 知道 有 多少 人 访问 过 。 逛 知 乎 的 时候 无意间 看到 了  Maupassant  这个 主题 ， 总体 看上去 还 挺 简洁 大方 的 ， 主要 是 信息 展示 的 比较 丰富 ， 不 像 之前 的  even  主题 ， 想 看 标签 和 分类 还要 专门 去 单独 的 页面 。 所以 就 开始 了 改造 。 访问 计数 这个 就 比较简单 了 ， 之前 用 的  even  主题 里 也 有 这个 位置 ， 只是 没有 打开 而已 。[params]  [params.busuanzi]         # count web traffic by busuanzi                             #  是否 使用 不 蒜 子 统计 站点 访问量     enable = true    siteUV = true    sitePV = true    pagePV = true 评论 评论 也 比较简单 ， 使用 的 是 utteranc [params.utteranc]       # https://utteranc.es/   enable = true   repo = \"lovelock/blog-comments\"               # The repo to store comments   issueTerm = \"pathname\"  # 表示 你 选择 以 那种 方式 让 github issue 的 评论 和 你 的 文章 关联 。   theme = \"github-light\" #  样式 主题 ， 有 github-light 和 github-dark 两种    async = true 站内搜索 重头戏 是 站内搜索 。 本来 也 没 想 弄 ， 发现 这个 主题 有 这个 功能 就 想着 把 它 搞定 。 但 按 主题 作者 的 说法 配置 完成 了 之后 并 没有 任何 效果 ， 所以 我 就 研究 了 下  hugo  下 实现 站内搜索 的 方案 。 首先 是 打开 [params]  localSearch = true 然后 在 content/search 目录 下 新建 index.md 文件 ， 并 添加 以下内容 title: \" 搜索 \"description: \" 搜索 页面 \"type: \"search\" 做 这些 的 目的 是 在 使用 搜索 功能 的 时候 可以 跳转 到 ${baseURL}/search/q=keyword 这个 页面 ， 而 它 对应 的 页面 模板 就是 single.html。 我 读 了 下 源码 ， 其实 它 做 的 事情 是 在 这个 页面  load  完成 时 从 public/index.xml 中 找到 所有 文章 的 标题 ， 然后 在 标题 列表 中 查找 相应 的 关键词 。 这 存在 几个 问题 中文 分词 的 支持 肯定 不好 public/index.html 无法 下载 选型 所以 我 就 转而 去  hugo  的 官 网 查 解决方案 了 。 查 了 一圈 对  lunr.js  比较 感兴趣 ， 好像 功能 也 比较 强大 ， 对应 也 有  hugo  的 小 工具 。 说来 也 搞笑 ，hugo  本来 是 要 取代  hexo  作为 新一代 的 静态 站点 生成 引擎 的 ， 这 是  go  语言 和  node  的 竞争 ， 但 当 涉及 到 这个 领域 时 ， 竟然 需要 在  hugo  中 引入  node  模块 来 解决 。 不过 还好 ， 我 对 这个 也 没有 洁癖 ， 能 工作 就 行 。 原理 其实 和 上面 描述 的 差不多 ， 通过 hugo-lunr-zh 生成 一个 index.json 文件 ， 页面 加载 的 时候 把 这个 文件 加载 过来 ， 通过  lunr  的 搜索 功能 在 里面 查 到 关键词 ， 进而 进行 下 一步 的 展示 。 这个 hugo-lunr-zh 其实 项目 本身 和  lunr  并 无 关系 ， 它 只是 用来 生成  lunr  可以 识别 的 数据 而已 。 而 要 使用 hugo-lunr-zh 则 是 为了 支持 中文 分词 。 行动 既然 改 了 搜索 方案 ， 现有 的 single.html 也 肯定 不能 用 了 ， 先  fork  一个 。 然后 npm -g install hugo-lunr-zh， 然后 在 博客 的 根目录 执行 hugo-lunr-zh， 简直 是 涕泗横流 ， 跑 不通 。 搜索 了 一下 确实 这个 方案 是 有些 问题 的 ， 主要 是 作者 也 不 更新 了 。 但 我 觉得 这个 原理 很 清晰 ， 于是 进入 了 不断 的  debug  阶段 。>  在  npm  上 的 版本 是  1.0.3， 而 我 自己 魔 改 成功 运行 之后 才 发现  github  上 的  master  已经 是  2.1.0  了 ， 但 我 把  master  版本 下载 下来 竟然 都 无法 安装 。 我 也 没 兴趣 研究 到底 哪里 出 了 问题 了 。 遇到 了 以下 问题 路径 解析 的 不 对 在  https  页面 上 向  http  的 接口 发起 请求 被 浏览器 拦截 在 $document.ready(() => {}) 中 操作 lunr 为 新 方案 适配 页面 1.  路径 解析 的 不 对 不 知道 是 为什么 作者 会 设计 成 这样 的 ， 我 的 文件 是 在 类似 post/life/a.md、post/devops/b.md 这种 路径 ， 为什么 它 会 认为 最终 的 访问 路径 是 posts/a 和 posts/b 呢 ？ 这个 解决 的 比较简单 ， 就是 破坏 了 原本 的 设计 ， 主要 是 我 也 不 认同 它 的 设计 。2.  在  https  页面 上 向  http  的 接口 发起 请求 被 浏览器 拦截 这个 问题 是 我 这个 站点 没有 使用  https， 在 配置文件 中 的 baseURL=http://blog.happyhacker.fun， 也 没有 用  https， 相应 的 搜索 框 的 写法 是 {{ \"search/\" | absURL }}， 经过  hugo  黑盒 的 解析 之后 这个 完整 的 链接 变成 了 https://blog.happyhacker.fun/search； 由于 无法 从 public 目录 下载 index.json 文件 ， 所以 我 把 它 放在 static/js/ 目录 下 了 ， 在 页面 模板 中 的 写法 是 {{ \"js/index.json\" | absURL }}， 最终 的 完成 链接 却 变成 了 http://blog.happyhacker.fun/js/index.json。 注意 到 区别 了 吗 ？js  目录 下 的 文件 没有  https， 而 跳转 的 页面 有  https。 所以 我 干脆 就 在 配置文件 里 把 baseURL 也 改成 https 了 ， 问题 就 这么 解决 了 。 因为 所有 的 请求 都 变成 了  https， 虽然 我 并 没有 配置 证书 。3.  在 $document.ready(() => {}) 中 操作 lunr 在 完成 这块 之前 我 是 没 想着 要 用到 分词 的 ， 只是 简单 分析 了 在 命令行 生成 的 词表 的 结构 ， 想着 干脆 把 这些 内容 用 空格 分开 生成 一个 大 列表 ， 然后 用 Array.prototype.includes() 方法 来 实现 搜索 ， 后来 研究 了 一下 发现 用  lunr  自身 的 搜索引擎 看起来 要 强大 许多 。 核心 代码 如下 $(document).ready(function () {  var q = getUrlParameter(\"q\");  $(\"span.keyword\").text(q);  $(\"article.post\").remove();  $.ajax({    url: '{{\"js/index.json\"|absURL}}',    dataType: \"json\",    success: function (data) {      lunr.zh = function () {        this.pipeline.reset();        this.pipeline.add(lunr.zh.trimmer, lunr.stopWordFilter, lunr.stemmer);      };      lunr.zh.trimmer = function (token) {        return token.update((str) => {          if (/[\\u4E00-\\u9FA5\\uF900-\\uFA2D]/.test(str)) return str;          return str.replace(/^\\W+/, \"\").replace(/\\W+$/, \"\");        });      };      lunr.Pipeline.registerFunction(lunr.zh.trimmer, \"trimmer-zh\");      const idx = lunr(function () {        this.use(lunr.zh);        this.ref(\"uri\");        this.field(\"content\");        this.field(\"tags\");        this.field(\"categories\");        this.field(\"title\");        data.forEach(function (e) {          this.add(e);        }, this);      });      const result = idx.search(q);      const hitRefs = result.map((e) => e.ref);      result.forEach((e) => {        const item = data.filter((d) => d.uri == e.ref)[0];        const oriTitle = item[\"oriTitle\"];        const content = item[\"content\"];        const title = item[\"title\"];        const uri = item[\"uri\"];        const score = result.filter((f) => uri == f.ref)0;        let searchItem =          `` +          oriTitle +          ``;        const pubDate = new Date(item[\"date\"]);        searchItem +=          `` +          pubDate.getFullYear() +           年  +          (pubDate.getMonth() + 1) +           月  +          pubDate.getDate() +           日 &nbsp;  匹配 度 ： +          score +          ``;        searchItem +=          `` +          item[\"content\"].replace(/\\s*/g, \"\").substring(0, 100) +          …… 阅读 全文 ;        $(\"div.res-cons\").append(searchItem);      });    },  });}); 梳理 下 逻辑 就是 拿到 词表 之后 在 前端 构建 一个  lunr  搜索引擎 ， 从中 搜索 想要 的 结果 ， 然后 根据 结果 中 的  ref  再 回到 原始 结果 中 拿 数据 ， 拼 页面 。 这里 提 一点 ，hugo  的 设计 还是 很 灵活 的 ， 可以 在 config.toml 中 配置 customJs 可以 在 所有 页面 引入 一个  js， 简直 不要 太 方便 。4.  为 新 方案 适配 页面 代码 已经 在 上面 贴出来 了 ， 比较简单 。 总结 开源 项目 真的 是 很 依赖 作者 ， 虽说 用 的 人 可能 很多 ， 但 真正 去 改 它 的 人 可能 凤毛麟角 。 作者 一时 兴起 发起 了 一个 开源 项目 ， 后面 不想 维护 了 ， 就 把 一堆 烂摊子 丢 给 了 用户 。 开源 免费 的 东西 我们 不能 要求 太 多 ， 那 就 只好 自己 在 前人 的 基础 上 研究 了 ， 只是 要 多 花 些 时间 。 本次 改造 中 新建 了 两个  repoMaupassant  主题 hugo-lunr-zh","title":"Hugo 支持 站内搜索 ","oriTitle":"Hugo支持站内搜索","categories":["in-action"],"date":"2021-01-16T16:11:45.000Z"},{"uri":"/post/install-centos8","tags":["linux","centos8"],"content":" 多年 不 安装 虚拟机 ， 竟然 卡 在 了 第一步 。 拣 重点 提 一下 容易 出 问题 的 地方 。 配置 联网 选择 安装 源 因为 DVD 的 安装 iso 太 大 了 ， 就 选 了 个 最小化 安装 iso。 这里 配置 的 地方 也 没有 可以 参考 的 文档 ， 照着 这个 写 就 可以 了 。 国内 有 很多 镜像 站 ， 可以 选 一个 你 自己 访问速度 最快 的 。 后面 的 步骤 就 不用说 了 。","title":"Install Centos8","oriTitle":"Install Centos8","categories":["in-action"],"date":"2020-04-05T16:10:43.000Z"},{"uri":"/post/install-homebrew-in-china","tags":["macOS","homebrew"],"content":" 不 知道 为什么 好像 家里 的 网络 对 github 很 不 友好 ， 网页 能 打开 ， 但 通过 curl 访问 就 有 问题 ， 所以 安装 homebrew 时 如果 使用 官方 提供 的 花里胡哨 的 curl 或者 wget 的 方式 就 安装 不 上 。 姑且 说 安装 成功 了 吧 ， 后面 安装 其他软件 的 时候 又 会 各种 慢 。 国内 中科大 ( 个人 认为 国内 做 的 最好 的 开源 镜像 站点 ) 和 清华大学 都 提供 了 homebrew 的 镜像 ， 但 比较 吊 诡 的 是 他们 提供 的 都 是 post-installation， 也 就是 前提 是 你 已经 安装 好 了 brew。 殊不知 很多 人 （ 网络 环境 ） 这 一步 都 过 不了 关 了 。 所以 我 看 了 一下 官方 的 安装 脚本 ， 参考 了 中科大 的 文档 ， 把 安装 脚本 中 的 github 地址 给 改成 中科大 的 ， 然后 加上 了 brew-cask 和 brew-core， 并 把 其中 的 brew update --force 命令 后面 加 了 个 -v， 方便 在 安装 的 时候 可以 看到 具体 的 进度 。 脚本 正文 直接 贴出来 ， 有 想 看 github 的 在 这里 。 脚本 默认 你 使用 的 是 zsh， 有 偏好 使用 bash 的 同学 可以 自行 修改 #!/bin/bashset -uFirst check if the OS is Linux.if [[ \"$(uname)\" = \"Linux\" ]]; then  HOMEBREWONLINUX=1fiOn macOS, this script installs to /usr/local only.On Linux, it installs to /home/linuxbrew/.linuxbrew if you have sudo accessand ~/.linuxbrew otherwise.To install elsewhere (which is unsupported)you can untar https://github.com/Homebrew/brew/tarball/masteranywhere you like.if [[ -z \"${HOMEBREWONLINUX-}\" ]]; then  HOMEBREW_PREFIX=\"/usr/local\"  HOMEBREW_REPOSITORY=\"/usr/local/Homebrew\"  HOMEBREW_CACHE=\"${HOME}/Library/Caches/Homebrew\"  STAT=\"stat -f\"  CHOWN=\"/usr/sbin/chown\"  CHGRP=\"/usr/bin/chgrp\"  GROUP=\"admin\"  TOUCH=\"/usr/bin/touch\"else  HOMEBREWPREFIXDEFAULT=\"/home/linuxbrew/.linuxbrew\"  HOMEBREW_CACHE=\"${HOME}/.cache/Homebrew\"  STAT=\"stat --printf\"  CHOWN=\"/bin/chown\"  CHGRP=\"/bin/chgrp\"  GROUP=\"$(id -gn)\"  TOUCH=\"/bin/touch\"fiBREW_REPO=\"http://mirrors.ustc.edu.cn/brew.git\"TODO: bump version when new macOS is releasedMACOSLATESTSUPPORTED=\"10.15\"TODO: bump version when new macOS is releasedMACOSOLDESTSUPPORTED=\"10.13\"no analytics during installationexport HOMEBREWNOANALYTICSTHISRUN=1export HOMEBREWNOANALYTICSMESSAGEOUTPUT=1string formattersif [[ -t 1 ]]; then  tty_escape() { printf \"\\033[%sm\" \"$1\"; }else  tty_escape() { :; }fittymkbold() { ttyescape \"1;$1\"; }ttyunderline=\"$(ttyescape \"4;39\")\"ttyblue=\"$(ttymkbold 34)\"ttyred=\"$(ttymkbold 31)\"ttybold=\"$(ttymkbold 39)\"ttyreset=\"$(ttyescape 0)\"havesudoaccess() {  if [[ -z \"${HAVESUDOACCESS-}\" ]]; then    /usr/bin/sudo -l mkdir &>/dev/null    HAVESUDOACCESS=\"$?\"  fi  if [[ -z \"${HOMEBREWONLINUX-}\" ]] && [[ \"$HAVESUDOACCESS\" -ne 0 ]]; then    abort \"Need sudo access on macOS!\"  fi  return \"$HAVESUDOACCESS\"}shell_join() {  local arg  printf \"%s\" \"$1\"  shift  for arg in \"$@\"; do    printf \" \"    printf \"%s\" \"${arg// /\\ }\"  done}chomp() {  printf \"%s\" \"${1/\"$'\\n'\"/}\"}ohai() {  printf \"${ttyblue}==>${ttybold} %s${ttyreset}\\n\" \"$(shelljoin \"$@\")\"}warn() {  printf \"${ttyred}Warning${ttyreset}: %s\\n\" \"$(chomp \"$1\")\"}abort() {  printf \"%s\\n\" \"$1\"  exit 1}execute() {  if ! \"$@\"; then    abort \"$(printf \"Failed during: %s\" \"$(shell_join \"$@\")\")\"  fi}execute_sudo() {  local -a args=(\"$@\")  if [[ -n \"${SUDO_ASKPASS-}\" ]]; then    args=(\"-A\" \"${args[@]}\")  fi  if havesudoaccess; then    ohai \"/usr/bin/sudo\" \"${args[@]}\"    execute \"/usr/bin/sudo\" \"${args[@]}\"  else    ohai \"${args[@]}\"    execute \"${args[@]}\"  fi}getc() {  local save_state  save_state=$(/bin/stty -g)  /bin/stty raw -echo  IFS= read -r -n 1 -d '' \"$@\"  /bin/stty \"$save_state\"}waitforuser() {  local c  echo  echo \"Press RETURN to continue or any other key to abort\"  getc cwe test for \\r and \\n because some stuff does \\r instead  if ! [[ \"$c\" == $'\\r' || \"$c\" == $'\\n' ]]; then    exit 1  fi}major_minor() {  echo \"${1%%.}.$(x=\"${1#.}\"; echo \"${x%%.*}\")\"}if [[ -z \"${HOMEBREWONLINUX-}\" ]]; then  macosversion=\"$(majorminor \"$(/usr/bin/sw_vers -productVersion)\")\"fiversion_gt() {  [[ \"${1%.}\" -gt \"${2%.}\" ]] || [[ \"${1%.}\" -eq \"${2%.}\" && \"${1#.}\" -gt \"${2#.}\" ]]}version_ge() {  [[ \"${1%.}\" -gt \"${2%.}\" ]] || [[ \"${1%.}\" -eq \"${2%.}\" && \"${1#.}\" -ge \"${2#.}\" ]]}version_lt() {  [[ \"${1%.}\" -lt \"${2%.}\" ]] || [[ \"${1%.}\" -eq \"${2%.}\" && \"${1#.}\" -lt \"${2#.}\" ]]}shouldinstallgit() {  if [[ $(command -v git) ]]; then    return 1  fi}shouldinstallcommandlinetools() {  if [[ -n \"${HOMEBREWONLINUX-}\" ]]; then    return 1  fi  if versiongt \"$macosversion\" \"10.13\"; then    ! [[ -e \"/Library/Developer/CommandLineTools/usr/bin/git\" ]]  else    ! [[ -e \"/Library/Developer/CommandLineTools/usr/bin/git\" ]] ||      ! [[ -e \"/usr/include/iconv.h\" ]]  fi}get_permission() {  $STAT \"%A\" \"$1\"}useronlychmod() {  [[ -d \"$1\" ]] && [[ \"$(get_permission \"$1\")\" != \"755\" ]]}existsbutnot_writable() {  [[ -e \"$1\" ]] && ! [[ -r \"$1\" && -w \"$1\" && -x \"$1\" ]]}get_owner() {  $STAT \"%u\" \"$1\"}filenotowned() {  [[ \"$(get_owner \"$1\")\" != \"$(id -u)\" ]]}get_group() {  $STAT \"%g\" \"$1\"}filenotgrpowned() {  [[ \" $(id -G \"$USER\") \" != \" $(get_group \"$1\") \"  ]]}USER isn't always set so provide a fall back for the installer and subprocesses.if [[ -z \"${USER-}\" ]]; then  USER=\"$(chomp \"$(id -un)\")\"  export USERfiInvalidate sudo timestamp before exiting (if it wasn't active before).if ! /usr/bin/sudo -n -v 2>/dev/null; then  trap '/usr/bin/sudo -k' EXITfiThings can fail later if pwd doesn't exist.Also sudo prints a warning message for no good reasoncd \"/usr\" || exit 1####################################################################### scriptif shouldinstallgit; then    abort \"$(cat &1)\"    sudoexitcode=\"$?\"    if [[ \"$sudoexitcode\" -ne 0 ]] && [[ \"$sudo_output\" = \"sudo: a password is required\" ]]; then      ohai \"Select the Homebrew installation directory\"      echo \"- ${ttybold}Enter your password${ttyreset} to install to ${ttyunderline}${HOMEBREWPREFIXDEFAULT}${ttyreset} (${ttybold}recommended${ttyreset})\"      echo \"- ${ttybold}Press Control-D${ttyreset} to install to ${ttyunderline}$HOME/.linuxbrew${ttyreset}\"      echo \"- ${ttybold}Press Control-C${ttyreset} to cancel installation\"    fi    if havesudoaccess; then      HOMEBREWPREFIX=\"$HOMEBREWPREFIX_DEFAULT\"    else      HOMEBREW_PREFIX=\"$HOME/.linuxbrew\"    fi    trap - SIGINT  fi  HOMEBREWREPOSITORY=\"${HOMEBREWPREFIX}/Homebrew\"fiif [[ \"$UID\" == \"0\" ]]; then  abort \"Don't run this as root!\"elif [[ -d \"$HOMEBREWPREFIX\" && ! -x \"$HOMEBREWPREFIX\" ]]; then  abort \"$(cat &1)\" && [[ \"$output\" == \"license\" ]]; then  abort \"$(cat /dev/null || returnwe do it in four steps to avoid merge errors when reinstalling  execute \"git\" \"init\" \"-q\"\"git remote add\" will fail if the remote is defined in the global config  execute \"git\" \"config\" \"remote.origin.url\" \"${BREW_REPO}\"  execute \"git\" \"config\" \"remote.origin.fetch\" \"+refs/heads/:refs/remotes/origin/\"ensure we don't munge line endings on checkout  execute \"git\" \"config\" \"core.autocrlf\" \"false\"  execute \"git\" \"fetch\" \"origin\" \"--force\"  execute \"git\" \"fetch\" \"origin\" \"--tags\" \"--force\"  execute \"git\" \"reset\" \"--hard\" \"origin/master\"  execute \"ln\" \"-sf\" \"${HOMEBREWREPOSITORY}/bin/brew\" \"${HOMEBREWPREFIX}/bin/brew\"  execute \"cd\" \"${HOMEBREW_PREFIX}/Homebrew/Library/Taps/homebrew\"  execute \"git\" \"clone\" \"https://mirrors.ustc.edu.cn/homebrew-cask.git\"  execute \"git\" \"clone\" \"https://mirrors.ustc.edu.cn/homebrew-core.git\"  execute \"${HOMEBREW_PREFIX}/bin/brew\" \"update\" \"--force\" \"-v\"  execute \"echo\" \"export\" \"HOMEBREWBOTTLEDOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles\" \">>\" \"~/.zshrc\"  execute \"source\" \"~/.zshrc\")if [[ \":${PATH}:\" != \":${HOMEBREW_PREFIX}/bin:\" ]]; then  warn \"${HOMEBREW_PREFIX}/bin is not in your PATH.\"fiohai \"Installation successful!\"echoUse the shell's audible bell.if [[ -t 1 ]]; then  printf \"\\a\"fiUse an extra newline and bold to avoid this being missed.ohai \"Homebrew has enabled anonymous aggregate formulae and cask analytics.\"echo \"$(cat /dev/null || return  execute \"git\" \"config\" \"--replace-all\" \"homebrew.analyticsmessage\" \"true\"  execute \"git\" \"config\" \"--replace-all\" \"homebrew.caskanalyticsmessage\" \"true\")ohai \"Next steps:\"echo \"- Run \\brew help\\ to get started\"echo \"- Further documentation: \"echo \"    ${ttyunderline}https://docs.brew.sh${ttyreset}\"if [[ -n \"${HOMEBREWONLINUX-}\" ]]; then  case \"$SHELL\" in    /bash)      if [[ -r \"$HOME/.bash_profile\" ]]; then        shellprofile=\"$HOME/.bashprofile\"      else        shell_profile=\"$HOME/.profile\"      fi      ;;    /zsh)      shell_profile=\"$HOME/.zprofile\"      ;;    *)      shell_profile=\"$HOME/.profile\"      ;;  esac  cat > ${shell_profile}Add Homebrew to your ${ttybold}PATH${ttyreset}    eval \\$(${HOMEBREW_PREFIX}/bin/brew shellenv)We recommend that you install GCC by running:    brew install gccEOSfi","title":" 中国 大陆 安装 homebrew 的 最优 方法 ","oriTitle":"中国大陆安装homebrew的最优方法","categories":["in-action"],"date":"2020-05-15T16:20:48.000Z"},{"uri":"/post/java/gson-vs-jackson","tags":["gson","jackson","json"],"content":" 工作 中 难免 经常 会 用到 这 两个 库 ， 简单 来说 Gson 的 用法 比较 无脑 ， 而 Jackson 的 则 比较 绕 。 这里 对比 几个 比较 典型 的 用法 。0.  准备 工作 引入 相关 依赖       com.google.code.gson      gson      2.8.6      com.fasterxml.jackson.core      jackson-databind      2.12.1      org.projectlombok      lombok      1.18.18      org.apache.logging.log4j      log4j-core      2.14.0      com.github.javafaker      javafaker      1.0.2      org.apache.logging.log4j      log4j-api      2.14.0 两个 POJOpackage fun.happyhacker;import lombok.Builder;import lombok.Data;@Data@Builderpublic class Person {    private Integer id;    private Integer age;    private String address;    private String title;    private Job job;}package fun.happyhacker;import lombok.AllArgsConstructor;import lombok.Data;@Data@AllArgsConstructorpublic class Job {    private String name;    private String domain;} 启动 类 package fun.happyhacker;import com.fasterxml.jackson.databind.ObjectMapper;import com.github.javafaker.Faker;import com.google.gson.Gson;import lombok.extern.log4j.Log4j2;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;@Log4j2public class App {    private static final Faker FAKER = Faker.instance();    private static final Gson GSON = new Gson();    private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();    public static void main(String[] args) {    }}1.  将 POJO 序列化 为 json2.  将 json 反 序列化 为 POJO2.1. Jackson  从 字符串 读取 json 转 成 POJO 对象     private static void jacksonJson2Pojo() {        try {            JsonNode jsonNode = OBJECTMAPPER.readTree(JSONPOJO);            log.info(jsonNode.toPrettyString());            Person person = OBJECTMAPPER.readValue(JSONPOJO, Person.class);            log.info(\"person {}\", person);            Person person1 = OBJECT_MAPPER.convertValue(jsonNode, Person.class);            log.info(\"person {}\", person1);        } catch (JsonProcessingException e) {            e.printStackTrace();        }    }2.2. Jackson  从文件 读取 json 内容 转 成 POJO 对象     private static void jacksonReadFromFile() {        List personList = new BufferedReader(new InputStreamReader(Objects.requireNonNull(Thread.currentThread().getContextClassLoader().getResourceAsStream(\"person.data\"))))        .lines()                .map(e -> {                    try {                        return OBJECT_MAPPER.readValue(e, Person.class);                    } catch (JsonProcessingException jsonProcessingException) {                        jsonProcessingException.printStackTrace();                    }                    return new Person();                })                .collect(Collectors.toList());        log.info(\"{}\", personList);    }2.2. Gson  从 字符串 读取 json 转 成 POJO 对象     private static void gsonJson2Pojo() {        Person person = GSON.fromJson(PERSON_JSON, Person.class);        log.info(\"person {}\", person);        JsonObject jsonObject = JsonParser.parseString(PERSON_JSON).getAsJsonObject();        log.info(\"json object {}\", jsonObject);        Person person1 = GSON.fromJson(jsonObject, Person.class);        log.info(\"person person1 {}\", person1);    } 从文件 读取 的 类似 ， 区别 只是 在于 map() 中 的 方法 不 一样 。>  这里 发现 了 一个 小 特点 ， 在 用 Jackson 测试 的 时候 ，json 字符串 最后 多 了 一位 \"}\"，Gson 会 报错 ， 而 Jackson 不 报错 ， 而且 结果 也 是 对 的 。3.  涉及 集合 的 场景 写 PHP 的 时候 没有 这个 意识 ， 写 Java 多 了 对 这个 感受 就 特别 深 了 。 因为 在 PHP 里 不管 是 List 还是 Map 通通 都 是 Array， 甚至 Object 用 起来 也 和 Array 没 啥 区别 ， 所以 对于 上面 的 例子 ， 经常 会 生成 这种 json{  \"1\": {    \"id\": 1,    \"age\": 34,    \"address\": \"2255 Monahan Mount, Batzton, MS 43857-6615\",    \"title\": \"qpzzi\",    \"job\": {      \"name\": \"trkfem\",      \"domain\": \"fwun\"    }  },  \"2\": {    \"id\": 2,    \"age\": 35,    \"address\": \"Suite 408 736 Chantel Estate, Port Kathyfurt, CA 72201\",    \"title\": \"itdpt\",    \"job\": {      \"name\": \"akuhbv\",      \"domain\": \"ckwz\"    }  },  \"3\": {    \"id\": 3,    \"age\": 28,    \"address\": \"87147 Kutch Summit, Andreaport, NV 24529-3219\",    \"title\": \"lmudd\",    \"job\": {      \"name\": \"fbjadr\",      \"domain\": \"damu\"    }  }} 因为 这样 在 取 id 的 时候 会 方便 一些 。 但 在 Java 中 处理 这种 数据 就 比较 蛋 疼 了 。3.1.  简单 的 Map3.2. List of Map","title":"Gson  和  Jackson  对比 ","oriTitle":"Gson 和 Jackson 对比","categories":["in-action"],"date":"2021-03-05T07:29:09.000Z"},{"uri":"/post/java/create-custom-archetype","tags":["maven","java","archetype"],"content":" 用 默认 的 archetype 太烦 了 ， 每次 都 要 改 很多 东西 ， 不如 自己 创建 一个 。 为什么 要 自己 定义 archetype 当然 是因为 懒 。 我 一般 是 用 maven-archetype-quickstart 创建 项目 ， 但 每次 创建 完 之后 还要 改 一通 ， 比如 JDK 版本号 、maven 插件 等等 ， 这些 东西 本身 其实 不 应该 花 太 多 时间 去 记 的 。 所以 自己 定义 一个 就 好 了 。 定义 archetype 的 步骤 生成 模板 从 maven-archetype-quickstart 创建 一个 正常 的 maven 项目 这个 maven 项目 是 什么 不 重要 ， 重要 的 是 它 会 帮 你 生成 一个 标准 的 pom.xml 文件 。 修改 pom.xml 文件 比如 你 几乎 所有 的 项目 都 需要 依赖 log4j2 这 套 日志 套件 ， 那么 你 就 需要 这 两个 依赖     org.apache.logging.log4j    log4j-api    2.14.0    org.apache.logging.log4j    log4j-core    2.14.0 那么 你 就 可以 在 这个 生成 的 pom.xml 文件 中 加上 这 两个 依赖 。 执行 mvn archetype:create-from-project 这 会 在 target 目录 中 生成 一个 新 的 maven 项目 ， 进入 这个 项目 ， 执行 mvn clean install， 你 就 把 新创建 的 archetype 安装 到 本地 了 。 使用 新创建 的 模板 执行 mvn archetype:generate -DarchetypeCatalog=local， 会 产生 一个 交互 ➜  my-project mvn archetype:generate -DarchetypeCatalog=local[INFO] Scanning for projects...[INFO][INFO] ------------------------------------------[INFO] Building my-project 1.0-SNAPSHOT[INFO] --------------------------------[ jar ]---------------------------------[INFO][INFO] >>> maven-archetype-plugin:3.1.2:generate (default-cli) > generate-sources @ my-project >>>[INFO][INFO]  org.apache.flink:flink-quickstart-java (flink-quickstart-java)2: local -> org.apache.maven.archetypes:maven-archetype-quickstart (quickstart)3: local -> fun.happyhacker:my-quickstart-1.8-archetype (my-quickstart-1.8)4: local -> fun.happyhacker:archetype-template-archetype (archetype-template)Choose a number or apply filter (format: [groupId:]artifactId, case sensitive contains): 2: 这时 就 可以 在 其中 找到 刚刚 创建 的 archetype 了 ， 在 这里 就是 第 4 个 ， 所以 在 交互 界面 填 4， 就 可以 继续 选择 域名 和 项目名称 ， 生成 一个 新 的 maven 项目 ， 在 生成 的 项目 中 你 就 会 发现 你 刚刚 在 第 2 步 中 添加 的 两个 依赖 已经 包含 在 里面 了 。 同样 的 道理 ， 也 可以 在 pom.xml 中 添加 相关 的 maven 插件 ， 以 使 从 模板 创建 的 项目 更 复合 平时 的 需求 。","title":" 创建 一个 自定义 的 Archetype","oriTitle":"创建一个自定义的Archetype","categories":["in-action"],"date":"2020-11-18T15:03:17.000Z"},{"uri":"/post/java/date-class-comparison","tags":["java"],"content":" 我们 知道  Java1.8  推荐 使用  LocalDate 和 LocalDateTime 类 来 处理 日期 和 时间 ， 但 之前 的 版本 是 用 GregorianCalendar。 之前 一直 以为 只是 易用性 上 的 差别 ， 没想到 还有 一个 神 坑 。 事情 经过 今天 发现 应用 崩 了 ， 查 日志 发现 是 接收 到 了 一个 Sat Jan 01 00:00:00 +0800 0001 这样 的 时间 ， 当 我 用 LocalDateTime.parse('Sat Jan 01 00:00:00 +0800 0001', DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss Z yyyy\")); 来 解析 的 时候 报 了 这样 一个 错 java.time.format.DateTimeParseException: Text 'Sat Jan 01 00:00:00 +0800 0001' could not be parsed: Conflict found: Field DayOfWeek 1 differs from DayOfWeek 6 derived from 0001-01-01\tat java.time.format.DateTimeFormatter.createError(DateTimeFormatter.java:1920) ~[?:1.8.0_231]\tat java.time.format.DateTimeFormatter.parse(DateTimeFormatter.java:1855) ~[?:1.8.0_231]\tat java.time.LocalDateTime.parse(LocalDateTime.java:492) ~[?:1.8.0_231] 看起来 像是 星期一 和 星期六 有 冲突 ， 然后 我 就 去 百度 公元 0001 年  1  月  1  日 到底 是 星期 几 ， 得到 的 答案 有 的 说 是 星期一 ， 有 的 说 是 星期六 ， 当然 是 找 不到 这样 一个 日历 的 ， 网上 能 找到 的 日历 最 多 也 就 到  1900  年 ， 这 就 勾起 了 我 的 兴趣 ， 于是 在 想 这个 日期 肯定 不是 人为 填写 的 ， 那么 就 只能 是因为 生成 这个 时间 的 方法 和 我 现在 用 的 解析 这个 时间 的 方法 有 出入 。 业务 方 很早 之前 就 开始 用  Java  了 ， 而 我们 是 最近 刚 开始 用 ， 所以 他们 即便 可能 现在 用 的 是  Java8， 里面 的 很多 写法 应该 还是 保留 了 更 早 的 方式 ， 所以 我 就 验证 了 一下 这个 日期 package fun.happyhacker.springbootdemo;import java.time.LocalDate;import java.time.Month;import java.util.Calendar;import java.util.Date;import java.util.GregorianCalendar;public class DateTest {    public static void main(String[] args) {        Date birthDay = new GregorianCalendar(1, Calendar.JANUARY, 1).getTime();        System.out.println(birthDay);        LocalDate birthDay1 = LocalDate.of(1, Month.JANUARY, 1);        System.out.println(birthDay1.getDayOfWeek());    }} 执行 一下 ， 神奇 的 事情 发生 了 Sat Jan 01 00:00:00 CST 1MONDAY 也就是说 在 GregorianCalendar 认为 这天 是 星期六 ， 而 LocalDateTime 认为 这天 是 星期一 。 总结 从 这件 事儿 得出 的 结论 就是 ， 从  JDK7  升级 到  JDK8  的 过程 中 ， 不光 要 注意 什么 语法 的 问题 ， 说不定 还 会 出现 这种 历史 遗留问题 。 虽然 这个 日期 比较 特殊 ， 但 保不齐 还有 其他 的 特殊 情况 。","title":"Java 日期 函数 的 一个 坑 ","oriTitle":"Java日期函数的一个坑","categories":["theory"],"date":"2021-01-21T08:33:43.000Z"},{"uri":"/post/java/history-of-log-for-java","tags":["java","log","log4j","logback","log4j2","slf4j"],"content":"Java 日志 真是 一个 过于 复杂 的 问题 了 ， 花 了 大量 的 时间 在 这个 本 不 应该 花 时间 的 地方 。 开篇 据说 上古 时期 Java 标准 库内 并 没有 日志 类 ， 所以 社区 就 搞 出来 了 log4j， 后来 Apache 想着 把 log4j 合并 到 JDK 中 去 ， 但 这 Java 官方 肯定 不想 让 别人 制定 标准 而 自己 做 别人 标准 的 遵守 者 ， 所以 就 搞 了 java.util.logging， 后来 就 越发 混乱 了 ，Apache 就 又 搞了个 Commons Logging， 这 应该 就是 最早 的 “ 日志 门面 ” 了 ， 它 和 后来 的 slf4j 解决 的 问题 是 一样 的 。 想象 一下 这个 场景 ， 你 的 项目 依赖 了 两个 包 ， 其中 一个 依赖 log4j， 另外 一个 依赖 jul， 但 很 显然 你 是 想 把 项目 中 所有 日志 放在 一起 管理 的 ， 如果 没有 一个 统一 的 框架 去 管理 ， 是 很 难 维护 一个 大型项目 的 。 问题 初现 那么 问题 来 了 ， 历史 原因 ， 别人 的 包 就是 不想 换 日志 框架 ， 那 不能 改变 别人 就 只能 改变 自己 了 ， 所以 我们 有 2 个 选择 ： 把 这 两个 实现 选 一个 作为 真正 的 实现 ， 通过 某种 方式 将 另 一个 日志 框架 的 调用 转发 到 这个 真正 的 实现 上 这 两个 我 谁 都 不用 ， 我 要 用 第三个 ， 所有 第三方 的 库 写 的 日志 都 转发 到 我 自己 用 的 这个 日志 框架 上 这 就是 所谓 的 bridge 了 ， 具体来说 如下 package fun.happyhacker;import java.util.logging.Logger;public class JULTest {    private static final Logger LOG = Logger.getLogger(JULTest.class.getCanonicalName());    public static void main(String[] args) {        log();    }    public static void log() {        LOG.info(\"hello log from JUL\");    }}package fun.happyhacker;import org.apache.log4j.Logger;public class Log4jTest {    private static final Logger LOG = Logger.getLogger(Log4jTest.class);    public static void main(String[] args) {        log();    }    public static void log() {        LOG.info(\"hello log from log4j\");    }} 神奇 的 桥接 据说 jul 的 性能 比较 差 ， 我 不想 用 ， 那么 就 需要 把 所有 对 它 的 调用 转发 到 log4j 上 ， 但 实际上 没有 所谓 的 jul-to-log4j ， 但 我们 可以 用 jul-to-slf4j， 然后 再 把 slf4j 的 实现 绑定 到 log4j， 问题 开始 变得复杂 了 。 简单 画 一下 就 现在 的 例子 来说 ， 加上             org.slf4j            slf4j-api            1.7.30            org.slf4j            jul-to-slf4j            1.7.30            org.slf4j            slf4j-log4j12            1.7.30 这些 依赖 再 执行 JULTest 类 ， 发现 还是 一样 的 结果 。。。。 这 是 怎么 回事儿 呢 。。。 原来 它 不能 自动 桥接 ， 还 需要 做 一些 改动 。 这里 我们 是 将 JULTest 作为 依赖 使用 的 ， 也 就是 假设 我们 不能 改变 它 的 源码 ， 所以 只能 改 我们 自己 的 应用 。 我们 的 应用 原本 是 这样 的 package fun.happyhacker;import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class App {    private static final Logger LOG = LoggerFactory.getLogger(App.class);    public static void main(String[] args) {        JULTest.log();    }} 执行 的 结果 如下 还 需要 改成 这样 package fun.happyhacker;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.slf4j.bridge.SLF4JBridgeHandler;import java.util.logging.LogManager;public class App {    private static final Logger LOG = LoggerFactory.getLogger(App.class);    static {        LogManager.getLogManager().reset();        SLF4JBridgeHandler.install();    }    public static void main(String[] args) {        JULTest.log();    }} 官方 文档 专门 强调 了 一点 ，jul 到 slf4j 是 有 很大 的 性能 损失 的 （ 本来 jul 的 性能 就 差 ， 这么 一 搞 就 更 差 了 ） 因为 其他 的 日志 框架 到 slf4j 的 桥接 都 是 通过 重新 实现 相应 的 接口 来 完成 的 ， 但 因为 双亲 委派 机制 的 限制 ， 我们 是 无法 重新 实现 java.util.logging 中 的 接口 的 ， 所以 实际 它 是 把 jul 中 的 LogRecord 替换成 了 slf4j 中 的 等价 对象 ， 这 层 转换 在 日志 这个 本 不 应该 消耗 太 多 资源 的 场景 下 就 消耗 了 太 多 的 资源 。 好消息 是 并 没有 太 多 的 应用 使用 jul。 所以 啊 ， 即便 你 是 官方 的 实现 ， 也 不 一定 那么 受欢迎 。 延伸 多数 情况 可能 是 要 用 log4j-over-slf4j 来 将 对 log4j 的 直接 调用 转调 到 slf4j-api 上 ， 然后 再 通过 其他 的 日志 框架 ， 比如 logback 来 写 日志 。 这里 可以 简单 的 追踪 以下 调用 过程 。package fun.happyhacker;import org.apache.log4j.Logger;public class Log4jTest {    private static final Logger LOG = Logger.getLogger(Log4jTest.class);    public static void main(String[] args) {        LOG.info(\"hello from log4j\");    }} 配合 相应 的 log4j.properties 就 能 有 相应 的 输出 。 那么 如果 我 不想 改 这块 代码 ， 而 想 让 它 直接 通过 logback 输出 ， 就 需要 引入 另外 两个 依赖       ch.qos.logback      logback-classic      1.2.3      org.slf4j      log4j-over-slf4j      1.7.25 这时 在 上述 代码 的 第 9 行 打 个 断点 进入 debug 模式 ， 走 到 第一步 Category.java， 就 会 发现 上面 会 有 一个 提示 ， 如图所示 但 当 你 真的 选 了 第二个 源码 文件 的 时候 它 又会有 另 一个 提示 这 说明 它 在 执行 的 时候 还是 用 的 log4j 包 中 的 class 文件 ， 而 不是 log4j-over-slf4j。 这时候 把 依赖 中 的 log4j 去掉 （ 实际 项目 中 应该 是 exclude 掉 ）。 再次 执行 就 会 发现 没有 这个 提示 了 ， 取而代之 的 是 代码 的 调用 直接 进入 了 log4j-over-slf4j 中 的 ， 打开 这个 包 的 源码 你 就 会 发现 它 的 包 结构 和 log4j 是 一致 的 所以 其实 就是 用 log4j-over-slf4j 中 的 类 “ 偷偷 ” 的 替换 了 log4j 中 的 类 ， 其实 已经 变成 了 基于 slf4j 中 的 实现 。 更 实际 的 情况 上面 讲述 的 这种 情况 很少 见 ， 但 更 常见 的 是 什么 呢 ？ 其中 一个 就是 配置 Spymemcached 的 日志 级别 。 更 复杂 的 场景 在 下面 。SpringBoot 可能 是 现在 最 常见 的 应用 类型 了 ， 我们 知道 它 默认 的 日志 框架 是 logback。  而 我 这里 还有 一个 基于 Flink 的 应用 ， 二者 要 复用 一部分 代码 ， 也就是说 需要 在 Flink 应用 里 创建 一个 Spring 容器 。Spring 用 的 是 logback，Flink 用 的 是 log4j， 又 需要 在 二者 中 选择 一个 了 。 但 这个 问题 其实 又 没有 那么 复杂 ， 因为 他们 其实 都 是 通过 slf4j 写 日志 的 ， 也就是说 我们 没有 log4j-to-slf4j 或者 logback-to-slf4j 这种 转换 ， 而 只 需要 选择 一个 实现 即可 。 正常 使用 logback 的 应用 会 引入 logback-classic 包 ， 它 提供 了 slf4j-api 和 log4j-over-slf4j 等 依赖 ， 所以 当 logback-classic 和 slf4j-log4j12 同时 存在 时 就 会 出现 下面 的 报错 也就是说 现在 classpath 中 存在 了 两个 LoggerFactoryBinder 的 实现 ， 我们 要 做 的 就是 把 它们 中 的 屏蔽 一个 。 比如 如果 你 不想 用 logback， 只 需要 在 spring 相关 依赖 中 添加             org.springframework.boot            spring-boot-starter-web            2.3.1.RELEASE                    ch.qos.logback                    logback-classic 相应 的 ， 如果 要 用 logback 而 不是 log4j， 就 把 slf4j-log4j12 排除 即可 。 一点 提示 前面 我们 说 到 了 ， 如果 想 把 直接 调用 log4j 的 请求 转发 到 slf4j-api 上 ， 再 根据 实际 情况 决定 最终 底层 用 哪个 日志 框架 。 而 slf4j-log4j12 就是 那个 决定 让 slf4j 使用 log4j 写 日志 的 包 ， 那么 如果 这 两个 包 同时 出现 又 会 怎么样 呢 ？            org.slf4j            slf4j-log4j12            1.7.30            org.slf4j            log4j-over-slf4j            1.7.30 再 执行 App， 就 会 像 下面 这样 崩溃 了 简单 说 就是 出现 了 死循环 ， 要 出现 栈 溢出 错误 了 。 道理 很 简单 ， 这里 不再 赘述 了 。 总结 这 篇 基本 就 把 Java 日志 里 出现 的 几种 情况 解释 清楚 了 。 下面 会 开 一篇 具体 说 说 这 几种 日志 框架 各自 的 配置 方式 。","title":"Java 日志 演化 梳理 ","oriTitle":"Java日志演化梳理","categories":["java"],"date":"2020-11-21T07:21:05.000Z"},{"uri":"/post/java/install-java-with-homebrew","tags":["jdk","homebrew","java"],"content":"Oracle JDK  现在 收费 了 ，macOS  上 安装 个  JDK  还 挺 麻烦 。TL；DR 简单 来讲 ， 可以 直接 运行 brew search openjdk 这样 搜索 出来 的 是  Oracle  发布 的  OpenJDK。 其中 openjdk 就是 最新 版本 的 ， 带 @ 的 就是 指定 版本 的 ， 其中  8  和  11  是  LTS  版本 ， 所以 可以 拥有 姓名 ， 至于 其他 的 短期 版本 ， 这里 就 干脆 也 没有 了 。AdoptOpenJDK 这个 名字 有点 长 ， 其实 是  Eclipse  基金会 在 维护 的 发行版 ， 它 和  Oracle OpenJDK  的 关系 有点 类似 于  MIUI  和  Andriod AOSP  的 关系 ， 功能 上 应该 是 一样 的 ， 不过 添加 了 一些 特色 的 功能 ， 如图所示 它 提供 了 不同 的 垃圾 收集器 和 所有 的 版本号 ， 社区 应该 也 比较 流行 吧 （ 好 吧 ， 其实 更 多 人 还是 会 去 下载  Oracle JDK， 只是 它 的 免费 的  JDK1.8  永远 的 停留 在 了 8u231）。 参考 这个 https://github.com/AdoptOpenJDK/homebrew-openjdk 强烈推荐 使用 这个 脚本 jdk() {        version=$1        export JAVAHOME=$(/usr/libexec/javahome -v\"$version\");        java -version } 可以 让你在 不同 版本 的  JDK  中 自由 切换 。","title":" 通过  homebrew  安装  JDK","oriTitle":"通过 homebrew 安装 JDK","categories":["java"],"date":"2021-01-14T08:28:04.000Z"},{"uri":"/post/java/jvm-class-loader","tags":["Java","JVM"],"content":" 刚 看 完 《Java 高 并发 编程 详解 —— 多线程 与 架构设计 》 的 第 10 章 ， 实验 一下 类似 Tomcat 的 热 加载 的 方法 。 这 一章 的 主要 内容 如下 图 背景 讲 到 基于 类 的 加载 和 卸载 来 实现 功能 热 更新 时 ， 我 就 想到 了 Tomcat 可以 检测 webapps 中 的 war 包 的 变化 来 重新 加载 新 的 应用 ， 所以 就 通过 本章 介绍 的 内容 扩展 一下 ， 自己 实现 一个 热 加载 功能 。 需求 当 指定 目录 下 的 class 文件 发生变化 时 ， 系统 能 及时 感知 并 重新 加载 。 实现 指定 一个 存放 class 文件 的 目录 ， 如 /tmp/classloader/ 在 其中 放 一个 class 文件 ， 如 Child.class， 开始 时 只有 一个 walk() 方法 系统 每隔 1 秒 中 检测 一次 该 目录 中 文件 是否 更新 ， 如果 更新 了 则 重新 加载 看 是否 可以 通过 反射 拿到 新 类 的 方法 列表 源码 package fun.happyhacker;import java.io.ByteArrayOutputStream;import java.io.IOException;import java.nio.file.Files;import java.nio.file.Path;import java.nio.file.Paths;public class MyClassLoader extends ClassLoader {    private static final Path CLASS_DIR = Paths.get(\"/tmp/classloader/\");    private final Path classDir;    public MyClassLoader() {        super();        this.classDir = CLASS_DIR;    }    public MyClassLoader(String classDir) {        this.classDir = Paths.get(classDir);    }    public MyClassLoader(ClassLoader parent) {        super(parent);        this.classDir = CLASS_DIR;    }    public MyClassLoader(ClassLoader parent, String classDir) {        super(parent);        this.classDir = Paths.get(classDir);    }    @Override    protected Class findClass(String name) throws ClassNotFoundException {        byte[] classBytes = this.readClassBytes(name);        if (classBytes.length == 0) {            throw new ClassNotFoundException(\"Can not load the class \" + name);        }        return this.defineClass(name, classBytes, 0, classBytes.length);    }    private byte[] readClassBytes(String name) throws ClassNotFoundException {        String classPath = name.replace(\".\", \"/\");        Path classFullPath = classDir.resolve(Paths.get(classPath + \".class\"));        if (!classFullPath.toFile().exists()) {            throw new ClassNotFoundException(\"The class \" + name + \" not found\");        }        try (ByteArrayOutputStream baos = new ByteArrayOutputStream()) {            Files.copy(classFullPath, baos);            return baos.toByteArray();        } catch (IOException e) {            throw new ClassNotFoundException(\"load the class \" + name + \" occur error.\", e);        }    }    @Override    public String toString() {        return \"MyClassLoader\";    }}package fun.happyhacker;import java.lang.reflect.InvocationTargetException;import java.lang.reflect.Method;import java.nio.file.Path;import java.nio.file.Paths;import java.util.concurrent.TimeUnit;public class Daemon {    private static final String CLASS_PATH = \"/tmp/classloader/\";    private static final String CLASS_NAME = \"a.b.c.Child\";    private static final int CHECK_INTERVAL = 5;    private long lastModified;    private ClassLoader classLoader;    private Class klass;    public static void main(String[] args) throws InterruptedException, ClassNotFoundException, NoSuchMethodException, InvocationTargetException, InstantiationException, IllegalAccessException {        Daemon daemon = new Daemon();        daemon.listen();    }    private void run() throws ClassNotFoundException, IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException {        if (classLoader == null) {            classLoader = new MyClassLoader();        }        if (klass == null) {             klass = classLoader.loadClass(CLASS_NAME);        }        Class child = klass;        System.out.println(child.getClassLoader());        Object instance = child.newInstance();        System.out.println(instance);        Method[] methods = child.getDeclaredMethods();        for (Method method : methods) {            Method m = child.getMethod(method.getName());            m.invoke(instance);        }    }    private void listen() throws InterruptedException, ClassNotFoundException, NoSuchMethodException, InvocationTargetException, InstantiationException, IllegalAccessException {        while (true) {            Path classPath = Paths.get(CLASS_PATH);            Path classFullPath = classPath.resolve(Paths.get(CLASS_NAME.replace(\".\", \"/\") + \".class\"));            System.out.println(\"class path \" + classFullPath.toFile().getAbsolutePath());            long newLastModified = classFullPath.toFile().lastModified();            System.out.println(\"exists \" + classFullPath.toFile().exists());            System.out.println(\"new last modified: \" + newLastModified);            if (newLastModified > lastModified) {                reload();                run();            }            lastModified = newLastModified;            TimeUnit.SECONDS.sleep(CHECK_INTERVAL);        }    }    private void reload() {        classLoader = null;        klass = null;    }}package a.b.c;public class Child {    public void walk() {        System.out.println(\"I can walk\");    }    public void speak() {        System.out.println(\"I can talk\");    }    public void write() {        System.out.println(\"I can write\");    }} 在 /tmp/classloader/a/b/c 中 修改 Child.java， 修改 之后 执行 javac Child.java 会 引起 Child.class 文件 的 变化 ， 从而 触发 系统 自动 重新 加载 新 的 class 文件 ， 执行 新 的 方法 。 总结 对于 Tomcat 会 更 复杂 一些 ， 但 也 就是 把 加载 一个 单独 的 class 文件 升级成 加载 一个 war 包 ， 原理 是 一样 的 。 不过 我 不 太 理解 的 是 ， 为什么 Tomcat 不能 实现 热 更新 ， 也 就是 为什么 不能 像 Nginx 那样 有 一段时间 是 新 老 服务 共存 ， 等 已经 连接 到 老 的 服务 上 的 请求 完成 之后 再 停掉 老 服务 呢 ？ 这个 答案 只能 从 Tomcat 的 源码 中 寻找 了 。","title":"JVM 类 加载 器 ","oriTitle":"JVM类加载器","categories":["in-action"],"date":"2020-10-27T14:04:17.000Z"},{"uri":"/post/java/set-log-level-of-spymemcached","tags":["log4j","spymemcached"],"content":" 用 这个 net.spy.memcached 最 恶心 的 事情 就是 它 的 日志 了 ， 不管三七二十一 先 打印 一组 红色 的 INFO 级别 日志 。 之前 也 没有 研究 这个 原因 ， 最近 在 总结 日志 相关 的 坑 ， 就 把 这里 详细 看 了 一下 。 观察 现象 首先 是 这个 日志 是 红色 的 ，INFO 级别 ， 而且 在 log4j.properties 中 添加 log4j.logger.net.spy.memcached=ERROR, consolelog4j.logger.addivitity.*=false 是 不起作用 的 。 分析 原因 由于 之前 对 log4j 的 配置文件 也 不太熟悉 ， 所以 一直 想着 是 自己 的 配置文件 没有 写 对 导致 的 ， 而 忽略 了 其他 原因 。 昨天 弄 明白 了 如果 要 改变 某个 指定 的 包 的 日志 配置 就是 这样 做 ， 所以 就 确定 了 配置文件 没有 问题 。 那么 原因 就 只 可能 是 这个 包 记录 日志 根本 就 没有 用 log4j。 那 它 用 的 是 啥 呢 ？ 不想 翻 文档 就 只能 debug 了 。 首先 找到 记 日志 的 地方 ， 打 个 断点 ， 执行程序 ， 一步 一步 往 下 跟 ， 找到 这里 很 明显 具体 拿到 的 Logger 类 就是 在 这里 决定 的 了 ， 这 段 简单 来说 就是 如果 系统 没有 设置 net.spy.log.LoggerImpl 属性 ， 就 用 默认 的 DefaultLogger， 实际上 跟 到 这里 确实 也 发现 就是 没有 设置 这个 属性 ， 从而 className 拿到 的 是 个 空 ， 所以 也 就 没有 log4j 什么 事儿 了 。 改造 方案 既然 知道 了 问题 的 根源 ， 那么 我们 就 设置 一下 这个 属性 就行了 ， 它 是从 System.getProperty() 方法 获取 的 ， 那么 我们 就 从 System.setProperty() 方法 设置 它 。 那么 要 设置 成 什么 呢 ？ 打开 这个 net.spy.log 目录 ， 就 会 发现 它 提供 了 几个 默认 的 实现 很 明显 我们 要 找 的 就是 net.spy.memcached.compat.log.Log4jLogger， 所以 只 需要 在 程序 入口 加上 这 行 System.setProperty(\"net.spy.log.LoggerImpl\", \"net.spy.memcached.compat.log.Log4JLogger\");>  这个 很 可能 是 slf4j 这种 日志 门面 出现 之前 的 一种 自己 实现 的 方案 ， 而 slf4j-api/log4j-api 就是 解决 这个 问题 的 了 。 即可 。 加上 之后 再 运行 程序 就 会 发现 颜色 已经 和 其他 的 日志 一样 了 。 总结 只要 把 问题 回归 到 我们 会 的 问题 上 ， 后面 的 问题 就 很 容易 解决 了 ， 前面 已经 配置 了 log4j.properties， 所以 当然 也 就 可以 方便 的 控制 它 的 日志 级别 了 。","title":" 配置 Spymemcached 的 日志 级别 ","oriTitle":"配置Spymemcached的日志级别","categories":["in-action"],"date":"2020-11-21T06:14:29.000Z"},{"uri":"/post/java/springboot-database-config-with-shardingsphere","tags":["springboot","shardingsphere"],"content":" 我们 都 自称  CRUD boy  了 ， 没有 数据库 拿 什么  CRUD？ 实验 环境 简单 起 见 ， 我们 在 本地 搭建 一个  MySQL  服务 ， 使用 brew install mysql 即可 安装 ， 之后 通过 brew services start mysql 即可 启动  MySQL  服务 。 相应 的 还 可以 通过 brew services list 查看 运行 中 的 服务 ， 通过 brew services stop mysql 来 停止  mysql  服务 。 如果 是 首次 安装 还 需要 执行 mysqlsecureinstallation 来 初始化 密码 等 。 建 库 建 表 create database happyhacker;use happyhacker;create table employee (\tid int unsigned auto_increment primary key,\tname varchar(40) not null default '',\tage tinyint unsigned not null default 0) engine=innodb default charset=utf8mb4;JDBC 简单 来讲  JDBC  就是 一套 操作 数据库 的  API（interface）， 它 是 不 包含 实现 的 （implementation）。 各 数据库 供应商 （ 如  MySQL  等 ） 提供 驱动 （ 实现 ） 来 完成 对 数据库 的 操作 。JDBC  提供 了 两个 功能 ：JDBC API  提供  Java  应用 和  JDBC Manager  之间 的 通信 JDBC driver  提供 了  JDBC Manager  和 数据库 驱动 之间 的 通信 我们 先 来 感受一下 使用 原生 的  JDBC  怎样 操作 数据库 。 建立 连接 （Connection）Connection connection = DriverManager.getConnection(\"jdbc:mysql://127.0.0.1:3306/happyhacker\", \"root\", \"12345678\"); 创建 语句 （Statement）Statement stmt = connection.createStatement();String sql = \"select * from employee\"; 执行 语句 并 返回 结果 （ResultSet）ResultSet rs = stmt.executeQuery(sql); 对 结果 集 进行 迭代 取出 数据 while (rs.next()) {  int id = rs.getInt(\"id\");  String name = rs.getString(\"name\");  int age = rs.getInt(\"age\");\tSystem.out.printf(\"id: %d,\\t name: %s,\\t age: %d\\n\", id, name, age);} 关闭 连接 和 语句 stmt.close();connection.close(); 从 上面 的 例子 中 也 可以 看出 ， 通过  JDBC  对 数据库 的 操作 分为 以下 步骤 ： 建立 连接 （Connection） 建立 语句 （Statement） 执行 语句 并 返回 结果 （ResultSet） 对 结果 集 进行 迭代 取出 数据 下面 列出 的 完整 代码 包含 对 数据库 的 增删 改 查 package fun.happyhacker.springbootdemo;import java.sql.*;public class JDBCTest {    public static void main(String[] args) {        jdbcTest();    }    private static void jdbcTest() {        Connection connection = null;        Statement stmt = null;        try {            Class.forName(\"com.mysql.cj.jdbc.Driver\");            connection = DriverManager.getConnection(\"jdbc:mysql://127.0.0.1:3306/happyhacker\", \"root\", \"12345678\");            stmt = connection.createStatement();            String selectSql = \"select * from employee\";            ResultSet rs = stmt.executeQuery(selectSql);            while (rs.next()) {                int id = rs.getInt(\"id\");                String name = rs.getString(\"name\");                int age = rs.getInt(\"age\");                System.out.printf(\"id: %d,\\t name: %s,\\t age: %d\\n\", id, name, age);            }            String insertSql = \"insert into employee (name, age) values ('John', 13)\";            long effectedRows1 = stmt.executeUpdate(insertSql, new String[]{\"id\"});            if (effectedRows1 > 0) {                System.out.println(\"insert ok\");            } else {                System.out.println(\"insert failed\");            }            String updateSql = \"update employee set name = 'Tam' where id = 3\";            long effectedRows2 = stmt.executeUpdate(updateSql);            if (effectedRows2 > 0) {                System.out.println(\"update ok\");            } else {                System.out.println(\"update failed\");            }            String deleteSql = \"delete from employee where id = 5\";            long effectedRows3 = stmt.executeUpdate(deleteSql);            if (effectedRows3 > 0) {                System.out.println(\"delete ok\");            } else {                System.out.println(\"delete failed\");            }          \trs.close();            stmt.close();            connection.close();        } catch (SQLException e) {            e.printStackTrace();        } finally {            if (stmt != null) {                try {                    stmt.close();                } catch (SQLException throwables) {                    throwables.printStackTrace();                }            }            if (connection != null) {                try {                    connection.close();                } catch (SQLException throwables) {                    throwables.printStackTrace();                }            }        }    }} 不要 忘 了 需要 在 pom.xml 中 添加 如下 依赖   mysql  mysql-connector-java  8.0.20>  注意 其中 的 Class.forName(\"com.mysql.cj.jdbc.Driver\") 这 句 ， 老 的 文档 都 会 写 这 句 ， 但 其实 使用 新版 的  MySQL Driver  的话 这个 已经 不 需要 了 ， 因为 新 版本 有 这个 > 连接池 前面 我们 看到 Statement 和 Connection 都 是 可以 复用 的 ， 但 这 仅仅 局限 在 一个 方法 中 。 想 让 一个 连接 在 整个 应用 中 都 可用 ， 就要 把 它 做成 全局变量 。 最 简单 的 做法 就是 这样 package fun.happyhacker.springbootdemo.jdbc;import java.sql.Connection;import java.sql.DriverManager;import java.sql.SQLException;public class JDBCConnection {    public static Connection getConnection() throws SQLException {        return DriverManager.getConnection(\"jdbc:mysql://127.0.0.1:3306/happyhacker\", \"root\", \"12345678\");    }} 这样 在 需要 用 它 的 地方 直接 调用 JDBCConnection.getConnection() 就 可以 了 。 但 要 注意 用 完 之后 可 不要 调用 connection.close()， 因为 一旦  close  就 无法 再 被 别人 使用 了 。 再 往 下 需要 考虑 的 东西 就 很多 了 ， 比如 用 完 之后 不 立即  close， 那 什么 时候  close？ 一个 连接 用 多少 次  close？ 应用 高 并发 的 情况 下 不 可能 只用 一个 连接 ， 多个 连接 如何 保持 ？ 连接 异常 断开 后 如何 自动 重 连 ？ 想想 就 觉得 很 复杂 ， 好 在 这个 问题 已经 有 很 完善 的 解决方案 了 。 早前 比较 流行 的 有 Apache  的  DBCP， 老牌 的  C3P0， 打败 它们 俩 的  BoneCP， 后起之秀  Hikari CP 等等 ， 而  Hikari CP  得益于 其 优异 的 性能 傲视群雄 ， 目前 已经 是  Springboot  默认 的 连接池 框架 ， 搞 的  BoneCP  的 作者 都 公开 声称 不再 更新 了 ， 建议 大家 去 用  HikariCP。BoneCP  的  github  主页 介绍 只有 这样 一段 了 > # BoneCP>> BoneCP is a Java JDBC connection pool implementation that is tuned for high performance by minimizing lock contention to give greater throughput for your applications. It beats older connection pools such as C3P0 and DBCP but should now be considered deprecated in favour of HikariCP. 这 是 得 多 心灰意冷 啊 。 所以 我们 直接  HikariCP  就行了 。 对 了 还有 一个 国产 的 阿里 出品  Druid， 说实话 用 了 那么 多 开源 的 东西 之后 ， 对 阿里 家 开源 的 东西 还是 要 谨慎 一些 ， 这个 东西 文档 不 丰富 ， 用户 遇到 了 问题 反馈 了 得不到 回应 。 最 简单 的 数据库 配置 最 简单 的 配置 就是 使用  Springboot  内置 的 模板 配置 了 ， 使用 数据库 需要 引入 一个 依赖 即可             org.springframework.boot            spring-boot-starter-data-jdbc 引入 这个 依赖 就 不用 再 引用  HikariCP  了 。 然后 在 配置文件 中 加入 这些 spring.datasource.type=com.zaxxer.hikari.HikariDataSourcespring.datasource.hikari.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.hikari.username=rootspring.datasource.url=jdbc:mysql://localhost:3306/happyhackerspring.datasource.hikari.password=12345678 接下来 就 可以 直接 注入 DataSource 了 。package fun.happyhacker.springbootdemo.controller;import fun.happyhacker.springbootdemo.hikari.Employee;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import javax.sql.DataSource;import java.sql.Connection;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;import java.util.ArrayList;import java.util.List;@RestControllerpublic class EmployeeController {    @Autowired    private DataSource ds;    @GetMapping(\"/list\")    public String list() {        List employees = new ArrayList();        try (Connection connection = ds.getConnection();             PreparedStatement ps = connection.prepareStatement(\"select * from employee\");             ResultSet rs = ps.executeQuery();        ) {            Employee employee = new Employee();            while (rs.next()) {                employee.setId(rs.getInt(\"id\"));                employee.setName(rs.getString(\"name\"));                employee.setAge(rs.getInt(\"age\"));                employees.add(employee);            }        } catch (SQLException throwables) {            throwables.printStackTrace();        }        return employees.toString();    }} 这里 提 一个 小 问题 ， 访问 这个 接口 你 会 发现 你 的 响应 是 这样 的 [Employee(id=8, name=John, age=13), Employee(id=8, name=John, age=13), Employee(id=8, name=John, age=13), Employee(id=8, name=John, age=13), Employee(id=8, name=John, age=13), Employee(id=8, name=John, age=13), Employee(id=8, name=John, age=13)] 这 和 我们 理解 的  Json  是 有 区别 的 ， 更 多 信息 可以 参考 实现  toJson()  方法 JPA 和 MyBatisJPA 本质 就是 Hibernate， 是 一个 “ 轻量级 ” 的 ORM 框架 （ 至于 是不是 真的 轻量 ， 得 看 跟 谁 比 ）。 上 手 还是 非常简单 的 。JPA 入门 —— 增删 改 查 引入 依赖             org.springframework.boot            spring-boot-starter-data-jpa            mysql            mysql-connector-java            8.0.20 添加 配置  application.propertiesspring.datasource.type=com.zaxxer.hikari.HikariDataSourcespring.datasource.hikari.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.hikari.username=rootspring.datasource.url=jdbc:mysql://localhost:3306/happyhacker?charset=utf8mb4spring.datasource.hikari.password=12345678spring.jpa.database-platform=org.hibernate.dialect.MySQL5InnoDBDialectspring.jpa.show-sql=truespring.jpa.hibernate.ddl-auto=validate 创建 实体类 package fun.happyhacker.springbootdemo.jpa.entity;import lombok.Data;import javax.persistence.*;@Entity@Table(name = \"employee\")@Datapublic class Employee {    @Id    @GeneratedValue    private Long id;    @Column(length = 32)    private String name;    private Integer age;}>  注意 ： 上面 的 表 名 大小写 不 需 区分 ， 可以 全部 大写 创建 Repository 接口 package fun.happyhacker.springbootdemo.jpa.repository;import fun.happyhacker.springbootdemo.jpa.entity.Employee;import org.springframework.data.jpa.repository.JpaRepository;import org.springframework.stereotype.Repository;import java.util.List;@Repositorypublic interface EmployeeRepository extends JpaRepository {} 验证 功能 有 了 上面 这些 配置 ， 就 可以 体验 JPA 带给 你 的 强大 功能 了 。 先 看 在 Controller 类 中 测试 。package fun.happyhacker.springbootdemo.controller;import fun.happyhacker.springbootdemo.hikari.ExtensionMethods;import fun.happyhacker.springbootdemo.jpa.entity.Employee;import fun.happyhacker.springbootdemo.jpa.repository.EmployeeRepository;import lombok.experimental.ExtensionMethod;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestController@ExtensionMethod({ExtensionMethods.class})public class EmployeeController {    @Autowired    private EmployeeRepository employeeRepository;    @GetMapping(\"/list\")    public String list() {        Employee john = new Employee();        john.setAge(20);        john.setName(\"John\");        Employee lam = new Employee();        lam.setName(\"lam\");        lam.setAge(30);        employeeRepository.save(john);        employeeRepository.save(lam);        Employee first = employeeRepository.getOne(1L);        first.setName(\"happyhacker\");        employeeRepository.save(first);        employeeRepository.deleteById(2L);        return employeeRepository.findAll().toString();    }} 在 看 junit 中 的 测试 package fun.happyhacker.springbootdemo.jpa.repository;import fun.happyhacker.springbootdemo.jpa.entity.Employee;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import java.util.ArrayList;import java.util.List;import java.util.Optional;import static org.junit.jupiter.api.Assertions.assertEquals;import static org.junit.jupiter.api.Assertions.assertFalse;@SpringBootTestclass EmployeeRepositoryTest {    @Autowired    private EmployeeRepository employeeRepository;    @Test    void crud() {        Employee john = new Employee();        john.setAge(20);        john.setName(\"John\");        Employee lam = new Employee();        lam.setName(\"lam\");        lam.setAge(30);        Employee johnWithId = employeeRepository.save(john);        assertEquals(john.getName(), johnWithId.getName());        Employee lamWithId = employeeRepository.save(lam);        assertEquals(lam.getName(), lamWithId.getName());        lamWithId.setAge(45);        Employee oldLam = employeeRepository.save(lamWithId);        assertEquals(45, oldLam.getAge());        employeeRepository.delete(oldLam);        Optional employeeOptional = employeeRepository.findById(2L);        assertFalse(employeeOptional.isPresent());        List list = employeeRepository.findAll();        List expected = new ArrayList();        expected.add(johnWithId);        assertEquals(expected, list);    }}JPA 处理 联合 主键 JPA 处理 联合 主键 主要 有 两种 方式 ， 用法 有 区别 ， 最终 生成 的 SQL 语句 也 有 区别 ， 具体 用 哪 种 方式 主要 看 场景 。 在 典型 的 RBAC 权限 控制系统 中 会 有 很多 联合 主键 的 情况 ， 下面 来 取 一个 简单 的 例子 说明 。Role 是 角色 ， 包含 idRoleAccount 是 角色 和 员工 的 映射 ， 其中 包含 roleId 和 accountId@IdClasspackage fun.happyhacker.springbootdemo.jpa.idclass.entity;import lombok.Data;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;@Entity@Datapublic class Role {    @Id    @GeneratedValue    private Integer id;    private String name;}package fun.happyhacker.springbootdemo.jpa.idclass.entity;import lombok.Data;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;@Entity@Datapublic class Account {    @Id    @GeneratedValue    private Integer id;    private String name;    private Integer age;}package fun.happyhacker.springbootdemo.jpa.idclass.entity;import lombok.Data;import javax.persistence.Entity;import javax.persistence.Id;import javax.persistence.IdClass;@Entity@Data@IdClass(RoleAccountId.class)public class RoleAccount {    @Id    private Integer roleId;    @Id    private Integer accountId;}package fun.happyhacker.springbootdemo.jpa.idclass.entity;import lombok.Data;import java.io.Serializable;@Datapublic class RoleAccountId implements Serializable {    private Integer roleId;    private Integer accountId;}>  注意 ： 联合 主键 类 需要 实现 Serializable 接口 package fun.happyhacker.springbootdemo.jpa.idclass.repository;import fun.happyhacker.springbootdemo.jpa.idclass.entity.RoleAccount;import fun.happyhacker.springbootdemo.jpa.idclass.entity.RoleAccountId;import org.springframework.data.jpa.repository.JpaRepository;public interface RoleAccountRepository extends JpaRepository {}package fun.happyhacker.springbootdemo.jpa.idclass.repository;import fun.happyhacker.springbootdemo.jpa.idclass.entity.Role;import org.springframework.data.jpa.repository.JpaRepository;public interface RoleRepository extends JpaRepository {}package fun.happyhacker.springbootdemo.jpa.idclass.repository;import fun.happyhacker.springbootdemo.jpa.idclass.entity.Account;import org.springframework.data.jpa.repository.JpaRepository;public interface AccountRepository extends JpaRepository {} 下面 是 单元测试 package fun.happyhacker.springbootdemo.jpa.idclass.repository;import fun.happyhacker.springbootdemo.jpa.idclass.entity.Account;import fun.happyhacker.springbootdemo.jpa.idclass.entity.Role;import fun.happyhacker.springbootdemo.jpa.idclass.entity.RoleAccount;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;@SpringBootTestclass RoleAccountRepositoryTest {    @Autowired    private RoleRepository roleRepository;    @Autowired    private AccountRepository accountRepository;    @Autowired    private RoleAccountRepository roleAccountRepository;    @Test    void idClassTest() {        Role admin = new Role();        admin.setId(1);        admin.setName(\"admin\");        Role role1 = new Role();        role1.setId(2);        role1.setName(\"role1\");        Role role2 = new Role();        role2.setId(3);        role2.setName(\"role2\");        roleRepository.save(admin);        roleRepository.save(role1);        roleRepository.save(role2);        Account john = new Account();        john.setAge(30);        john.setName(\"john\");        john.setId(4);        accountRepository.save(john);        RoleAccount roleAccount = new RoleAccount();        roleAccount.setRoleId(admin.getId());        roleAccount.setAccountId(john.getId());        roleAccountRepository.save(roleAccount);    }}@Embeddable 和 @EmbeddedId 和 上面 相同 的 代码 就 再 贴 了 ， 只 贴 不同 的 文件 。package fun.happyhacker.springbootdemo.jpa.embeddable.entity;import lombok.Data;import javax.persistence.EmbeddedId;import javax.persistence.Entity;@Entity@Datapublic class RoleAccount {    @EmbeddedId    private RoleAccountId roleAccountId;}package fun.happyhacker.springbootdemo.jpa.embeddable.entity;import lombok.Data;import javax.persistence.Embeddable;import java.io.Serializable;@Data@Embeddablepublic class RoleAccountId implements Serializable {    private Integer roleId;    private Integer accountId;}package fun.happyhacker.springbootdemo.jpa.embeddable.repository;import fun.happyhacker.springbootdemo.jpa.embeddable.entity.Account;import fun.happyhacker.springbootdemo.jpa.embeddable.entity.Role;import fun.happyhacker.springbootdemo.jpa.embeddable.entity.RoleAccount;import fun.happyhacker.springbootdemo.jpa.embeddable.entity.RoleAccountId;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;@SpringBootTestclass RoleAccountRepositoryTest {    @Autowired    private RoleRepository roleRepository;    @Autowired    private AccountRepository accountRepository;    @Autowired    private RoleAccountRepository roleAccountRepository;    @Test    void idClassTest() {        Role admin = new Role();        admin.setId(1);        admin.setName(\"admin\");        Role role1 = new Role();        role1.setId(2);        role1.setName(\"role1\");        Role role2 = new Role();        role2.setId(3);        role2.setName(\"role2\");        roleRepository.save(admin);        roleRepository.save(role1);        roleRepository.save(role2);        Account john = new Account();        john.setAge(30);        john.setName(\"john\");        john.setId(4);        accountRepository.save(john);        RoleAccount roleAccount = new RoleAccount();        RoleAccountId roleAccountId = new RoleAccountId();        roleAccountId.setRoleId(admin.getId());        roleAccountId.setAccountId(john.getId());        roleAccount.setRoleAccountId(roleAccountId);        roleAccountRepository.save(roleAccount);    }} 小结 从 上面 的 比较 可以 看出 ， 最终 使用 的 时候 差别 不 大 ， 都 可以 对 联合 主键 进行 很 好 的 控制 。 区别 在于 ， 如果 RoleAccountId 类 是从 别人 的 jar 包 中 引用 的 ， 你 无法 修改 其中 的 内容 ， 那么 就 无法 添加 @Embeddable 注解 ， 而 这时候 用 @IdClass 就 比较简单 了 。 除此之外 的 其他 情况 ， 我 认为 使用 @Embeddable 会 更 清楚 一些 。MyBatis—— 基础 用法 MyBatis 是 面向 数据表 的 ， 而 JPA（Hibernate） 则 是 面向 领域 对象 的 ， 前者 更 接近 数据库 ， 而 后者 更 接近 业务 。JPA 的 JpaRepository 提供 了 非常 多 的 内置 方法 ， 但 面对 国内 互联网 公司 灵活 多变 的 需求 ， 这些 内置 方法 还是 不够 多 。 这 也 是 为什么 MyBatis 在 国内 比较 流行 的 原因 ， 据 我 了解 很多 人 在 用 国内 的 一个 封装 ——MyBatis-Plus。 同时 ， 在 做 这个 datalink 项目 的 过程 中 ， 我 也 越来越 发现 现在 这种 方式 的 弊端 （ 复杂 、 添加 schema 需要 做 的 事情 太 多 等等 ）， 所以 以下 的 MyBatis 的 例子 我们 就 使用 MyBatis-Plus 替代 。 引入 依赖             com.baomidou            mybatis-plus-boot-starter            3.4.2 创建 表 DROP TABLE IF EXISTS user;CREATE TABLE user(\tid BIGINT(20) NOT NULL COMMENT ' 主键 ID',\tname VARCHAR(30) NULL DEFAULT NULL COMMENT ' 姓名 ',\tage INT(11) NULL DEFAULT NULL COMMENT ' 年龄 ',\temail VARCHAR(50) NULL DEFAULT NULL COMMENT ' 邮箱 ',\tPRIMARY KEY (id)); 填充 数据 INSERT INTO user (id, name, age, email) VALUES(1, 'Jone', 18, 'test1@baomidou.com'),(2, 'Jack', 20, 'test2@baomidou.com'),(3, 'Tom', 28, 'test3@baomidou.com'),(4, 'Sandy', 21, 'test4@baomidou.com'),(5, 'Billie', 24, 'test5@baomidou.com');>  如果 你 自己 测试 用 内存 数据库 h2， 这些 sql 就 不 需要 提前 执行 ， 只 需要 把 建 表 语句 schema.sql 和 数据 语句 data.sql 放在 resource 目录 下 ， 添加 以下 两行 配置 即可 >> > spring.datasource.schema=classpath:database/h2/schema.sql> spring.datasource.data=classpath:database/h2/data.sql> 添加 配置 spring.datasource.url=jdbc:mysql://localhost:3306/happyhacker?charset=utf8mb4spring.datasource.hikari.username=rootspring.datasource.hikari.password=12345678 创建 实体类 package fun.happyhacker.springbootdemo.mybatis.entity;import lombok.Data;@Datapublic class User {    private Long id;    private String name;    private Integer age;    private String email;} 创建 Mapperpackage fun.happyhacker.springbootdemo.mybatis.mapper;import fun.happyhacker.springbootdemo.mybatis.entity.User;import org.apache.ibatis.annotations.Mapper;@Mapperpublic interface UserMapper {} 添加 方法 接下来 就 可以 在 UserMapper 类 中 添加 增删 改 查 的 方法 了 。 在 UserMapper.java 中 添加 相关 方法 package fun.happyhacker.springbootdemo.mybatis.mapper;import fun.happyhacker.springbootdemo.mybatis.entity.User;import org.apache.ibatis.annotations.Mapper;@Mapperpublic interface UserMapper extends BaseMapper {    List queryByNameEquals(String userName);} 在 resources/fun/happyhacker/springbootdemo/mybatis/mapper 中 添加 UserMapper.xml， 内容 如下         SELECT * FROM user WHERE name = #{userName, jdbcType=VARCHAR}>  注意 ：UserMapper.xml 和 UserMapper.java 所在 的 包 名 一定 要 相同 。 这样 就 可以 以 同样 的 方式 调用 userMapper.queryByNameEquals(name) 方法 了 。 单元测试 package fun.happyhacker.springbootdemo.mybatis.mapper;import fun.happyhacker.springbootdemo.mybatis.entity.User;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import java.util.List;import static org.junit.jupiter.api.Assertions.assertEquals;@SpringBootTestclass UserMapperTest {    @Autowired    private UserMapper userMapper;    @Test    void testSelect() {        List userList = userMapper.queryByNameEquals(\"Jone\");        assertEquals(1, userList.size());    }}>  如果 不想 在 每个 xxxMapper 上面 写 @Mapper 注解 ， 可以 在 启动 类 上 加 @MapperScan(\"fun.happyhacker.springbootdemo.mybatis.mapper\")， 让 系统 自动 扫描 MyBatis——MyBatis-Plus 上 节 虽然 用 的 是 MyBatis-Plus， 但 并 没有 用到 任何 它 独有 的 特性 ， 下面 来 介绍 一下 。 内置 方法 前面 我们 自己 写 了 一个     List queryByNameEquals(String userName);， 但 实际上 这种 增删 改 查 的 方法 已经 内置在 BaseMapper 中 了 ， 多数 时候 我们 只 需要 让 UserMapper 扩展 BaseMapper 即可 。 代码生成 这个 和 原生 MyBatis 的 代码生成 功能 差不多 ， 多出 的 功能 在于 它 能 生成 controller、service 层 的 代码 ， 虽然 都 是 空 的 。 而且 能 生成 带 lombok 的 的 代码 。>  这 一点 其实 和 国外 团队 的 思路 是 不同 的 ， 他们 可能 更 多 的 考虑 职责 分离 ， 克制 的 加入 带有 个人 主观 偏好 的 功能 ， 但 国人 开发 的 MyBatis-Plus 则 不同 ， 更 多 从 实际 开发 角度 出发 考虑 问题 ， 而 不 太 关注 设计模式 。 这 也 很 像 诸多 的 Android 定制 版 ， 国内 的 各种 定制 版 你 可能 说 它 臃肿 、 不 简洁 ， 但 你 不能 说 它 不好 用 。 添加 依赖             com.baomidou            mybatis-plus-generator            3.4.1 编写 CodeGenerator.javapackage fun.happyhacker.springbootdemo.mybatis;import com.baomidou.mybatisplus.core.exceptions.MybatisPlusException;import com.baomidou.mybatisplus.core.toolkit.StringUtils;import com.baomidou.mybatisplus.generator.AutoGenerator;import com.baomidou.mybatisplus.generator.config.DataSourceConfig;import com.baomidou.mybatisplus.generator.config.GlobalConfig;import com.baomidou.mybatisplus.generator.config.PackageConfig;import com.baomidou.mybatisplus.generator.config.StrategyConfig;import com.baomidou.mybatisplus.generator.config.rules.NamingStrategy;import java.util.Scanner;public class CodeGenerator {    public static void main(String[] args) {        AutoGenerator mpg = new AutoGenerator();        GlobalConfig gc = new GlobalConfig();        String projectPath = System.getProperty(\"user.dir\") + \"/springboot-demo\";        gc.setOutputDir(projectPath + \"/src/main/java\");        gc.setAuthor(\"happyhacker\");        gc.setOpen(false);        mpg.setGlobalConfig(gc);        DataSourceConfig dsc = new DataSourceConfig();        dsc.setUrl(\"jdbc:mysql://localhost:3306/happyhacker?charset=utf8mb4\");        dsc.setDriverName(\"com.mysql.cj.jdbc.Driver\");        dsc.setUsername(\"root\");        dsc.setPassword(\"12345678\");        mpg.setDataSource(dsc);        PackageConfig pc = new PackageConfig();        pc.setModuleName(scanner(\" 模块 名 \"));        pc.setParent(\"fun.happyhacker.mybatis\");        mpg.setPackageInfo(pc);//        InjectionConfig cfg = new InjectionConfig() {//            @Override//            public void initMap() {////            }//        };//        String templatePath = \"/templates/mapper.xml.vm\";//        List focList = new ArrayList();//        focList.add(new FileOutConfig(templatePath) {//            @Override//            public String outputFile(TableInfo tableInfo) {//                return projectPath + \"/src/main/resources/mapper/\" + pc.getModuleName() + \"/\" + tableInfo.getEntityName() + \"Mapper\" + StringPool.DOT_XML;//            }//        });//        cfg.setFileOutConfigList(focList);//        mpg.setCfg(cfg);////        TemplateConfig templateConfig = new TemplateConfig();//        templateConfig.setXml(null);//        mpg.setTemplate(templateConfig);        StrategyConfig strategyConfig = new StrategyConfig();        strategyConfig.setNaming(NamingStrategy.underlinetocamel);        strategyConfig.setColumnNaming(NamingStrategy.underlinetocamel);//        strategyConfig.setSuperEntityClass(\" 父 类 Entity， 没有 可以 不用 设置 \");        strategyConfig.setEntityLombokModel(true);        strategyConfig.setRestControllerStyle(true);//        strategyConfig.setSuperControllerClass(\" 父 类 Controller， 没有 就 不用 设置 \");        strategyConfig.setSuperEntityColumns(\"id\");        strategyConfig.setTablePrefix(pc.getModuleName() + \"_\");        mpg.setStrategy(strategyConfig);        mpg.execute();    }    private static String scanner(String tip) {        Scanner scanner = new Scanner(System.in);        System.out.println(\" 请 输入  \" + tip + \"：\");        if (scanner.hasNext()) {            String ipt = scanner.next();            if (StringUtils.isNotBlank(ipt)) {                return ipt;            }        }        throw new MybatisPlusException(\" 请 输入 正确 的  \" + tip + \"！\");    }} 测试 就 不再 赘述 了 。 小结 数据库 方面 总的来说 有 JPA 和 MyBatis 两种 选择 ， 一般来说 国内 用 MyBatis 比较 多 ， 这 和 我们 在 设计 系统 时 先 从 数据库 开始 考虑 的 思维 方式 有 关系 ， 因为 JPA 更 适应 DDD（ 领域 驱动 设计 ） 的 开发方式 ， 而 这种 方式 在 我们 实际 项目 开发 中 几乎 不 存在 。 不过 在我看来 其实 MyBatis-Plus 提供 的 BaseMapper 和 JPA 提供 的 JpaRepository 作用 其实 差不多 ， 而且 后者 多数 时候 更好 用 。 虽说 我 个人 更 倾向 于 使用 JPA， 但 考虑 到 国内 用户 的 使用 习惯 和 招聘 难度 ， 加上 之前 项目选择 React 而 不是 Vue 引起 大部分 同事 的 抵触 ， 最终 还是 决定 使用 MyBatis。 实际 项目 中 的 数据库 配置 实际 的 项目 不会 像 上面 那样 简单 ， 需要 考虑 更 多 的 问题 多 数据库 实例 ， 肯定 就 不能 用 spring.datasource.type 这种 配置 了 主从 分离 得益于 dynamic-datasource， 我们 就 不用 再 费劲 的 自己 通过 代码 配置 数据源 和 主从 分离 了 ， 而是 简单 的 通过 增加 配置 即可 实现 。 回顾 首先 让 我们 来 回顾 一下 前面 的 经验 ， 要 实现 一个 简单 的 CRUD， 需要 如下 的 class/interfaceEntity -> UserMapper -> UserMapperService -> UserServiceServiceImpl -> UserServiceImpl 在 UserService 中 ， 可能 存在 List allUsers() 和 int createUser(User user) 两个 方法 ， 如下 package fun.happyhacker.springbootdemo.mybatis.service;import fun.happyhacker.springbootdemo.mybatis.entity.User;import java.util.List;public interface UserService {    List listAllUsers();    int createUser(User user);}package fun.happyhacker.springbootdemo.mybatis.service.impl;import com.baomidou.dynamic.datasource.annotation.DS;import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;import fun.happyhacker.springbootdemo.mybatis.entity.User;import fun.happyhacker.springbootdemo.mybatis.mapper.UserMapper;import fun.happyhacker.springbootdemo.mybatis.service.UserService;import org.springframework.stereotype.Service;import java.util.List;import java.util.Objects;@Servicepublic class UserServiceImpl extends ServiceImpl implements UserService {    @Override    @DS(\"account_slave\")    public List listAllUsers() {        QueryWrapper wrapper = new QueryWrapper();        wrapper.gt(\"id\", 0);        return baseMapper.selectList(wrapper);    }    @Override    @DS(\"account_master\")    public int createUser(User user) {        if (Objects.isNull(user)) {            return 0;        }        return baseMapper.insert(user);    }} 你 可能 已经 注意 到 了 这 里面 的 @DS 注解 ， 它 就是 用来 配置 主从 分离 的 。 要 实现 上述 的 功能 我们 需要 引入 以下 依赖             com.baomidou            dynamic-datasource-spring-boot-starter            3.3.1> dynamic-datasource 的 配置 比较 多 ， 用 yaml 写 会 更 方便 一些 添加 数据源 相关 的 配置 spring:  datasource:    dynamic:      hikari:        connection-timeout: 5000        leak-detection-threshold: 5000        max-lifetime: 30000      primary: account_master      strict: false      datasource:        account_master:          url: jdbc:mysql://192.168.99.101:3306/account          username: account          password: account!          driver-class-name: com.mysql.cj.jdbc.Driver        account_slave:          url: jdbc:mysql://192.168.99.101:3307/account          username: account_r          password: account!          driver-class-name: com.mysql.cj.jdbc.Driver 通过 这个 配置 ， 我们 可以 很 简单 的 配置 主从 分离 。 但 这个 方法 有 个 致命 的 问题 —— 分表 。 它 提供 了 一个 TableNameHandler 可以 用来 根据 传入 的 SQL 来 选择 相应 的 表 ， 看起来 很 美好 ， 但 实际上 很 难 实现 ， 看 下 代码 protected String changeTable(String sql) {        TableNameParser parser = new TableNameParser(sql);        List names = new ArrayList();        parser.accept(names::add);        StringBuilder builder = new StringBuilder();        int last = 0;        for (TableNameParser.SqlToken name : names) {            int start = name.getStart();            if (start != last) {                builder.append(sql, last, start);                String value = name.getValue();                TableNameHandler handler = tableNameHandlerMap.get(value);                if (handler != null) {                    builder.append(handler.dynamicTableName(sql, value));                } else {                    builder.append(value);                }            }            last = name.getEnd();        }        if (last != sql.length()) {            builder.append(sql.substring(last));        }        return builder.toString();    } 可以 看到 ， 它 提供 的 方法 是 接收 PreparedStatement 中 的 sql 部分 ， 通俗 点 说 就是 还 没有 替换 变量 的 SQL， 比如 我们 要 通过 其中 的 uid 字 段 以 uid%128 作为 表 名 的 后缀 ， 通过 这种 方式 就 很 难 实现 了 。 所以 下 一步 就要 祭 出 大 杀 器 Apache ShardingSphere， 它 提供 了 针对 分库 分表 的 一整套 解决方案 。 在 实际 应用 中 ， 我们 只 关心 ShardingSphere-JDBC 即可 。ShardingSphere-JDBC 在 开始 介绍 之前 ， 首先 设定 一个 场景 。 假设 我们 的 项目 是 要 处理 订单 ， 由于 订单 很多 ， 需要 不仅 要 分表 还要 分库 。 为了 简化 问题 ， 我们 就 分成 2 个 库 ， 每个 库 4 张 表 ， 每个 库 一 主 一 从 。orders0  主库 ， 包含 表 torders0, torders2, torders4, torders_8orders1  主库 ， 包含 表  torders1, torders3, torders5, torders_7slave0  从 库 ， 包含 表 torders0, torders2, torders4, torders_8slave1 从 库 ， 包含 表  torders1, torders3, torders5, torders_7 根据 userid 分库 ， 库 名 后缀 为 userid%2， 后缀 可 选 范围 为 0 和 1 根据 userid 分表 ， 表 名 后缀 为 userid%8， 后缀 可 选 范围 为 0-7 为了 演示 不 需要 分表 的 场景 ， 添加 一个 torderconfig 表 ， 位于 orders0 主库 和 orders0 从 库 启动 数据库 服务 version: \"3.3\"services:  db-3306:    image: mysql:latest    restart: always    ports:      \"3306:3306\"    volumes:      \"3306:/var/lib/mysql:rw\"    environment:      MYSQLALLOWEMPTY_PASSWORD: \"yes\"      MYSQLROOTPASSWORD: \"root\"  db-3307:    image: mysql:latest    restart: always    ports:      \"3307:3306\"    volumes:      \"3307:/var/lib/mysql:rw\"    environment:      MYSQLALLOWEMPTY_PASSWORD: \"yes\"      MYSQLROOTPASSWORD: \"root\"  db-3308:    image: mysql:latest    restart: always    ports:      \"3308:3306\"    volumes:      \"3308:/var/lib/mysql:rw\"    environment:      MYSQLALLOWEMPTY_PASSWORD: \"yes\"      MYSQLROOTPASSWORD: \"root\"  db-3309:    image: mysql:latest    restart: always    ports:      \"3309:3306\"    volumes:      \"3309:/var/lib/mysql:rw\"    environment:      MYSQLALLOWEMPTY_PASSWORD: \"yes\"      MYSQLROOTPASSWORD: \"root\"volumes:  \"3306\":  \"3307\":  \"3308\":  \"3309\": 使用 上面 的 docker-compose.yml 文件 ， 启动 数据库 服务 docker-compose up 得到 4 个 数据库 端口 。 对应 关系 如下 表 |  端口  |  库 名        |  主 / 从  || ---- | ---------- | ----- || 3306 | orders_0 |  主     || 3307 | orders_1 |  主     || 3308 | slave_0  |  从     || 3309 | slave_1  |  从     | 建 表 在 3306 和 3308 端口 执行 以下 SQL 语句 create database orders_0;use orders_0;SET NAMES utf8mb4;SET FOREIGNKEYCHECKS = 0;-- Table structure for torders0DROP TABLE IF EXISTS torders0;CREATE TABLE torders0 (                            id bigint(11) NOT NULL AUTO_INCREMENT COMMENT ' 订单 编号 ',                            user_id int(16) DEFAULT NULL COMMENT ' 用户 编号 ',                            PRIMARY KEY (id)) ENGINE=InnoDB AUTOINCREMENT=8 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4bin COMMENT=' 订单 表 ';-- Table structure for torders2DROP TABLE IF EXISTS torders2;CREATE TABLE torders2 (                            id bigint(11) NOT NULL AUTO_INCREMENT COMMENT ' 订单 编号 ',                            user_id int(16) DEFAULT NULL COMMENT ' 用户 编号 ',                            PRIMARY KEY (id)) ENGINE=InnoDB AUTOINCREMENT=8 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4bin COMMENT=' 订单 表 ';-- Table structure for torders4DROP TABLE IF EXISTS torders4;CREATE TABLE torders4 (                            id bigint(11) NOT NULL AUTO_INCREMENT COMMENT ' 订单 编号 ',                            user_id int(16) DEFAULT NULL COMMENT ' 用户 编号 ',                            PRIMARY KEY (id)) ENGINE=InnoDB AUTOINCREMENT=8 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4bin COMMENT=' 订单 表 ';-- Table structure for torders6DROP TABLE IF EXISTS torders6;CREATE TABLE torders6 (                            id bigint(11) NOT NULL AUTO_INCREMENT COMMENT ' 订单 编号 ',                            user_id int(16) DEFAULT NULL COMMENT ' 用户 编号 ',                            PRIMARY KEY (id)) ENGINE=InnoDB AUTOINCREMENT=8 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4bin COMMENT=' 订单 表 ';-- Table structure for order_configDROP TABLE IF EXISTS torderconfig;CREATE TABLE torderconfig (                                id int(11) NOT NULL AUTO_INCREMENT COMMENT ' 编号 ',                                pay_timeout int(11) DEFAULT NULL COMMENT ' 支付 超时 时间 ; 单位 ： 分钟 ',                                PRIMARY KEY (id)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin COMMENT=' 订单 配置 表 ';SET FOREIGNKEYCHECKS = 1; 在 3307 和 3309 端口 执行 以下 SQL 语句 create database orders_1;use orders_1;SET NAMES utf8mb4;SET FOREIGNKEYCHECKS = 0;-- Table structure for torders1DROP TABLE IF EXISTS torders1;CREATE TABLE torders1 (                            id bigint(11) NOT NULL AUTO_INCREMENT COMMENT ' 订单 编号 ',                            user_id int(16) DEFAULT NULL COMMENT ' 用户 编号 ',                            PRIMARY KEY (id)) ENGINE=InnoDB AUTOINCREMENT=400675304294580226 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4bin COMMENT=' 订单 表 ';-- Table structure for torders3DROP TABLE IF EXISTS torders3;CREATE TABLE torders3 (                            id bigint(11) NOT NULL AUTO_INCREMENT COMMENT ' 订单 编号 ',                            user_id int(16) DEFAULT NULL COMMENT ' 用户 编号 ',                            PRIMARY KEY (id)) ENGINE=InnoDB AUTOINCREMENT=8 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4bin COMMENT=' 订单 表 ';-- Table structure for torders5DROP TABLE IF EXISTS torders5;CREATE TABLE torders5 (                            id bigint(11) NOT NULL AUTO_INCREMENT COMMENT ' 订单 编号 ',                            user_id int(16) DEFAULT NULL COMMENT ' 用户 编号 ',                            PRIMARY KEY (id)) ENGINE=InnoDB AUTOINCREMENT=8 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4bin COMMENT=' 订单 表 ';-- Table structure for torders7DROP TABLE IF EXISTS torders7;CREATE TABLE torders7 (                            id bigint(11) NOT NULL AUTO_INCREMENT COMMENT ' 订单 编号 ',                            user_id int(16) DEFAULT NULL COMMENT ' 用户 编号 ',                            PRIMARY KEY (id)) ENGINE=InnoDB AUTOINCREMENT=8 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4bin COMMENT=' 订单 表 ';SET FOREIGNKEYCHECKS = 1; 配置 依赖             com.baomidou            mybatis-plus-boot-starter            3.4.2            org.apache.shardingsphere            sharding-jdbc-spring-boot-starter            4.1.1 编写 相应 的 POJOEntitypackage fun.happyhacker.springbootdemo.mybatis.orders.entity;import com.baomidou.mybatisplus.annotation.TableName;import lombok.Data;@Data@TableName(value = \"t_orders\")public class Order {    private Integer id;    private Integer userId;}package fun.happyhacker.springbootdemo.mybatis.orders.entity;import com.baomidou.mybatisplus.annotation.TableName;import lombok.Data;import java.time.LocalDateTime;@Data@TableName(value = \"torderconfig\")public class OrderConfig {    private Integer id;    private LocalDateTime pay_timeout;}Mapperpackage fun.happyhacker.springbootdemo.mybatis.orders.mapper;import com.baomidou.mybatisplus.core.mapper.BaseMapper;import fun.happyhacker.springbootdemo.mybatis.orders.entity.OrderConfig;import org.apache.ibatis.annotations.Mapper;@Mapperpublic interface OrderConfigMapper extends BaseMapper {}package fun.happyhacker.springbootdemo.mybatis.orders.mapper;import com.baomidou.mybatisplus.core.mapper.BaseMapper;import fun.happyhacker.springbootdemo.mybatis.orders.entity.Order;import org.apache.ibatis.annotations.Mapper;@Mapperpublic interface OrderMapper extends BaseMapper {    Order selectByUserId(Integer userId);}XML Mapper        select * from torders where userid = #{userId} order by id desc limit 1Service  和  ServiceImplpackage fun.happyhacker.springbootdemo.mybatis.orders.service;import com.baomidou.mybatisplus.extension.service.IService;import fun.happyhacker.springbootdemo.mybatis.orders.entity.OrderConfig;public interface OrderConfigService extends IService {}package fun.happyhacker.springbootdemo.mybatis.orders.service;import com.baomidou.mybatisplus.extension.service.IService;import fun.happyhacker.springbootdemo.mybatis.orders.entity.Order;import org.apache.ibatis.annotations.Param;public interface OrderService extends IService {    Order selectByUserId(@Param(\"userId\") Integer userId);    Order selectAndUpdate(@Param(\"userId\") Integer userId);}package fun.happyhacker.springbootdemo.mybatis.orders.service.impl;import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;import fun.happyhacker.springbootdemo.mybatis.orders.entity.OrderConfig;import fun.happyhacker.springbootdemo.mybatis.orders.mapper.OrderConfigMapper;import fun.happyhacker.springbootdemo.mybatis.orders.service.OrderConfigService;import org.springframework.stereotype.Service;@Servicepublic class OrderConfigServiceImpl extends ServiceImpl implements OrderConfigService {}package fun.happyhacker.springbootdemo.mybatis.orders.service.impl;import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;import fun.happyhacker.springbootdemo.mybatis.orders.entity.Order;import fun.happyhacker.springbootdemo.mybatis.orders.mapper.OrderMapper;import fun.happyhacker.springbootdemo.mybatis.orders.service.OrderService;import lombok.extern.log4j.Log4j2;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;@Service@Log4j2public class OrderServiceImpl extends ServiceImpl implements OrderService {    @Override    public Order selectByUserId(Integer userId) {        return baseMapper.selectByUserId(userId);    }    @Transactional    @Override    public Order selectAndUpdate(Integer userId) {        Order aOrder = new Order();        aOrder.setUserId(20);        baseMapper.insert(aOrder);        return baseMapper.selectByUserId(20);    }} 应用 配置 server:  port: 8080spring:  shardingsphere:    datasource:      names: master0, master1, slave0, slave1      master0:        type: com.zaxxer.hikari.HikariDataSource        driver-class-name: com.mysql.cj.jdbc.Driver        jdbcUrl: jdbc:mysql://192.168.99.101:3306/orders_0?charset=utf8mb4&allowPublicKeyRetrieval=true&useSSL=false        username: root        password: root      master1:        type: com.zaxxer.hikari.HikariDataSource        driver-class-name: com.mysql.cj.jdbc.Driver        jdbcUrl: jdbc:mysql://192.168.99.101:3307/orders_1?charset=utf8mb4&allowPublicKeyRetrieval=true&useSSL=false        username: root        password: root      slave0:        type: com.zaxxer.hikari.HikariDataSource        driver-class-name: com.mysql.cj.jdbc.Driver        jdbcUrl: jdbc:mysql://192.168.99.101:3308/orders_0?charset=utf8mb4&allowPublicKeyRetrieval=true&useSSL=false        username: root        password: root      slave1:        type: com.zaxxer.hikari.HikariDataSource        driver-class-name: com.mysql.cj.jdbc.Driver        jdbcUrl: jdbc:mysql://192.168.99.101:3309/orders_1?charset=utf8mb4&allowPublicKeyRetrieval=true&useSSL=false        username: root        password: root    sharding:      tables:        t_orders:          key-generator:            column: id            type: SNOWFLAKE          actual-data-nodes: ds0.torders$->{[0,2,4,6]}, ds1.torders$->{[1,3,5,7]}          table-strategy:            inline:              algorithm-expression: torders$->{user_id % 8}              sharding-column: user_id          database-strategy:            inline:              algorithm-expression: ds$->{user_id % 2}              sharding-column: user_id        torderconfig:          actual-data-nodes: ds0.torderconfig      master-slave-rules:        ds0:          master-data-source-name: master0          slave-data-source-names: slave0        ds1:          master-data-source-name: master1          slave-data-source-names: slave1      default-database-strategy:        inline:          sharding-column: user_id          algorithm-expression: master$->{user_id % 2}    props:      log:        show: true #  在 日志 中 打印 执行 过程       sql:        show: true #  打印 Logic SQL 和  Actual SQL， 非常 方便 排查 问题 mybatis-plus:  configuration:    map-underscore-to-camel-case: true #  类 属性 中 的 驼峰 字 段 到 数据库 中 的 下划线 字 段   global-config:    db-config:      id-type: none      logic-delete-value: 1      logic-not-delete-value: 0  mapper-locations: classpath:mapper/.xml #  搜索 resources/mapper/ 目录 下 的 XML 文件 作为 Mapper  type-aliases-package: fun.happyhacker.springbootdemo.mybatis.orders #  使 XML Mapper 中 可以 直接 使用 短 类 名 ， 而 不 需要 包 名 上面 的 配置文件 展示 了 需要 和 不 需要 分库 分表 的 情况 下 的 不同 配置 ， 理 清楚 之后 也 很 清晰 。 一定 要 注意 的 是 database-strategy 的 值 引用 的 是 spring.shardingsphere.datasource.names 中 的 值 ， 而 不是 实际 的 库 名 。*-strategy.algorithm-expression 是 Groovy 脚本 ， 本身 Apache ShardingSphere 支持 两种 写法 master${user_id % 2}master$->{user_id % 2} 但 第一种 方式 在 Spring 环境 中 会 被 认为 user_id % 2 是 一个 变量名 而 不是 表达式 ， 所以 在 Spring 环境 中 需要 使用 第二种 方式 。 事务 上面 的 代码 中 有 一个 方法 标记 了 @Transactional， 表明 是 支持 事务 的 。 在 本例 中 ， 插入 数据 之后 后面 的 方法 也 会 去 相应 的 主库 中 查找 对应 的 数据 而 不是 去 从 库 中 查 ， 你 可以 把 @Transactional 注解 移除 验证 一下 。 总结 关于 数据库 的 所有 内容 到 这里 就 结束 了 ， 我们 从 最 基础 的 JDBC 开始 学习 ， 了解 了 主流 的 JPA 和 MyBatis 的 基础 用法 ， 以及 在 使用 这些 框架 时 实际 遇到 的 问题 ， 后面 引入 了 MyBatis-Plus 来 消除 模板 代码 ， 使用 内置 的 方法 减少 代码 量 。 在 介绍 主从 分离 和 分库 分表 时 我们 遇到 了 挑战 ， 使用 Dynamic-Datasource 不能 解决问题 ， 因此 我们 引入 了 Apache ShardingSphere 来 解决 。 问 中 给出 了 非常 详细 的 代码 ， 希望 对 你 的 学习 有 帮助 。","title":"Springboot 使用 Shardingsphere 配置 数据库 ","oriTitle":"Springboot使用Shardingsphere配置数据库","categories":["in-action"],"date":"2021-02-04T14:43:50.000Z"},{"uri":"/post/java/to-string-implementation","tags":["java","json"],"content":"\bJava  中  POJO  的 toString() 方法 和 我们 预期 的  JSON  格式 不 符合 ， 而 如果 直接 覆盖 它 写 一个 生成  JSON  的 又 不 合适 ， 因为 当 需要 那种 格式 的 时候 就 没 得 用 的 ， 所以 本着 各司其职 的 原则 ， 我们 来 实现 一个 toJson() 方法 。 序列化 库 选择 我 比较 熟悉 的 就是  Jackson  和  Gson， 其中  Gson  的 使用 较为简单 ， 所以 这里 用  Gson  来 实现 。 其实 主要 原因 是  Jackson  在 序列化 对 向 的 时候 会 抛出 异常 ， 而  Gson  就 不会 。 这里 简单 验证 一下 。package fun.happyhacker.json;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import com.google.gson.Gson;public class JsonTest {    public static void main(String[] args) {        Employee employee = new Employee();        employee.setAge(10);        employee.setId(1);        employee.setName(\"John\");        ObjectMapper objectMapper = new ObjectMapper();        String jackson = \"\";        try {            jackson = objectMapper.writeValueAsString(employee);        } catch (JsonProcessingException e) {            e.printStackTrace();        }        System.out.println(jackson);        String gson = new Gson().toJson(employee);        System.out.println(gson);        System.out.println(new GsonBuilder().serializeNulls().create().toJson(employee));    }}{\"id\":1,\"name\":null,\"age\":10}{\"id\":1,\"age\":10}{\"id\":1,\"name\":null,\"age\":10} 所以 ， 起码 在 序列化  JSON  这方面 ， 可以 认为 两个 库 的 作用 是 一致 的 ， 但  Gson  用 起来 很 简单 。 给 每个  POJO  添加 toJson 方法 所以 是不是 就要 人 肉 给 每个  POJO  添加 这个 方法 了 ， 比如 上面 提到 的 Employeepackage fun.happyhacker.json;import com.google.gson.GsonBuilder;import lombok.Data;@Datapublic class Employee {    private int id;    private String name;    private int age;    public String toJson() {        return new GsonBuilder().serializeNulls().create().toJson(this);    }} 虽说 是 可行 ， 但 明显 有 太 多 了 模板 代码 可以 消除 了 。 利用  lombok 其实 这个 方法 我 都 是 在  lombok  相关 的 帖子 下 看到 的 ， 考虑 到 目前  lombok  并 没有 提供 类似 @ToJson 这种 注解 ， 那么 可以 利用 它 的 ExtensionMethod 来 实现 。 首先 创建 一个 扩展 方法 集 package fun.happyhacker.json;import com.google.gson.GsonBuilder;import java.io.Serializable;public class Extensions {    public static  String toJson(T t) {        return new GsonBuilder().serializeNulls().create().toJson(t);    }} 这 里面 我 加 了 一点 小 的 限制 ， 让 POJO  类 必须 要 可以 序列化 才能 使用 toJson() 方法 。 然后 在 需要 调用  toJson()  方法 的 所在 的 类 上 加上  @ExtensionMethod  注解 package fun.happyhacker.json;import lombok.experimental.ExtensionMethod;@ExtensionMethod({Extensions.class})public class JsonTest {    public static void main(String[] args) {        Employee employee = new Employee();        employee.setAge(10);        employee.setId(1);        employee.setName(\"John\");        System.out.println(employee.toJson());    }} 这时 你 会 发现  IDEA  识别 不了 这个 toJson() 方法 ， 但 没关系 ， 它 是 可以 正常 执行 的 ， 这 是  IDEA  的  lombok  扩展 不 支持 而已 。 在 这 一点 上  Eclipse  已经 领先 了 ， 虽然 在 其他 所有 方面  Eclipse  都 是 惨遭 碾压 。 简单 讲 就是  lombok  在 编译 期 把 employee.toJson() 这个 方法 改写 成 了 new GsonBuilder().serializeNulls().create().toJson(employee)， 这 也 解释 了 为什么 Extensions 中 的 方法 需要 是 静态 的 。 总结 虽说 是 解决 了 一部分 问题 ， 但 我 觉得 这个 问题 解决 的 不够 优雅 ， 按 我们 正常 的 思维 ， 这个 注解 是 应该 加 到 Employee 这个 类 上 的 ， 而 不是 加 到 调用 它 的 类 上 。 所以 就 很 尴尬 了 。 不 知道 能 不能 参与 到  lombok  官方 项目 中 ， 给 它 加上 这个 功能 。 经过 简单 的 搜索 发现 这个 问题 已经 被 讨论 过 无数遍 了 ， 核心 问题 是 核心 开发者 认为 这个 和 项目 设计 之 初 的 目标 不 符合 （ 我 觉得 这点 站不住脚 ）， 他们 拿 toString() 来 做 比较 ， 说 本来 每个 类 也 都 有 toString， 只是 没有 实现 ， 但 几乎 没有 类 存在 toJson 这个 方法 。 其实 本质 上 还是 因为 实现 起来 太 复杂 了 ， 没有 一个 轻量级 、 高性能 的  JSON  序列化 库 可以 用 ， 虽然  Jackson  和  Gson  都 可以 达成 目的 ， 但 他们 认为 都 太重 了 。 所以 这 已经 不是 技术 问题 了 ， 而是 哲学 问题 。 可能 这些 “ 库 ” 作者 压根 不能 理解 我们 应用 开发者 的 痛点 吧 。","title":" 实现  toJson()  方法 ","oriTitle":"实现 toJson() 方法","categories":["theory"],"date":"2021-01-21T09:53:05.000Z"},{"uri":"/post/java-basics","tags":["java"],"content":" 前段时间 写 Java 一直 忙于 做 工程 上 的 工作 ， 还是 得 停下来 看看 理论 的 东西 。 基本 类型 类型  |  存储 需求  |  取值 范围  |  备注 ---|---|---|---int | 4 Bytes | $-2^{31}$ ~ $2^{31}-1$short | 2 Bytes | $-2^{15}$ ~ $2^{15}-1$long | 8 Bytes | $-2^{63}$ ~ $2^{63}-1$byte | 1 Byte | $-2^7$ ~ $2^7-1$float | 4 Bytes |  大约  $3.40282347E+38F$（ 有效位数 6～7 位 ）|  只有 很少 场景 可以 用到 floatdouble | 8 Bytes |  大约  $1.79769313486231570E+308$（ 有效位数 15 位 ）|  带 小数点 的 默认 是 doublechar | - | | char 描述 了 UTF-16 编码 中 的 一个 代码 单元 ， 尽量 不要 使用 boolean | 1 bit | true  和  false | 位 运算 & and| or^ xor~ not 以 (n & 0b1000) / 0b1000 为 例 ， 如果 整数 n 的 二进制 表示 从左到右 第 4 位 是 1， 结果 就是 1， 其余 情况 则 为 0。 利用 & 并 结合 适当 的 2 的 幂 ， 可以 把 其他 位 mask 掉 ， 而 只 留下 其中 一位 。>> 和 >> 运算符 会 用 0 填充 高位 ， 这 与 >> 不同 ， 后者 用 符号 填充 高位 。 不 存在 ` \"If the virtual machine is started from an interactive command line without redirecting the standard input and output streams then its console will exist and will typically be connected to the keyboard and display from which the virtual machine was launched. If the virtual machine is started automatically, for example by a background job scheduler, then it will typically not have a console.\" 简单 说 就是 如果 它 是从 命令行 直接 启动 的 就 没 问题 ， 而 如果 是从 一个 【 后台 工作 调度 器 】， 其实 也 就是 IDEA 的 工作 线程 启动 的 ， 就 没有 console 了 。 所以 要 执行 带有 console 的 应用 ， 就 需要 javac App.java && java App 了 。 数组 Arrays 和 List 在 Java 中 是 不同 的 数据类型 （ 神奇 的 是 为什么 还有 一个 ArrayList）。。。Array 数组 表示 的 是 【 定 长 的 数组 ， 一旦 确定 了 长度 就 不能 再 改变 了 】， 而 List 列表 则 表示 可以 改变 长度 的 列表 。Array 的 创建 方式 有 很多 ， 如下 ：package fun.happyhacker.java.basics;import java.util.Arrays;public class Array {    public static void main(String[] args) {        //  总之 数组 就是 定 长 的 ， 要么 给定 长度 ， 要么 给定 元素 让 它 自己 计算长度         int[] a = new int[10];        int n = 100;        int[] b = new int[n];        int[] c = {1,2,3,4,};        int[] d = new int[]{1,2,3,4,};        //  还有 一点 需要 注意 ， 下面 的 e 和 f 两个 变量 会 共用 同一个 数组 ， 所以 改变 其中 一个 也 会 改变 另外 一个         int[] e = {1,2,3,4,};        int[] f = e;        f[2] = 5;        System.out.println(Arrays.toString(e));        System.out.println(Arrays.toString(f));        //  如果 要 拷贝 数组 ， 则 需要 用 Arrays.copy 方法         int[] g = {1,2,3,4,};        int[] h = Arrays.copyOf(g, g.length);        h[2] = 8;        System.out.println(Arrays.toString(g));        System.out.println(Arrays.toString(h));    }}`","title":"Java 基础 ","oriTitle":"Java基础","categories":["theory"],"date":"2020-04-21T15:28:34.000Z"},{"uri":"/post/java-localdatetime-timezone","tags":["java","timezone"],"content":" 用 Java 开发新 项目 ， 遇到 了 很多 之前 没 见 过 的 问题 ， 时 区 算是 第二 头疼 的 一个 。 现象 数据库 中 的 时间 是 2020-03-20 00:00:00， 但 查询 时 需要 2020-03-21 08:00:00 才能 查 到 。 这 明显 是 差 了 8 个 时 区 。 排查 过程 JDBC 连接 搜索 该 问题 ， 提到 的 最 多 的 就是 在 jdbc url 中 加上 时 区 的 配置 ， 应该 是 Asia/Shanghai 和 GMT+8( 注意 encode) 都行 ， 我 测试 的 时候 两种 都 没有 解决 我 的 问题 。serverTimezone=GMT%2B8 数据库 服务器 的 时间 到 数据库 服务器 执行 以下 命令 ， 得到 的 输出 如下 mysql> show variables like '%time_zone%';+------------------+--------+| Variable_name    | Value  |+------------------+--------+| systemtimezone | CST    || time_zone        | SYSTEM |+------------------+--------+ 测试环境 和 线 上 环境 都 是 这样 的 配置 ， 看起来 问题 应该 不是 出 在 这里 。 但 还是 要 提 以下 这个 容易 产生 混淆 的 地方 ，CST 这个 缩写 是 有 歧义 的 ， 起码 在 指 时 区 这 一件 事情 时 ， 就 有 多种不同 的 意思 但 其实 在 mysql 服务 的 时 区 这件 事 上 其实 是 没有 歧义 的 ， 就是指 UTC-6:00 的 中央标准 时间 。 服务器 本地 时间 和 容器 的 时间 由于 我 的 代码 是 在 docker 中 执行 的 ， 所以 其实 更 应该 关注 的 是 容器 中 的 时间 。 这时候 发现 了 容器 中 的 时间 和 宿主机 相差 了 8 小时 ， 猜测 问题 可能 是 由此 引起 的 。Java 的 LocalDateTime 因为 LocalDateTime 是 和 时 区 无关 的 时间 ，jvm 默认 它 就是 UTC 时间 ， 所以 传过来 的 2020-03-20 00:00:00 会 被 转换成 2020-03-19 16:00:00， 这 就是 最 上面 的 问题 的 答案 了 。 可以 通过 以下 方式 验证 import java.time.LocalDateTime;public class TimeZoneTest {    public static void main(String[] args) {        System.out.println(LocalDateTime.now());    }} 执行 javac TimeZoneTest.java && java -cp TimeZoneTest， 会 发现 和 预期 不 符合 ， 准确 的 说 是 比 当前 时间 慢 了 8 小时 。import java.time.LocalDateTime;import java.util.TimeZone;public class TimeZoneTest {    public static void main(String[] args) {        TimeZone tz = TimeZone.getTimeZone(\"GMT+8\");        TimeZone.setDefault(tz);        System.out.println(LocalDateTime.now());    }} 同样 执行 javac TimeZoneTest.java && java -cp TimeZoneTest， 就 会 发现 和 当前 时间 一致 了 。 解决方案 找到 了 问题 的 根本原因 ， 就 容易 解决 了 。Springboot@SpringBootApplicationpublic class WebApplication {    public static void main(String[] args) {        SpringApplication.run(WebApplication.class, args);    }    @PostConstruct    void setDefaultTimeZone() {        TimeZone.setDefault(TimeZone.getTimeZone(\"GMT+8\"));    }} 设定 Java 命令行 参数 java -Duser.timezone=GMT+8 TimeZoneTest 总结 我 最终 选择 的 是 在 jdbc url 中 添加 时 区 的 同时 ， 在 SpringBootApplication 中 设置 默认 时 区 ， 完美 的 解决 了 问题 。","title":"Java 时 区 问题 的 排查 和 分析 ","oriTitle":"Java时区问题的排查和分析","categories":["in-action"],"date":"2020-04-01T04:48:50.000Z"},{"uri":"/post/java-memory-leak-record","tags":["java","memory-leak"],"content":" 我们 用 Java 是 为了 让 它 自动 管理 内存 ， 然后 我 的 第一个 Java 项目 上线 就 面临 排查 线程 数 过 多 导致 无法 创建 新 线程 、 内存 泄漏 导致 机器 重启 各种 个 样 的 问题 。 这 和 我 原本 想象 的 可不 一样 。 最近 几天 比较忙 ， 排查 的 过程 没有 有效 的 记录下来 ， 但 其实 也 不 影响 最终 的 结果 ， 因为 并 不是 代码 的 问题 导致 的 内存 泄漏 ， 而是 docker 的 版本 问题 。 现象 描述 我 理解 的 内存 泄漏 应该 是 内存 的 缓慢 增长 ， 但 实际上 从 监控 曲线 看 ， 它 总是 每隔 几分钟 就 突增 一次 ， 每次 增加 的 量 大概 是 物理 机 内存 总量 的 15%， 所以 能 在 30 分钟 左右 就 耗尽 物理 机 的 内存 ， 最终 docker 进程 挂掉 ， 内存 释放 。 注意 ， 这里 的 现象 是 docker 服务 挂掉 ， 而 不是 运行 tomcat 的 容器 挂掉 。 这 是 一个 很 重要 的 信号 ， 也 是 在 最 早期 被 忽略 的 线索 。 同时 还 发现 ， 当 内存 占 用量 不停 升高 时 ， 重启 运行 tomcat 的 容器 并 不能 释放 内存 。 这 一点 很 反常规 ， 因为 按 我们 的 理解 ，tomcat 是 一个 jvm 进程 ， 当 jvm 进程 重启 时 ， 它 对应 的 内存 泄漏 应该 也 被 释放 才 对 。 这时候 我们 又 被 绕 进 了 另外 一个 误区 ， 去 排查 native memory 了 ， 这里 按下不表 。 其实 从 上面 的 描述 看 ， 最 可能 的 问题 是 在 docker 上 。 使用 的 docker 版本 是 非常 老 的 1.6.2，java 版本 是 adoptopenjdk 1.8.242， 按照 官方 的 说法 ， 在 jdk 1.8.131 之后 ，jvm 已经 可以 识别 cgroup， 即 可以 感知 到 自己 是 在 容器 中 运行 ， 因而 不会 将 物理 机 的 总 内存 认为 是 jvm 可用 的 总 内存 。 但 还是 无法解释 我们 遇到 但 问题 。 一筹莫展 之际 ， 我 尝试 了 在 宿主机 上 执行 运行 tomcat， 持续 运行 了 几个 小时 ， 内存 占用率 一直 在 15% 左右 ， 非常 稳定 ， 内存 泄漏 的 问题 不见 了 。 那么 基本上 就 锁定 是 docker 的 问题 了 。 升级 docker 版本 到 1.13.1， 问题 解决 。 排查 用到 的 工具 虽然 排查 的 过程 走 了 不少 弯路 ， 但 基本上 能 用到 的 排查 工具 也 都 用到 了 。 这里 只 记录 一下 大概 ， 用到 的 时候 还是 要 查 对应 的 文档 。jps    首先 是 最 基础 的 jps -lvVm， 可以 看到 整个 jvm 进程 的 启动 参数 ， 也 可以 用于 验证 指定 的 各种 命令行 参数 是否 生效 了 。visualvm    这个 就是 比较 高端 的 分析 工具 了 ， 最 重要 的 是 它 能 连接 远程 jvm 进程 ， 实时 查看 堆 内存 和 gc 的 情况 ， 甚至 还有 很多 插件 用于 查看 更 多 信息 。 但 对于 我们 的 这个 情况 来说 ， 只能 看到 堆 内存 的 占用 一直 维持 在 一个 正常 水平 ，ygc 也 很 正常 ， 整个 内存 的 使用 情况 呈 锯齿状 ， 能 说明 堆 内存 没有 泄漏 。perf    这 是 linux 内核 支持 的 工具 ， 可以 监听 指定 进程 在 一段时间 内 的 所有 系统 调用 。mat    全称 Memory Analyzer Tool,  可以 用于 分析 生成 的 hprof 文件 ， 这个 hprof 文件 可以 是 系统 崩溃 时 自动 生成 的 堆 内存 快照 ， 也 可以 是 由 jmap 生成 。jmap    生成 可 供 mat 分析 的 内存 快照 。>  需要 注意 的 是 .hprof 文件 可能 会 非常 大 ， 最好 监控 起来 ， 一方面 是因为 除去 人为 通过 jmap 生成 的 情况 之外 ， 都 是 系统 崩溃 了 才 会 生成 ， 另一方面 是 文件 太 大 ， 很 可能 会 快速 占 满 磁盘空间 。 基本上 常用 的 内存 检查 工具 就 这些 了 ， 关于 这些 工具 的 详细 使用 方法 ， 最好 还是 参照 官方 文档 ， 后面 如果 再 遇到 需要 查 内存 泄漏 的 例子 ， 将 会 在 这里 补充 一些 具体 的 案例 。","title":"Java 内存 泄漏 排查 记录 ","oriTitle":"Java内存泄漏排查记录","categories":["in-action"],"date":"2020-04-05T15:11:28.000Z"},{"uri":"/post/java-stream-api","tags":["java","basics"],"content":"Java 的 stream api 真是 功能强大 ， 但 写 的 时候 总是 忘 ， 这里 简单 记录 以下 。 概念 经常 会 搞 混淆 的 应该 就是 Stream 和 Collection 的 区别 。 从 定义 上 讲 ，Collection 是 一个 内存 数据结构 ， 它 包含 了 这个 数据结构 拥有 的 所有 元素 ， 每个 元素 都 必须 是 确定 的 。 也就是说 ， 一个 元素 在 加入 到 一个 集合 （Collection） 中 之前 一定 是 计算 好 了 的 、 确定 的 。 而 Stream 从 概念 上 固定 的 数据结构 ， 它 里面 的 元素 可以 按 需 计算 。 差异 如下 ： 流 并 不 存储 其 元素 。 这些 元素 可能 存储 在 底层 的 集合 中 ， 或者 是 按 需 生成 的 。 流 的 操作 不会 修改 其 数据源 。filter 方法 不会 从 流 中 移除 元素 ， 而是 会 生成 一个 新 的 流 。 流 的 操作 是 尽可能 惰性 的 ， 这 意味着 直至 需要 结果 时 ， 操作 才 会 执行 。 创建 Stream 的 几种 方式 1. Stream.Of(val1, val2, val3)public class StreamBuilders {    public static void main(String[] args) {        Stream stream = Stream.of(1,2,3,4,5,6,7,8,9);        stream.forEach(p -> System.out.println(p));        // stream.forEach(System.out::println);    }}2. Stream.of(arrayOfElements)public class StreamBuilders {    public static void main(String[] args) {        Stream stream = Stream.of(new Integer[]{1,2,3,4,5,6,7,8,9});        stream.forEach(System.out::println);    }}3. List.stream()public class StreamBuilders {    public static void main(String[] args) {        List list = new ArrayList();        for (int i = 0; i  stream = list.stream();        stream.forEach(System.out::println);    }}4. Stream.generate() 或 Stream.iterate()public class StreamBuilders {    public static void main(String[] args) {        Stream stream = Stream.generate(Date::new);        stream.forEach(System.out::println);    }}5. String chars 或 String tokenspublic class StreamBuilders {    public static void main(String[] args) {        IntStream stream = \"12345_abcde\".chars();        stream.forEach(System.out::println);    }}6. Map 通过 entrySet().stream()public class StreamBuilders {    public static void main(String[] args) {        Map map = new HashMap();        for (int i = 0; i > stream = map.entrySet().stream();        stream.forEach(System.out::println);    }} 中间 操作 和 终止 操作 public class StreamBuilders {    private static final List memberNames = new ArrayList();    static {        memberNames.add(\"Amitabh\");        memberNames.add(\"Shekhar\");        memberNames.add(\"Aman\");        memberNames.add(\"Rahul\");        memberNames.add(\"Shahrukh\");        memberNames.add(\"Salman\");        memberNames.add(\"Yana\");        memberNames.add(\"Lokesh\");    }} 中间 操作     public static void main(String[] args) {        memberNames.stream().filter(s -> s.startsWith(\"A\"))                .forEach(System.out::println);        memberNames.stream().filter(s -> s.startsWith(\"S\"))                .map(String::toUpperCase)                .forEach(System.out::println);        memberNames.stream().sorted()                .map(String::toUpperCase)                .forEach(System.out::println);    } 终止 操作         memberNames.forEach(System.out::println);        System.out.println(memberNames.stream().map(String::toLowerCase)                .collect(Collectors.toList()));        boolean b1 = memberNames.stream().anyMatch(s -> s.startsWith(\"A\"));        System.out.println(b1);        boolean b2 = memberNames.stream().allMatch(s -> s.startsWith(\"A\"));        System.out.println(b2);        boolean b3 = memberNames.stream().noneMatch(s -> s.startsWith(\"A\"));        System.out.println(b3);        long count = memberNames.stream().filter(s -> s.startsWith(\"S\")).count();        System.out.println(count);        Optional reduced = memberNames.stream()                .reduce((s1, s2) -> s1 + \"#\" + s2);        reduced.ifPresent(System.out::println);map 和 flatMap 这 两个 真是 最 容易 搞混 的 ， 不过 如果 要 搞清楚 他们 的 区别 也 很 简单 ：map 就是 一个 转换 ， 把 原来 是 a 的 转换成 b， 原来 是 List，map 之后 还是 List（ 其实 是 stream， 是 类型 没有 变 ）， 而 flatMap 会 生成 一个 新 的 stream 把 原先 的 多个 stream 合并 在 一起 。 举例说明 下 //  例 1List lower = Arrays.asList(\"a\", \"b\", \"c\", \"d\");List upper = lower.stream().map(String::toUpperCase).collect(Collectors.toList());System.out.println(lower);System.out.println(upper); 从 这个 例子 可以 看出 ， 通过 map， 让 这个 List 中 的 每个 元素 都 执行 了 e.toUpperCase() 方法 ， 输出 的 结果 就是 [a, b, c, d][A, B, C, D] 下面 看 flatMap 可以 实现 什么 功能 //  例 2List> packed = new ArrayList();packed.add(lower);packed.add(upper);System.out.println(packed);List flat = packed.stream().flatMap(s -> s.stream()).map(String::toUpperCase).collect(Collectors.toList());System.out.println(flat); 这里 必须 要 注意 一点 ，map() 的 输出 是 stream 中 的 一级 元素 ， 像 例 1 中 的 String::toUpperCase 显然 是 输入 a， 输出 A。 而 对于 flatMap 而言 ， 它 的 输入 是 一个 Collection， 而 输出 是 一个 stream， 那 怎么 形成 一个 stream 呢 ， 像 例 2 中 的 packed， 它 就是 由 两个 List 组成 的 ， 对 他们 调用 stream() 方法 就让 它 返回 一个 stream 到 flatMap 的 输出 了 。 举 个 不 太 恰当 的 例子 ， 这里 有 3 包 牛奶 ，map 方法 只能 把 3 包 牛奶 倒 到 3 个 杯子 里 ， 而 flatMap 可以 把 它们 倒 到 1 个 杯子 里 。 如何 实现 呢 ？ 当然 就是 在 flatMap 中 把 每个 牛奶 的 袋子 撕开 ， 然后 倒 出来 。 例 2 的 输出 如下 [[a, b, c, d], [A, B, C, D]][A, B, C, D, A, B, C, D] 理解 到 了 这 一步 ， 基本上 就 搞清楚 了 二者 的 区别 了 ， 总之 就是 记住 一定 要 让 flatMap() 输出 一个 stream。Map 的 stream()List 输出 到 stream 的 方法 很 容易 理解 ， 因为 它 本身 就是 一个 一个 的 元素 ， 但 Map 是 分 了 key 和 value 的 ， 要 怎么 才能 把 它 转换成 stream 呢 ？ 答案 是 Map.Entry。 可能 第一门 语言 就是 Java 的 同学 觉得 很 理所应当 ， 但 熟悉 PHP 的 同学 再 来 理解 这个 概念 就 有点 对应 不 上 了 （ 因为 PHP 里 基本上 不 区分 List 和 Map， 一切 皆 为 数组 ）。 先 看 一个 PHP 的 例子 $a = [    'a' => 'b',    'c' => 'd',];foreach ($a as $key => $value) {    echo $key . '=>' . $value, \"\\n\";} 在 这个 例子 中 $key 和 $value 的 组合 就是 Java 中 Map.Entry 的 概念 了 ， 只不过 继续 遵循 封闭 的 原则 ， 给 二者 都 配备 了 对应 的 方法 getKey() 和 getValue()， 也就是说 ， 可以 从 一个 Map 的 Entry 中 同时 获取 当前 这个 元素 的 key 和 value。 那么 问题 又 来 了 ， 怎么 拿到 它 的 Entry 呢 ？ 通过 entrySet() 方法 。 对 一个 Map 调用 entrySet() 方法 ， 相当于 新建 了 一个 List， 它 的 元素 是 这个 Map 的 Entry， 这 就 又 回到 了 List， 当然 也 就 可以 用 stream api 了 。 比如 要 把 一个 Map 的 key 和 value 倒 过来 （PHP 的 array_flip 方法 ）Map g = new HashMap();g.put(\"k1\", \"v1\");g.put(\"k2\", \"v2\");g.put(\"k3\", \"v3\");g.put(\"k4\", \"v4\");g.put(\"k5\", \"v5\");val h = g.entrySet().stream().collect(Collectors.toMap(Map.Entry::getValue, Map.Entry::getKey));System.out.println(g);System.out.println(h); 结果 如下 {k1=v1, k2=v2, k3=v3, k4=v4, k5=v5}{v1=k1, v2=k2, v3=k3, v4=k4, v5=k5}>  注意 这个 方法 可能 会 有 异常 ， 因为 如果 原始 输入 中 不同 的 key 对应 了 相同 的 value， 就 无法 生成 新 map 了 > > Exception in thread \"main\" java.lang.IllegalStateException: Duplicate key v3 (attempted merging values k3 and k4)>\tat java.base/java.util.stream.Collectors.duplicateKeyException(Collectors.java:133)>\tat java.base/java.util.stream.Collectors.lambda$uniqKeysMapAccumulator$1(Collectors.java:180)>\tat java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169)>\tat java.base/java.util.HashMap$EntrySpliterator.forEachRemaining(HashMap.java:1746)>\tat java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)>\tat java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)>\tat java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913)>\tat java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)>\tat java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578)>\tat fun.happyhacker.java.stream.MapDemo.main(MapDemo.java:56)>Map 还有 一个 方法 ， 可以 把 它 的 所有 key 输出 到 一个 List，PHPer 肯定 又 想到 了 array_keys()， 没错 ， 就是 keySet()collect 很多 时候 前面 的 一堆 操作 都 是 要 把 结果 收集 起来 ， 这个 话题 太 大 了 ，collect 的 方式 多种多样 ， 这里 也 说不完 ， 简单 说 几个 最 常用 的 。collect(Collectors.toList()) 这 是 最 简单 的 ， 把 一个 stream 中 的 所有 元素 按 前面 的 输出 收集 到 一个 List 中 。 而 这个 List 的 类型 ， 当然 就 取决于 这个 stream 中 的 元素 了 ， 参考 例 1 的 代码 即可 。collect(Collectors.toMap()) 这个 就 相对 复杂 一点 了 ， 既然 把 结果 收集 成 map， 那 就 肯定 得 设置 key 和 value， 比如 我们 要 把 一个 小写字母 的 列表 和 它 对应 的 大写字母 分别 对应 起来 ，//  例 3List lower = Arrays.asList(\"a\", \"b\", \"c\", \"d\");val f = lower.stream().collect(Collectors.toMap(e -> e, String::toUpperCase));System.out.println(f); 输出 如下 {a=A, b=B, c=C, d=D}`","title":"Java Stream Api","oriTitle":"Java Stream Api","categories":["theory"],"date":"2020-04-29T15:23:57.000Z"},{"uri":"/post/lftp-usage","tags":["lftp","macOS","ftp"],"content":" 简单 的 工具 最好 用 。lftp 是 我 非常 喜欢 的 一个 lftp 工具 ， 命令 简单 。 为了 避免 每次 输入 密码 ， 可以 通过 在 $HOME/.netrc 中 添加 一行 记录 来 实现 machine 192.168.1.108 login ${myusername} password ${my_password} 非常简单 。 而且 这个 .netrc 并 不是 lftp 专用 的 ， 而是 一个 用 在 很多 开源 软件 上 的 公用 配置 。","title":"lftp 记录 密码 ","oriTitle":"lftp记录密码","categories":["in-action"],"date":"2020-04-05T03:32:45.000Z"},{"uri":"/post/life/fix-gzjzz-website-with-extension","tags":["政务","工作居住证"],"content":" 工作 居住证 这个 网站 不 知道 是 什么 时候 开发 的 了 ， 现在 用 新款 的 浏览器 打开 会 有 各种 样式 错乱 、 功能 报错 ， 不过 这 都 难不倒 我们 伟大 的 人民 ！ 问题 一 ：macOS 电脑 无法 登陆 网站 解决方案 访问  http://219.232.200.39/uamsso/SSOSecService?sid=e10adc3949ba59abbe56e057f20f883e&LinkType=online&LinkID=666  这个 地址 打开 一个 可以 输入 用户名 、 密码 和 验证码 的 页面 ， 虽然 页面 样式 也 是 错乱 的 ， 但 不 影响 。 输入 正确 的 信息 之后 会 跳转 到 另 一个 页面 ， 不用 管 它 ， 再次 访问 上面 的 这个 链接 ， 就 能 找到 系统 的 入口 了 。 到 这 一步 你 就 能 正常 填写 信息 ， 等待 工作 居住证 审批 完成 了 。 现在 （2021 年 1 月 ） 已经 没有 纸质 的 工作 居住证 了 ， 办事 儿 需要 自己 打印 确认 单 。 这里 的 功能 没有 问题 ， 跳 过 。 问题 二 ： 无法 切换 标签 页 有时候 办事 儿 还 需要 提供 工作 居住证 的 审批 流程 ， 也 就是 比如 要 给 孩子 办 入学 手续 ， 就 需要 有 孩子 的 随 往 证明 ， 这 就 需要 点击 这里 但 点击 了 之后 发现 页面 报错 了 ， 查找 原因 其实 是 在 页面 上 的 js 里面 有 这样 一段 ， 有 语法错误 ， 导致 后面 的 js 无法 执行 了 。 我 入 行 晚 ， 也 不 知道 这种 写法 在 以前 可不 可行 ， 或者 在 IE 浏览器 里 可以 的 ？ 这 相当于 是 要 重写 系统 函数 了 ， 反正 在 Chrome 里 是 无法 执行 的 。 找到 了 问题 的 根源 就 好 解决 了 。 解决方案 ： 方案 一 最 简单 的 办法 就是 把 这 行 错误代码 后面 的 函数 定义 直接 复制到 console 里面 执行 一下 就 好 了 。function changeSub(flag) {\tif (flag == \"education\") {\t\tdocument.getElementById(\"education\").style.display = \"\";\t\tdocument.getElementById(\"unit\").style.display = \"none\";\t\tdocument.getElementById(\"achievement\").style.display = \"none\";\t\tdocument.getElementById(\"follows\").style.display = \"none\";\t} else if (flag == \"unit\") {\t\tdocument.getElementById(\"education\").style.display = \"none\";\t\tdocument.getElementById(\"unit\").style.display = \"\";\t\tdocument.getElementById(\"achievement\").style.display = \"none\";\t\tdocument.getElementById(\"follows\").style.display = \"none\";\t} else if (flag == \"achievement\") {\t\tdocument.getElementById(\"education\").style.display = \"none\";\t\tdocument.getElementById(\"unit\").style.display = \"none\";\t\tdocument.getElementById(\"achievement\").style.display = \"\";\t\tdocument.getElementById(\"follows\").style.display = \"none\";\t} else if (flag == \"follows\") {\t\tdocument.getElementById(\"education\").style.display = \"none\";\t\tdocument.getElementById(\"unit\").style.display = \"none\";\t\tdocument.getElementById(\"achievement\").style.display = \"none\";\t\tdocument.getElementById(\"follows\").style.display = \"\";\t}}function toMod() {\twindow.location = \"/yjrc/person/ApplyCardAction.do?formAction=cApply\";}function back() {\twindow.location = \"/yjrc/person/ApplyListAction.do?formAction=in&opType=cApply\";}function queryEdu(id) {\tvar goUrl = \"/yjrc/person/QueryEduResumAction.do?formAction=in&applyId=\" + id;\twindow.open(goUrl, 'querywindow', 'width=1030,height=420,top=10,left=10,status=yes,menubar=no,resizable=yes,scrollbars=yes');}function queryWork(id) {\tvar goUrl = \"/yjrc/person/QueryWorkResumAction.do?formAction=in&applyId=\" + id;\twindow.open(goUrl, 'querywindow', 'width=1030,height=420,top=10,left=10,status=yes,menubar=no,resizable=yes,scrollbars=yes');} 但 为了 刷新 页面 之后 还 能 用 ， 还是 得 把 代码 “ 注入 ” 到 页面 上 ， 这 也 是 方案 二 要 做 的 。 方案 二 之前 简单 了解 了 Chrome 浏览器 的 扩展 开发 原理 ， 其实 现在 面临 的 这个 问题 用 扩展 就 很 好 解决 了 ， 在 页面 加载 完成 后 往 页面 上 写 一个 `` 标签 ， 把 那些 因为 语法错误 而 中断 执行 的 代码 粘贴 进去 。 只是 我 上次 写 的 是 个 非常简单 的 扩展 ， 只用 到 了 content_scripts， 这个 限制 就是 js 可以 访问 页面 DOM 元素 ， 但 DOM 元素 无法访问 js 中 定义 的 函数 ， 也 无法 在 js 中 定义 listener。 而 前面 那些 没有 执行 的 代码 恰好 就是 事件 的 回调 函数 。 所以 ， 整个 扩展 的 目录 结构 就是 这样 的 ： 其中 content-script.js 负责 在 页面 上 写入 ` 标签 ， 并 把 extension.js` 注入 进去 ， 后者 里面 就是 那些 需要 添加 的 函数 。 如果 你 选择 了 方案 二 ， 可以 继续 往下读 ， 如果 你 选择 了 方案 一 ， 那么 你 的 问题 已经 解决 了 。 安装 扩展 把 代码 从 github 上 下载 下来 ， 找到 其中 的 chrome-extension 目录 浏览器 找到 扩展 管理 页面 点击  Load Unpacked， 选择 上面 提到 的 chrome-extension 目录 结束 总结 我 也 不 知道 对于 普通用户 来说 是 复制 一段 js 代码 更 容易 还是 安装 一个 浏览器 扩展 更 容易 ， 整个 过程 也 不 复杂 ， 参考 了 网上 的 一些 信息 ， 这里 把 扩展 和 源码 都 贴 到 github 上 了 。https://github.com/lovelock/gzjzz-website-fixer>  我 没有 注册 过 Chrome WebStore 的 开发者 权限 ， 所以 打 出来 的 .crx 包 也 是 不能 直接 安装 的 ， 需要 通过 目录 安装 。","title":" 通过 Chrome 扩展 修复 北京 工作 居住证 网站 ","oriTitle":"通过Chrome扩展修复北京工作居住证网站","categories":["life"],"date":"2021-01-02T04:37:30.000Z"},{"uri":"/post/life/macos-network-proxy-script","tags":["macOS","bash"],"content":" 一直 以来 我 都 有 个 疑问 ， 就是 为什么 所有 操作系统 的 网络 代理 设置 都 不能 保存 。 以 macOS 为 例 ， 如果 我 设置 了 代理 地址 ， 而 没有 勾 选 左边 的 勾 选项 ， 那么 保存 之后 再 打开 也 同时 没有 了 已经 设置 好 的 代理 地址 。 而 我 想要 的 是 可以 设置 好 一个 固定 的 代理 地址 ， 我 需要 开启 的 时候 在 一个 很 明显 的 入口 点 一下 ， 就 配置 上 了 。 不想 用 的 时候 关掉 即可 ， 不用 清空 配置 。 然而 我 搜 遍 了 全网 也 没有 找到 。 于是 我 就 想 macOS 系统 既然 脱胎 于 BSD， 那 会 不会 有 相应 的 命令行 可以 做 这件 事儿 呢 ， 果然 被 我 找到 了 一系列 命令 networksetup。 先 看 一下 这个 命令 都 有 什么 功能 吧 ，networksetup -help 输出 太 多 了 ， 这里 就 不 贴 了 ， 可以 自己 尝试 一下 。 我们 关注 的 是 代理 （Proxy）， 所以 在 输出 的 信息 里 搜索 proxy， 就 会 找到 以下内容 Usage: networksetup -setautoproxyurl\tSet proxy auto-config to url for  and enable it.Usage: networksetup -getautoproxyurl\tDisplay proxy auto-config (url, enabled) info for .Usage: networksetup -setautoproxystate\tSet proxy auto-config to either  or . 很 明显 也 就 看 出来 各自 的 用途 了 ， 知道 这个 了 就 很 容 写出 两个 脚本 了 由于 我 的 是 黑 苹果 ， 使用 的 是 有线 网络 ， 所以 这里 的 网络 名 是 en0， 你 的 电脑 用 的 是 什么 网络 需要 你 自己 去 发现 了 设置 代理 #!/usr/bin/env bashecho \"Enabling auto proxy....\"networksetup -setautoproxyurl \"Ethernet Adaptor (en0)\" \"http://your.host/proxy.pac\"networksetup -setautoproxystate \"Ethernet Adaptor (en0)\" onnetworksetup -getautoproxyurl \"Ethernet Adaptor (en0)\"if [ $? -eq 0 ]; then    echo \"Proxy is set\"fi 关掉 代理 #!/usr/bin/env bashecho \"Disabling auto proxy...\"networksetup -setautoproxystate \"Ethernet Adaptor (en0)\" offnetworksetup -getautoproxyurl \"Ethernet Adaptor (en0)\"if [ $? -eq 0 ]; then    echo \"Proxy is disabled\"fi 设置 快捷方式 把 这 分别 保存 为 disableproxy 和 enableproxy， 放在 $HOME/.local/bin/ 目录 下 ， 然后 在 你 的 $HOME/.zshrc 或 $HOME/.bashrc 的 最后 一行 追加 export PATH=$PATH:$HOME/.local/bin 再 执行 source ~/.zshrc 或 source ~/.bashrc， 就 可以 生效 了 。 之后 就 可以 通过 执行 enableproxy 开启 代理 ， 通过 disableproxy 来 关闭 代理 了 。 再也 不用 找 那么 深 的 入口 去 一遍 遍 的 配置 代理 了 。","title":"macOS  网络 代理 设置 脚本 ","oriTitle":"macOS 网络代理设置脚本","categories":["macOS"],"date":"2020-11-17T14:34:31.000Z"},{"uri":"/post/life/mandy-words","tags":["满满"],"content":" 我家 姑娘 有意思 的 事儿 。 前庭 为什么 没有 让 他们 吐 呢 ？ 前 几天 她 突然 要 考考 我 为什么 自己 挠 自己 脚丫 不会 觉得 痒 ， 我 要 跟 她 解释 时 ， 她 说 她 知道 ， 是 前庭 如何 如何 。 我 又 给 她 补充 说 当 吃 了 有毒 的 东西 人 感觉 头晕 时 前庭 会 通知 大脑 你 中毒 了 ， 需要 把 吃 的 东西 吐出来 。。。。 今天 我们 聊天 谈到 黑龙江 发生 的 酸 汤 子 事件 ，9 个人 全都 不幸 去世 。 孩子 就 问 我 ， 为什么 前庭 没有 让 他们 吐 呢 ？ 我 问 了 两遍 才 确认 她 确实 是 问 的 这个 问题 。 我 也 有点 疑问 。","title":" 满满 语录 ","oriTitle":"满满语录","categories":["生活趣事"],"date":"2020-10-22T03:30:55.000Z"},{"uri":"/post/life/renting-invoice-applying-in-beijing","tags":["政务"],"content":" 好久 没有 去 政府 机关 办事 了 ， 今天 记录 一下 开 租房 发票 的 过程 。TL;DR 出租方 / 承租方 的 身份证 原件 、 复印件 ， 提前准备 好 复印件 ， 园区 内 不能 复印 不 需要 房产证 原件 ， 只要 房产证 上 的 “ 坐落 ” 那个 地址 导航 搜索 “ 北京 青年 创业 示范园 （ 南门 ）”， 停车场 在 这个 门 的 东面 每个 月 的 最后 一个 工作日 不 开发票 需要 准备 的 材料 出租方 / 承租方 的 身份证 原件 、 复印件 地址 这个 比较 诡异 ， 大家 都 在 百度 搜索 ， 估计 都 是 搜索 到 了 这个 ， 看起来 非常 完备 的 答案 这时候 正常 我们 会 去 地图 上 搜索 这个 位置 ， 然后 得到 这么 个 地址 然后 就 奔 这 去 了 ， 结果 到 了 之后 人家 保安 大爷 说 所有 在 网上 搜 地址 的 都 找到 这里 来 了 ， 但 不是 在 这里 交 ， 要 去 “ 回龙观 青年 创业 示范园 ” 然后 我 就 奔 这里 去 了 ， 来 放大 看 一下 地图 看 地图 上 标注 出来 的 ， 如果 你 开车 过来 的 ， 直接 把 车 停 在 标注 “ 门口 ” 的 那里 ， 这个 在 地图 上 没有 标注 ， 实际上 是 有 一个 临时 停车场 ， 供 前来 办事 儿 的 人 停车 用 的 。 停 好 车 之后 再 从 “ 北京市 昌平 回龙观 工业 企业 总公司 ” 这个 门口 进去 ， 一直 往 里 走 到 一排 平房 的 位置 左 拐 尽头 的 一间 就是 开 租房 发票 的 地方 了 ， 当然 这里 可以 开 很多 发票 。 填写 和 提交 材料 这个 办理 点 受理 龙 泽 园 、 回龙观 、 史 各庄 三个 社区 的 事务 ， 需要 根据 你 的 实际 情况 选择 窗口 排队 。 领取 材料 之后 根据 实际 情况 填写 。 填写 完成 之后 提交 上面 提到 的 两个 身份证 原件 和 复印件 ， 重点 园区 内 不 提供 复印 服务 ， 所以 一定 要 自行 复印 好 再 去 。 这里 说明 一点 ， 开票 金额 是 没有 人 关心 的 ， 你 想开 多少 都行 。 开票 金额 和 租金 相关 ， 这 里面 的 关系 你 可以 自行 联想 ， 具体 怎么 操作 我 就 不 细说 了 。 填好 材料 之后 基本上 2 分钟 之内 就 办完 了 。 总结 从 网上 能 搜 到 的 资料 来看 ， 之前 应该 是 要 房产证 原件 和 复印件 的 ， 但 我 实际 去 办理 过程 中 是 没有 要 的 ， 但 填写 的 材料 上 要 写 房屋 的 具体位置 ， 要 和 房产证 上 的 一致 ， 所以 你 能 写 这个 地址 也 证明 你 肯定 见 过 房产证 了 。","title":" 在 北京 （ 昌平 ） 开具 租房 发票 流程 ","oriTitle":"在北京（昌平）开具租房发票流程","categories":["幼升小"],"date":"2020-12-30T14:01:15.000Z"},{"uri":"/post/life/tiggo8-first-1000-km","tags":["car","tiggo8"],"content":" 新车 开 了 1000 公里 了 ， 终于 上 牌 了 。1000 公里 算是 一个 小小的 里程碑 吧 ， 简单 的 记录 一下 这 段时间 的 想法 。 关于 品牌 奇瑞 这个 品牌 还 挺 有意思 。 路 人 视角 没有 买 过 的 人 对 它 的 印象 总是 停留 在 “ 奇瑞 奇瑞 ， 修车 排队 ”。 这 句 话 的 到底 是 来自 友 商 的 中伤 还是 车主 的 调侃 已经 无从 考证 了 ， 但 我 自己 分析 ， 很 可能 是 来自 友 商 。 因为 那个 年代 互联网 也 不 发达 ， 一个 这种 顺口溜 能 流传 到 这种 程度 ， 是 很 难 想象 的 。 简单 描述 一下 这个 事儿 的 背景 ， 当时 奇瑞 没有 生产 汽车 的 资质 （ 现在 的 这些 民营 汽车 公司 当时 都 面临 一样 的 问题 ）， 所以 和 上汽 合作 ， 才 有 了 当时 的 上汽 奇瑞 ， 售后 网点 也 是 在 上汽 。 但 这个 合作 是 有点 不 平等 条约 的 意思 ， 后来 奇瑞 的 销量 意外 的 好 ， 上汽 就 想 拿 更 多 的 利益 ， 奇瑞 不 同意 ， 于是 售后 就 区别对待 奇瑞 的 车 了 ， 由于 销量 好 ， 售后 网点 少 ， 那么 这个 口号 在 当时 说 是 现实 其实 也 没什么 问题 。 不管 怎么样 ， 这 句 话 对 奇瑞 的 销量 的 影响 直到 今天 都 还 很大 ， 每个 去 店里 的 新 “ 潜在 客户 ” 都 会 说 这 句 话 ， 说明 他们 心里 是 存在 疑虑 的 ， 奇瑞 面向 的 受众 还是 相对 低端 ， 他们 接受 信息 的 渠道 相对 少 ， 不 太 愿意 去 查找 这 句 话 真正 的 原因 ， 更 愿意 听 周围 的 人 怎么 说 ， 销售 估计 天天 都 要 跟 人 解释 。 直至 今天 ， 我 也 没 见 过 奇瑞 公司 对 这个 事儿 作出 过 什么 补救措施 。 就 这 现在 的 拳头产品 瑞 虎 8 还 能 卖 到 月 销 1 万多 也 是 奇迹 。 车主 视角 作为 车主 ， 买车 之前 肯定 做 了 一些 功课 ， 把 品牌 的 发展史 大概 了解 了 一下 ， 知道 了 是 多 品牌 害死 了 它 。 有人 说 奇瑞 的 车 没有 延续性 ， 一个 车系 卖 的 不好 就 砍掉 ， 再起 一个 新 的 系列 。 子 品牌 表现 不行 就 砍掉 ， 再起 4 个子 品牌 。 关于 车系 的 延续性 这件 事儿 ， 我 的 看法 是 这个 事儿 根本 用不着 车主 关心 ， 只要 这个 车 企 没有 倒闭 ， 他们 还 能 继续 给 你 生产 配件 ， 那 后续 的 车型 叫 什么 名字 和 你 又 有 什么 关系 呢 ？ 拿 10 代 思域 为 例 ， 虽然 都 叫 思域 ， 那 9 代 和 10 代 除了 名字 一样 ， 还有 什么 是 一样 的 ？ 是 配件 能 通用 还是 长 得 一样 ？ 平心而论 ， 如果 你 不 知道 这 两辆车 都 是 思域 ， 你 能 知道 他们 是 同一个 名字 吗 ？ 是不是 改名字 只是 厂家 的 策略 而已 ， 不 改名字 可以 降低 宣传 成本 ， 提高 老 车主 的 认同感 ， 相反 改名字 就要 重新 宣传 ， 被 人 骂 没有 传承 。 那 为什么 厂家 还 一直 对 多 品牌 乐此不疲 呢 ？ 多 品牌 只是 表象 ， 背后 其实 是 权力 的 斗争 。 这里 不 说 什么 海归派 、 芜湖 派 这种 ， 就 说 公司 内部 的 小 权力 集团 ， 其实 是 没 人 在乎 公司 死活 的 ， 他们 在乎 的 是 自己 小集团 的 利益 ， 都 想 当 品牌 一把手 ， 那 一把手 的 椅子 又 不够 ， 怎么办 呢 ？ 多 打造 几把 椅子 呗 。 干 了 几年 把子 品牌 干 黄 了 ， 没关系 ， 再 整 它 几个 ， 又 可以 赚 一 波 KPI。 公司 被 多 品牌战略 拖累 ？ 没 人 在乎 。 如果 多 品牌 之间 互相配合 ， 满足 不同 价位 不同 需求 的 客户 那 则 还 了 ， 这些 品牌 的 老大 们 可是 个个 都 想 当 别人 的 老大 。 捷 途 ： 什么 ， 我 捷 途 是 低端 子 品牌 ？ 看 我 怎么 做成 高端 ， 干 死 奇瑞 品牌 ！ 星 途 ？ 下 一个 。 星 途 ： 作为 高端 ， 我 卖 不 动 可 怎么办 ？ 降价 吧 ， 只要 足够 便宜 ， 一定 能 卖出去 。 奇瑞 ：？？？ 本来 定位 高 中低端 的 三个 品牌 ， 现在 互相 重叠 互相 打架 ， 别人 多 生 孩子 跟 别人 打架 ， 奇瑞 是 多 生 孩子 窝里 打架 。 我 觉得 还是 尹 同 跃 不够 强势 ， 就 想 当 个 老好人 ， 谁 也 不想 得罪 ， 最后 在 谁 那 也 落 不到 好 。 老 车主 视角 话说回来 ， 但 实际 我 看到 的 情况 是 ， 很多 老 奇瑞 车主 在 换车 时 还是 选择 奇瑞 。 说 几个 我 了解 到 的 。 去 提 车 那天 遇到 一个 看起来 是 跑 工地 的 大哥 ，40 多岁 的 样子 ， 手动挡 E5 开 了 8 年 23 万公里 ， 置换 了 一辆 瑞 虎 8 2019 款 1.5T 自动 精英 ， 我 跟 他 聊天 ， 他 说 ：“ 咱 老百姓 买车 不 就 图 个 省心 省油 吗 ， 我 这 8 年 的 车 了 还 能 开出 7 个 油 。 我 朋友 让 我 买 大众 ， 我 说 咱 也 不是 什么 大 老板 要 出去 谈 生意 ， 要 什么 面子 啊 ， 买 个 大众 花 20 多万 ， 买 个 奇瑞 才 8 万多 ， 剩下 的 钱 买 啥 不行 ， 你 说 对 不 对 。” 还是 提 车 那天 ， 销售 指着 门口 的 一辆 传 祺 GS5 跟 我 说 ， 那个 车主 原来 开 的 5 年 的 奇瑞 ， 后来 换 了 传 祺 ， 这 开 了 2 年 又 来 换 奇瑞 了 。 今天 去 上 牌 遇到 一位 看起来 是 小店 老板娘 的 大姐 ， 新 买 了 一辆 瑞 虎 7 1.5T 手动挡 ， 她 说 ：“ 之前 开 的 开 瑞 优 优 手动挡 开 了 10 年 ， 想 换车 了 就 还是 选 了 奇瑞 。 去 店里 一眼 就 看 上 瑞 虎 7 了 ， 喜欢 红色 ， 等 了 23 天才 提 车 。 这么 大 的 车 ， 看起来 这么 豪华 ， 才 7 万多块 钱 ， 太 值 了 。” 上 完 牌 去 贴膜 ， 我 说起 看到 好几个 老 车主 换车 还 选 奇瑞 的 ， 老板娘 说 见 过 最 厉害 的 是 换 了 4 辆 的 ， 开 三五年 就 换 一辆 ， 一直 是 奇瑞 。 在 贴膜 店里 排队 在 我 前面 的 是 一个 大爷 ， 在 车管所 停车场 也 算 见 过 了 ， 我 的 蓝色 瑞 虎 8 和 他 的 隔 了 一个 车位 ， 我 在 新车 大厅 看着 外面 发呆 ， 看着 他们 几个 人 就 冲 我 的 车 过去 了 ， 拉 不 开 就 开始 按 钥匙 ， 还是 拉 不 开 ， 这时 终于 有 一个 人 看到 这 大爷 身后 的 车 在 闪 灯 。 我 说起 这 事儿 的 时候 他 还 挺 不好意思 自己 找 错车 了 。 我 问 他 这 车 开 着 感觉 咋样 ， 他 说 这 是 买 的 第二辆 了 ， 专门 从 沈阳 坐火车 来 北京 买 的 ， 后备箱 还 放 着 坐火车 的 时候 拉 的 行李箱 。 关于 品 控 品 控 说 实在 的 不怎么样 ， 车子 开 下来 问题 还是 遇到 了 一些 的 。 中 控 车机 中 控 车机 在 使用 高 德 地图 导航 时 总是 会 时不时 的 没有 信号 ， 是 同时 GPS 和 4G 都 没有 信号 ， 打 给 售后 说 是 让 去 店里 检测 ， 还要 让 工作日 去 ， 可能 需要 和 厂家 一起 看 这个 问题 。 虽说 用 CarPlay 也 可以 ， 但 我 感觉 CarPlay 还 没有 车机 的 好 用 呢 ， 没有 小 地图 都 看不到 在 整个 路线 里 自己 走 到 哪儿 了 ， 不 方便 。 智能 钥匙 手动 按 门把手 的 感应 区 经常 是 有 感应 ， 但 在 锁 车 还 能 识别 成 锁 车 。 这个 真是 很 恼人 。 电动 尾 门 理论 上 是 站 在 车 后 等 示 廓 灯 闪 几下 往后 退一步 就 可以 自动 打开 尾 门 ， 但 实际上 经常 打不开 。。。 奇葩 的 设定 今天 贴完 膜 走 高速 收费站 ， 需要 开门 接 卡 ， 没有 停 稳 就 把 拉了一把 门把手 ， 把 第一道 锁 解开 了 ， 一瞬间 手刹 就 拉 上 了 ！ 那会儿 时速 也 就 5 公里 吧 ， 不过 还是 着实 把 我 吓 得 不 轻 。 我 在 想 这个 设定 到底 是否 合理 ？ 门 都 没有 打开 ， 直接 拉 手刹 ？ 关于 品质 内饰 这块 我 没有 开 过 太 好 的 车 ， 感觉 还是 看 得 过去 的 。 但 我 说 的 品质 是 行驶 品质 。38 号 在 2019 年 评测 19 款 1.5T 瑞 虎 8 的 时候 说 的 “ 一台 变速箱 毁 所有 ” 对 现在 的 2020 款 1.6T 同样 适用 。24-28 时速 区间 2-3 挡 切换 会 有 明显 的 顿挫 或者说 抖动 。 低速 踩 刹车 时候 偶尔 会 有 明显 的 闯 动 ， 应该 是 转速 不 匹配 引起 的 。 这些 在 试 驾 的 时候 都 没有 觉察到 ， 当时 也 仔细 感受 了 的 。","title":" 瑞 虎 8 1000 公里 感受 ","oriTitle":"瑞虎8 1000公里感受","categories":["life"],"date":"2020-10-15T14:51:47.000Z"},{"uri":"/post/life/tiggo8-first-glance","tags":["car","tiggo8"],"content":" 终于 还是 不想 再 忍受 皮 卡 了 ， 换 了 一辆 国产车 。 经过 了 几番 试 驾 和 比较 ， 最终 还是 选定 了 最初 看 上 的 奇瑞 瑞 虎 8 2020 款  1.6T  自动 豪华版 ， 昨天 去 把 车 开 回来 的 ， 简单 说 说 体验 。 外观 外观 说不上 第一眼 很 惊艳 ， 但 算 耐看 的 类型 吧 ， 主要 是 前 脸 有些 奇怪 ， 其他 的 地方 都 很 协调 。 外观 见仁见智 ， 这里 不 说 太 多 了 。 全家人 都 喜欢 蓝色 ， 最终 也 就 定 了 莱茵 蓝 。 我 也 不 知道 为什么 叫 这么 个 名字 。 空间 空间 是 非常 吸引 我 的 地方 。 我 人生 第一辆 车 是 铃木 启 悦 ， 一辆 紧凑 级 轿车 ， 车 内 空间 确实 很 紧凑 ， 头部 空间 更 堪忧 ， 后备箱 空间 倒 是 挺 大 。 后来 换 了 一辆 纳瓦拉 皮 卡 ， 前排 空间 是 大 了 一些 ， 但 没有 后备箱 了 ， 如果 硬 要说 货箱 是 后备箱 也 行 ， 但 由于 是 开放式 的 ， 所以 平时 也 是 放 不了 东西 的 。 所以 这次 选 车 的 一个 目标 就是 ： 车 内 空间 要 大 ， 后备箱 空间 也 要 大 。 而 瑞 虎 8 这样 一辆 准 中型 SUV 就 完美 的 解决 了 上面 两个 问题 ， 市面上 主流 的 国产 SUV 多 是 紧凑型 ， 虽说 瑞 虎 8 的 所谓 “ 中型 ” 有点 噱头 的 意思 ， 但 相比 其他 “ 真 紧凑型 ” 的 SUV 而言 ， 空间 上 还是 有 很大 优势 的 ， 尤其 对比 哈 弗 F7， 那个 后备箱 就 太小 了 。 孩子 甚至 很 期待 躺 在 后备箱 睡觉 。 当然 毕竟 也 只是 “ 准 中型 ”， 前排 空间 相比 纳瓦拉 还是 要 小 一些 的 ， 不过 也 可以 满足 需求 了 。 提到 纳瓦拉 ， 日产 的 座椅 可 真 不是 吹 的 ， 坐 到 车上 ， 屁股 就 会 告诉 你 答案 ， 日产 的 座椅 明显 支撑 性 更好 ， 也 是 厚 ， 缓冲作用 要 好得多 。 动力 启 悦 的 也 是 1.6L， 不过 是 自然 吸气 ， 仅仅 122P 马力 ， 而 瑞 虎 8 的 1.6T 则 功率 达到 了 197P 马力 ， 扭矩 290NM， 单 从 参数 上 看 简直 惊人 ， 已经 超过 了 很多 德 系 车 的 2.0T 低 功率 版本 。 提 车 的 时候 观察 了 下 车子 上 的 铭牌 ， 功率 是 140KW， 也 就是 190P 马力 ， 和 之前 抖 音 上 马力 机 测试 出 的 轮 上 马力 的 结果 一致 ， 也 就 说明 没有 虚 标 ， 不 像 长安 的 蓝鲸 什么 鬼 动不动 少 了 大 几十匹 。。。 实际上 的 动力 体验 也 很 好 ， 不 激烈 驾驶 使用 ECO 模式 ， 给 我 的 感觉 就是 很 轻快 ， 能 感觉 到 还有 很多 动力 储备 。 今天 早上 下雨 ， 一辆 班车 和 我 并排 还 想 超 我 ，ECO 模式 下 一脚 油门 出去 直接 把 我 自己 干 头晕 了 ， 等 回过 神 来 已经 跑出去 几十米 了 ， 赶紧 松开 油门 缓缓 神 接着 走 了 。 以前 我 觉得 一辆车 百公里 加速 12 秒 和 8 秒 能 有 什么 区别 啊 ， 只有 4 秒 的 差距 ， 但 现在 看 还 真的 不是 这样 ， 动力 好 的 车子 动力 储备 丰富 ， 能 让你在 需要 动力 的 时候 马上 爆发 出来 ， 在 安全性 方面 也 是 一个 加强 。 不过 刚才 这 一下子 还是 有点 草率 了 ， 下着雨 还 这么 操作 还是 挺 危险 的 。 以后 可 不敢 了 。 遥想 今年 五一 开 纳瓦拉 回老家 ， 从 服务区 匝道 出来 上 高速 ， 一脚 油门 到底 车子 也 是 干吼 不 走 ， 吓 得 后面 的 大 货车 都 紧急 变 道 了 ， 真是 尴尬 ， 也 是 很 危险 的 情况 。 以后 应该 就 不会 出现 这种 尴尬 的 情况 了 。 周末 去 了 趟 燕山 大峡谷 ， 念叨 了 一年 了 ， 终于 去 了 。 整个 过程 中 车子 的 油耗 让 我 很 惊讶 ， 这么 大 的 车 ， 最后 竟然 能 开出 6.2L/100KM 的 油耗 。 基本上 高速 时 瞬时 油耗 在 7 个 多 ， 国道 如果 保持 100 以下 的 速度 油耗 就 非常低 。 我 的 要求 也 不 高 ， 按 我 的 正常 实用 场景 ， 能 保持 在 10 个 以内 就 行 接受 。 其他 配置 国产车 的 配置 永远 不会 让 人 失望 。 车 内 氛围 灯 什么 的 就 不 说 了 ， 没 啥 用处 的 东西 ， 晚上 开 高速 反倒 变成 了 光污染 。 这里 只 说 一下 我 觉得 非常 有用 的 配置 。Autohold  自动 驻 车 这个 功能 是 非常 吸引 我 的 ， 以前 开 的 车 虽然 也 都 是 自动挡 ， 但 堵车 的 时候 要么 得 一直 踩 着 刹车 ， 要么 就 踩 刹车 、 拉 手刹 、 摘 空挡 ， 起步 的 时候 踩 刹车 、 挂 D 挡 、 松手 刹 ， 这 一套 操作 下来 整个 人 都 很 疲惫 ， 如果 长时间 堵车 右腿 都 要 废 了 ， 大腿 根 疼 的 不行 （ 这里 心疼 手动挡 司机 一秒 ， 不过 右腿 疼 ， 左腿 也 要 疼 ）。 而 Autohold 就是 为了 解决 这个 问题 出现 的 ， 自动 帮助 驾驶员 踩 刹车 ， 起步 的 时候 轻点 油门 就 走 了 。 简直 完美 ， 这个 功能 甚至 让 我 觉得 自动挡 的 车 本来 就 应该 这样 ， 没有 这个 功能 的 车 都 是 不 完整 的 。 解放 右腿 ， 哦 耶 ！ 自 适应 巡航 第一辆 车 没有 定速巡航 ， 开 长途 的 时候 觉得 很 累 ， 当时 很 希望 能 开 一辆 有 定速巡航 的 车 。 第二辆 车 也 没有 定速巡航 ， 提 车 后 毫不犹豫 的 去 加装 了 ， 但 后来 一年 的 使用 中 ， 发现 可用 的 场景 非常少 ， 而且 需要 比 正常 自己 控制 花费 更 多 的 精力 ， 所以 感觉 有些 鸡肋 。 瑞 虎 8 是 我 的 第三辆 车 ， 昨天 在 路上 自己 摸索 了 一下 自 适应 巡航 功能 。 按 自 适应 巡航 开关 打开 功能 设定 与 前 车 保持 的 间距 ， 有 长 / 中 / 短 三个 设置 ， 如果 是 跑 长途 ， 当然 倾向 于 长 。 按 RES- 设定 速度 松开 踏板 之后 车子 就 可以 自己 保持 速度 和 与 前 车 的 距离 了 ， 如果 前方 插入 一辆车 或者 前 车 减速 ， 会 有 明显 的 自动 刹车 减速 ， 与 前 车 的 距离 重新 拉开 之后 又 会 自动 加速 。 这 才 是 “ 巡航 ” 的 意义 所在 嘛 ， 这么 一 比 ， 定速巡航 真的 是 没有 什么 用 。 以后 再也 不用 担心 长途 行车 了 。 后备箱 感应 开启 这个 车 和 其他 的 什么 扫 腿 打开 后备箱 不同 ， 而是 一种 很 独特 的 方式 。 人 带 着 钥匙 站 在 车尾 ， 等 车灯 闪 几下 之后 向 后退 一步 ， 尾 门 就 自动 打开 。 我 个人感觉 这种 设定 比 扫 腿 的 那种 更 实用 ， 想象 拿 了 一大堆 东西 ， 都 站不稳 了 怎么 去 扫 腿 啊 ， 但 前后 移动 一下 还是 可以 的 。 不过 就是 等 的 时间 长 一点 ， 有利有弊 吧 。 这个 东西 我 没有 太 大 感觉 ， 一般 去 超市 也 不会 开车 去 。 碰撞 预警 这个 还是 给 我 留下 了 比较 深刻 的 印象 ， 不过 我 到 现在 也 还是 没有 搞清楚 逻辑 是 什么 。 在 国道 上 和 前 车 比较 近 （ 到底 是 多 近 ？ 不 知道 ） 会 提示 有 车辆 或 行人 靠近 ， 请 注意 ， 但 没有 声音 提示 。 在 市区 开 ， 比如 转弯 时 前 车 有变 道 去 直 行车道 我 需要 加速 跟上 转弯 的 车流 时 ， 会 有 急促 的 碰撞 预警 滴 滴滴 的 声音 ， 不过 也 没有 感受 到 有 主动 刹车 的 介入 。 所以 也 不 知道 什么 情况 下 才 会 触发 主动 刹车 。 不管 怎么样 ， 这个 功能 还是 给 人 一个 很 靠 谱 的 印象 ， 但愿 永远 不会 用到 。 自动 大灯 / 雨 刷 这个 我 倒 觉得 其实 作用 不是 特别 大 ， 开始 开车 第一年 之后 就 再也 没有 忘记 过 开灯 了 。 这种 功能 就 把 人 变成 傻子 了 ， 所有 功能 都 变成 自动 了 ， 人 就 只管 开车 就 完 了 。 不过 瑞 虎 8 这个 车子 的 大灯 控制杆 和 雨 刷 控制杆 手感 不是 特别 好 ， 尤其 是 大灯 的 ， 没有 那种 吸入 感 ， 可能 也 没有 吸入 ， 根本就是 电子 的 。 那天 晚上 为了 晃 一个 远 光 狗 ， 向下 推 了 一下 大灯 控制杆 ， 再 往前走 时 被 对 向 的 车 晃 了 一下 才 发现 刚才 把 远光灯 已经 打开 了 。 我 还 以为 根本 就 没有 推动 呢 。 这个 手感 真是 差 评 。 缺点 毕竟 10 万出头 的 车子 ， 也 不 可能 所有 方面 都 很 完美 。 目前 发现 有 几个 不 舒服 的 地方 。 减震 硬 这个 硬是 真的 硬 ， 尤其 在 一些 县 道 上 遇到 有 坑 时 ， 那 就 感觉 是 硬碰硬 的 感觉 ， 还好 我 出 门前 把 胎 压 从 2.7 调整 到 了 2.4， 不然 估计 就 更 难受 了 。 给 人 的 感觉 就是 这种 情况 下 弹簧 完全 没有 吸收 震动 ， 而且 好像 轮胎 也 是 完全 没有 弹性 ， 不 知道 为什么 会 有 这种 感觉 。 不过 在 过 高速 和 国道 上 的 减速带 时 感觉 就 很 舒服 ， 干净利落 ， 完全 不会 拖泥带水 ， 甚至 都 有点 享受 这种 感觉 。 很 极端 的 体验 。2-3 挡 变速箱 顿挫 这个 在 买 之前 也 看到 有人 说 ， 没想到 还是 挺 明显 的 ， 不过 倒 不是 每次 都 会 有 ， 偶尔 会 顿挫 以下 ， 整体 倒 是 问题 也 不 大 。 今天 早上 转弯 的 时候 踩 刹车 减速 ， 车子 却 突然 加速 了 一下 吓了一跳 。 这个 问题 相对 不 那么 影响 体验 ， 上下班 也 开 了 几天 了 ， 就 遇到 一次 比较 明显 的 顿挫 。 其实 之前 开 纳瓦拉 的 7AT 有时 感觉 更 难受 ， 所以 这个 也 可以 接受 。 不好 停车 相信 我 的 停车 水平 ，5.3 米 的 皮 卡 我 都 开 了 一年 多 ， 这个 车 的 大小 我 还是 没什么 问题 的 。 就是 在 倒车 的 时候 方向感 不好 ， 转动 了 方向盘 ， 但 车尾 总是 不能 很 精确 的 按照 我 的 预期 摆动 ， 我 也 不 清楚 这 是 什么 问题 。 而且 这个 车 的 辅助 功能 太 多 了 ， 一圈 的 雷达 加上 全景 影像 ， 倒 个 车 雷达 一直 滴 滴滴 ， 烦得 慌 ， 都 不 知道 到底 是 应该 按 自己 的 习惯 看 后视镜 还是 看 倒车 影像 了 。 中央 T 型 区 设计 吐 槽 空调 风量 的 调节 按钮 太小 了 ， 而且 是 触 控 按键 ， 很 不好 操作 ， 如果 开车 的 时候 调节 ， 会 有 安全隐患 。 不过 其实 语音 也 可以 控制 ， 只是 我 现在 还 不 习惯 。USB 插口 有 两个 ， 都 在 下方 的 镂空 区域 ， 所以 用 CarPlay 的 时候 手机 就 放在 下面 了 。 但 拿 的 时候 就 不 太 方便 了 。 另外 ， 自动 豪华版 竟然 没有 无线 充电 ， 不得已 我 只能 拿 了 一个 小米 的 无线 充电器 放在 手机 槽 的 位置 了 。。。 该 说 不 说 这个 T 型 区 确实 宽 了 点 ， 导致 前排 主 副驾驶 的 腿部 空间 受 了 影像 。 可能 就是 简单 的 从 捷 豹 路 虎 上面 移植 过来 的 ， 但 没有 考虑 到 毕竟 豪华车 的 宽度 比较 大 ， 所以 没什么 影像 ， 但 瑞 虎 8 只有 1.86 的 车 宽 ， 就 会 影响 了 。 后备箱 的 声音 会 传入 驾驶舱 这 可能 是 SUV 的 通病 ， 毕竟 轿车 、 皮 卡 都 开 过 ， 而 前 两个 尾 厢 和 驾驶舱 都 是 隔离 的 ， 所以 不会 听到 后备箱 里 的 声音 ，SUV 就 不 一样 了 ， 后备箱 里 一瓶 水 滚动 的 声音 都 听 的 清清楚楚 。 总结 落地 12.5 的 车子 ， 配置 高 的 一 比 ， 动力 也 很 强 ， 唯一 的 不 舒服 的 感受 比较 强烈 的 就是 减震 ， 其他 真的 不是 为什么 严重 的 问题 ， 所以 也 可以 接受 了 。 这辆 车 没什么 问题 的话 可能 会 开 很多年 了 。","title":"2020 款 奇瑞 瑞 虎 8 用车 体验 ","oriTitle":"2020款奇瑞瑞虎8用车体验","categories":["life"],"date":"2020-09-23T01:56:14.000Z"},{"uri":"/post/life/tiggo8-second-1000-km","tags":["tiggo8"],"content":" 其实 已经 2500 公里 了 。 这 是 11 月份 去 北京 双龙 峡 景区 时 的 照片 。 我 总是 不好意思 给 自己 的 车 拍 很多 照片 ， 总 感觉 有点 矫情 ， 一辆车 而已 嘛 ， 但 其实 在 心里 有 惹 不住 对 它 的 喜爱 之 情 。 这 段时间 开 下来 对 这辆 车 的 脾气 更 多 了 一些 了解 。 关于 修车 今天 终于 去 把 之前 提到 的 4G 和 GPS 信号 丢失 的 问题 去 修好 了 ， 其实 前 几天 已经 去过 一次 了 ， 检查 了 一遍 复现 了 问题 ， 售后 的 总监 亲自 接待 的 我 ， 其实 是因为 车机 的 问题 只能 找 他 修 ， 可能 是 和 与 厂家 沟通 的 权限 有关 。 和 厂家 的 工程师 确认 是 Tbox 模块 的 问题 之后 先是 把 电瓶 线 拔掉 让 Tbox 模块 重置 设置 ， 意思 是 如果 解决 就 皆大欢喜 ， 如果 没有 解决 ， 再 出现 的 时候 就 拍 个 照片 把 时间 拍 出来 发给 他 ， 这样 他 就 能 把 详细情况 发给 厂家 具体 排查 。 当时 是 好 了 ， 但 一开 上 五环 ， 马上 就 复现 了 故障 ， 我 拍 了 几张 照片 ， 他 说 他 订 模块 ， 结果 过 了 几天 我 再 问 的 时候 他 说 厂家 还 没 给 回复 ， 所以 模块 也 还 没 订 。 这时候 我 已经 有点 生气 了 ， 合 着 刚 说 过 的话 还 不作数 了 。 但 下午 就 给 我 回信 说 厂家 已经 确认 了 是 硬件 故障 ， 新 的 Tbox 模块 也 已经 到货 了 ， 让 我 抽时间 去 换上 ， 于是 今天 就 去 了 。 本来 说 的 是 可能 需要 很 长时间 ， 但 实际上 换 的 过程 也 不 复杂 ， 这个 模块 的 位置 在 手套 箱 里面 ， 就是 这么 个 东西 它 承担 了 汽车 上面 所有 涉及 网络 的 功能 ， 包括 远程 控制 、4G 信号 、GPS 信号 等等 ， 我 估计 豪华版 和 以下 的 其他 配置 的 主要 区别 也 就 在 这里 了 。 估计 也 就 10 分钟 就 换上 了 ， 后面 就是 和 厂家 的 沟通 ， 做 各种 匹配 了 ， 前后 一共 也 就 一个多 小时 ， 远远 小于 预期 时间 了 ， 重点 是 换上 之后 问题 真的 解决 了 。 后面 回家 的 路上 再也 没有 出现 这个 问题 。 说来 也好 笑 ， 我 本来 想 给 国产车 一个 机会 ， 结果 我 一边 通过 它 的 动力 、 底盘 告诉 别人 奇瑞 的 车子 真的 不 差 ， 但 一方面 别人 却 真 真的 看到 了 我 买 了 国产车 之后 去 修车 跑 了 两次 ， 这 在 我 之前 开 的 两辆车 过程 中 是 从来 没有 出现 过 的 。 你 说 以后 我 还 会 不会 支持 国产车 ？ 我 想 大概 还是 会 的 。 我 对 “ 爱国主义 ” 这种 情感 的 诉求 并 不 强烈 ， 纯粹 是因为 这种 故障 不是 什么 大 问题 ， 换 了 件 能 解决 就行了 ， 而且 也 不是 大规模 出现 的 ， 甚至 都 很 难 在 网上 或者 车友 群 问 到 同样 的 问题 ， 说明 确实 不是 通病 ， 只是 我 的 运气 比较 差 碰到 了 而已 ， 况且 售后 能 很 轻松 的 给 解决 了 ， 所以 问题 不 大 。 更 多 关于 驾驶 感受 的 描述 还是 关于 底盘 硬 的 问题 。 很 可能 纯粹 就是 车子 出厂 的 时候 胎 压 太 高 了 而已 。 我 自己 的 车子 开 到 家 的 时候 胎 压 是 2.7， 确实 很 硬 ， 后面 我 给 放到 了 2.4， 开 起来 就是 完全 不同 的 感受 了 。 我 看 车友 群 里 有人 的 胎 压 甚至 是 3.1， 而且 也 没有 调整 ， 很 可能 就是 这 完全 不 懂 车 的 人 到处 宣传 车子 的 底盘 很 硬 吧 。 再 后来 因为 天气 变冷 ， 我 发现 冷 车 状态 下 胎 压 只 剩下 2.1 了 ， 所以 就 重新 调 到 了 2.5， 然后 就 明显 感觉 到 重新 变硬 了 。 结论 就是 ： 硬 不 硬 很大 程度 上 取决于 胎 压 ， 胎 压 高 了 （2.5-2.6） 开 起来 动力性 会 稍 强 一些 ， 更 干脆 ， 而 胎 压低 了 （2.3-2.4） 会 更 柔韧 ， 动力 响应 上 会 有些 损失 ， 不过 舒适型 会 提升 很多 。 而 不管 胎 压 怎样 ， 在 转弯 时 侧 倾 的 抑制 上 做 的 非常 好 ， 去 双龙 峡 的 路上 有 几十公里 的 山路 ， 有 机会 超车 时 ECO 模式 多少 有点 力不从心 ， 切换 到 SPORT 模式 那 简直 是 起飞 了 ， 毫无 压力 。 至于 高速 感受 ， 那 更是 游刃有余 了 ， 超车 变 道 非常 有 信心 ，ECO 模式 下 就 有 非常 好 的 动力 响应 ， 加上 全速 域 的 自 适应 巡航 ， 简直 不要 太 好 开 。 更 气 人 的 是 油耗 还 非常低 ， 高速 保持 在 120 以内 基本上 就是 6 个 多点 的 水平 ， 要 知道 这 是 一台 中型 SUV（ 从 尺寸 上 说 确实 达到 了 ， 只是 在 中型 这个 级别 里 算是 小 的 ） 了 ， 和 同级 别的 合资 车 比 油耗 都 完全 不 虚 。 关于 油耗 开 过 了 以 动力 差 、 油耗 低 著称 的 铃木 启 悦 （A 级 轿车 表显 8 个 多 ， 所以 是否 油耗 低 要 存疑 ）。 开 过 了 以 动力 差 、 油耗 高 著称 的 日产 纳瓦拉 。 再 来 开 动力 强 、 油耗 低 的 奇瑞 瑞 虎 8（ 高速 6 个 多 ， 市区 拥堵 驾驶 风格 激进 时 11 个 多 ）， 我 对 油耗 表现 还是 非常 满意 的 。 也许 堵车 环境 下 慢慢悠悠 的 加速 能 把 油耗 保持 在 10 个 以内 ， 也许 听 别人 的 隔 几天 去 拉拉 高速 ， 把 表显 油耗 拉 低 一点 在 车友 群 里 晒 一下 能 引起 别人 的 关注 ， 可 这 有 什么 意义 呢 ？ 现在 这个 油耗 是 我 的 真实 用车 场景 ， 我 愿意 为了 更好 的 加速 性能 和 更 流畅 的 驾驶 体验 牺牲 一些 油耗 ， 况且 也 就是 最 多多 2 个 油 而已 ， 完全 值 回 票价 了 。 关于 选 车 我 对 汽车 相关 的 话题 比较 关注 ， 经常 看到 很多 人 让 别人 告诉 自己 到底 是 该 选 SUV 还是 选 轿车 ， 这个 问题 是 永远 没有 结果 的 ， 因为 这 是 个 非常 主观 的 问题 ， 只有 自己 能 给出 答案 。 对应 的 ， 我们 也 经常 看到 有人 说 中国 人 不 懂 车 ， 喜欢 大车 所以 都 喜欢 买 SUV， 就是 好 面子 ； 我们 也 经常 看到 这些 人 说 美国 人 懂 车 ， 他们 因为 地广人稀 ， 需要 拉 货 所以 喜欢 皮 卡 和 SUV， 就是 讲 实用性 。 简直 是 大型 双 标 现场 。 你 可以 说 中国 人 不 懂 修车 ， 在 动手 修车 方面 ， 由于 修车 的 费用 相对 还是 比 美国 低 （ 具体 加 个 不 知道 ， 但 美国 是 以 人工 费用 高 著称 的 ， 要么 谁 愿意 自己 费劲 给 车子 保养 呢 ？）， 所以 更 多 人 还是 选择 去 店里 修车 ， 但 中国 人 还是 懂得 自己 的 需求 。 目前 国内 的 汽车 保有量 还是 不够 大 ， 一家子 几口 人 就 一辆车 ， 他们 想 买 一辆 大 的 车 是 为了 满足 全家人 的 出行 需求 ， 基于 这个 需求 买 一辆 空间 和 装载 能力 更 强 的 SUV 有 什么 问题 呢 ？ 美国 人 基于 自己 地广人稀 、 搬家 拉 货 的 需求 买 大车 是 懂 车 。 欧洲人 基于 自己 街道 狭窄 、 不好 停车 的 需求 买 小车 是 懂 车 。 中国 人 基于 自己 预算 有限 、 乘坐 舒适 的 需求 买 大车 就是 不 懂 车 。 我 TM 直接 好家伙 ， 这些 人 什么 时候 才能 站 起来 啊 。 关于 奇瑞 “ 老实 ” 的 奇瑞 终于 明白 怎么 回事儿 了 ， 哈 弗 H6 你 搞 一个系列 上 百款 车型 一起 卖 ， 统计 销量 的 时候 归 到 一个 车型 系列 上 ， 那 我们 也 来 个 瑞 虎 8 系列 ， 销量 从 10 月份 的 1.6 万辆 直接 就 到 了 11 月 的 2 万辆 ， 要 知道 瑞 虎 8PLUS 刚刚 上市 ， 瑞 虎 8 的 车友 群 里 已经 混进 了 不少 PLUS 的 潜在 客户 了 ， 产品 力 够 硬 的 东西 还是 能够 打动 用户 的 。 如果 再 加上 捷 途 甚至 已经 超过 4 万辆 了 ， 和 哈 弗 H6 也 差 不了 太 多 了 。 可惜 捷 途 是 奇瑞 控股 的 商用车 公司 搞 出来 的 ， 你 让 它们 一起 统计 那 是 不 可能 的 。 总结 后面 可能 不会 再 写 关于 这辆 车 的 更 多 内容 ， 能 体验 的 到 现在 也 体验 的 差不多 了 ， 总之 这辆 车 有 很 强 的 家用 属性 ， 给 人 很 居家 过日子 的 感觉 ， 但 同时 又 提供 了 澎湃 的 动力 ， 让 你 一个 人 开车 的 时候 还 能 稍稍 的 激情 一把 ， 而 车里 的 各种 功能 也 是 很多 恰到好处 。 对 了 ， 买 了 车 之后 听 车友 群 里 说 9 月 中旬 之后 的 车 都 已经 装配 了 自动 启 停 功能 ， 他们 几乎 都 在 找 能够 永久 关闭 的 方法 ， 恰恰 我 的 9 月 2 日 生产 的 这 批次 是 没有 这个 功能 的 ， 美滋滋 。 厂家 花 了 钱 装 了 ， 所有人 都 不用 ， 还 不如 把 自动 启 停 模块 的 钱 拿来 加 个 雾灯 了 ， 真是 费力 不 讨好 。 彩蛋 晒 一下 在 售后 拍 到 的 一些 照片 。 老 车 的 漆 面 保护 的 真不错 。 这个 还是 能 看 出来 是 辆 硬派 越野 ， 甚至 后来 有 一天 我 在 路上 也 看到 一辆 贴着 越野 大队 什么 的 贴纸 。 被 人 吐 槽 丑 ， 然后 又 被 另 一 波 人 说 如果 你 说 这 车 丑 ， 就 等于 说 Q5 丑 的 捷 途 。 不过 其实 还 真是 差 挺 多 的 ， 线条 就是 不 流畅 。 一辆 正在 维修 中 的 奇瑞 电动 面包车 ， 生锈 挺 厉害 啊 ， 不 知道 这 卷 边 是因为 之前 顶错 地方 了 还是 生锈 了 才 顶 坏 的 。 这 让 我 对 车子 防锈 处理 开始 有点 怀疑 了 。 这 是 我 自己 的 车子 ， 后面 的 小窗 下 沿 不 知道 哪里 来 的 油渍 ， 刚 提 车 的 时候 擦 过 一次 ， 后来 也 洗 过 车 ， 不 知道 怎么 又 出现 了 。 店里 的 维修 人员 说 这里 也 没有 油液 ， 也 说不上来 是 哪里 出来 的 ， 让 擦 干净 后 再 观察 。","title":" 瑞 虎 8 2000 公里 感受 ","oriTitle":"瑞虎8 2000公里感受","categories":["life"],"date":"2020-12-02T14:28:03.000Z"},{"uri":"/post/life/tiggo8-upgrade-apps","tags":["tiggo8"],"content":" 瑞 虎 8 自豪 版 车机 里 的 App 可以 升级 。 据说 是 官方 正规 的 方法 。 声明 ： 我 认为 中 控 屏幕 车机 和 行车 安全 没有 关系 ， 是 隔离 的 系统 ， 但 行车 系统 的 一些 参数 可以 通过 种 控 屏 设置 ， 如果 对 安全性 有 担忧 ， 请勿 尝试 以下 操作 准备 工作 硬件 需求 电脑 一台 U 盘 一个 （ 需要 FAT32 格式 ）， 用于 存放 要 安装 的 包 操作 流程 1.  下载安装 包 下载 最新版 的 高 德 地图 2.  在 U 盘 上 建立 必要 的 目录 在 U 盘 上 新建 T1AUpdateNavi/App/ 目录 ， 将 上述 下载 的 安装包 放在 里面 。3.  车机 进入 工程模式 车 机上 有 一个 隐藏 按键 ， 在 设置 / 存储容量 界面 的 右侧 1/4 处 的 下 边缘 附近 ， 点击 听到 “ 滴 ” 声 即 是 点击 成功 了 。 在 这个 位置 连续 点击 10 下 ， 进入 工程模式 。 随后 输入 密码  456258， 其实 就是 一个 十字形 。 之后 会 进入 这个 界面 ， 点击 “ 升级 ” 再 点击 “App 升级 ” 就 可以 进入 U 盘中 刚才 创建 的 目录 了 。 找到 高 德 地图 的 安装包 ， 点击 勾 选 ， 之后 点击 右上角 的 “ 安装 所 选 ” 即可 开始 安装 。>  我 这里 还 自动 生成 了 一个 以 . 开头 的 apk 包 ， 不 知道 是 什么 原因 ， 忽略 它 即可 ， 选择 不 以 . 开头 的 文件 。 安装 完成 后 选中 条目 变成 绿色 ， 即 完成 安装 。 按照 提示 重启 系统 就 完成 了 升级 。 警告 不 建议 安装 其他 “ 原 装车 机上 不 存在 的 应用 ”， 简单 来说 就是 你 安装 完 也 无法 找到 入口 ， 也 就 没 办法 使用 。 亲 测 。 如果 你 已经 安装 了 无法 使用 的 其他 应用 ， 可以 使用 Android 手机 安装 一个 Remote ADB Shell 软件 来 卸载 ， 当然 理论 上 不管 它 也 不会 有 什么 问题 。 总结 升级 后 的 App 色彩 更 鲜艳 ， 功能 上 实现 了 和 手机 的 实时 互联 ， 手机 上 “ 进入 导航 ” 后 ， 车机 如果 在 联网 状态 会 自动 同步 手机 上 的 导航 状态 ， 非常 方便 。 推荐 升级 。","title":" 瑞 虎 8 车机 App 升级 ","oriTitle":"瑞虎8车机App升级","categories":["life"],"date":"2020-12-30T07:18:16.000Z"},{"uri":"/post/linux/python-in-a-nutshell","tags":["python","bash"],"content":"Python 虽然 简单 ， 但 长时间 不 写 还是 忘 ， 记录 一些 常用 的 片段 。1.  脚本 中 出现 中文 时报 错 python2 默认 是 不 识别 中文 编码 的 ， 头部 需要 这么 写 #!/usr/bin/env python-- coding: utf-8 --python3 默认 就 支持 UTF-8 了 ， 这个 也 就 不 需要 了 。2.  获取 本 机 IP#!/usr/bin/env python-- coding: utf-8 --import netifaces as nidef get_hostname():\treturn ni.ifaddresses('eth0')ni.AF_INET['addr']3.  判断 一个包 是否 已经 安装 #!/usr/bin/env python-- coding: utf-8 --import osoutput = os.popen('rpm -q jdk1.8').readlines()for line in output:    print(line)> os.popen('cmd').readlines() 和 os.system('cmd') 的 区别 在于 前者 会 把 命令 的 输出 保存 到 output 中 ， 而 后者 则 不会 ， 所以 如果 需要 关注 命令 的 输出 ， 就 用 前面 这个 。4.  下载 一个 文件 #!/usr/bin/env python-- coding: utf-8 --import urlliburllib.urlretrieve(URLJDK8, filename='/data1/jdk-8u231-linux-x64.rpm')>  如果 文件 已经 存在 ， 则 会 覆盖 5.  检查 文件 是否 存在 #!/usr/bin/env python-- coding: utf-8 --import osif os.path.isfile('/path/to/file'):    print(' 文件 存在 ')","title":"Python 的 一些 实用技巧 ","oriTitle":"Python的一些实用技巧","categories":["linux"],"date":"2020-11-27T08:37:50.000Z"},{"uri":"/post/linux/shell-in-a-nutshell","tags":["bash","python"],"content":"Shell 总 认为 很 简单 ， 每 到 写 的 时候 总是 不会 写 。 这里 总结 了 写 shell 脚本 时 经常 会 遇到 的 问题 。1. sudo  无法 修改 文件 ， 而 sudo -s 切换 到 root 后 可以 比如 本来 是  sudo echo 'hahaha' > /etc/abcde， 改成 sudo sh -c \"echo 'hahaha' > /etc/abcde\"  即可 。2.  从 可信 站点 下载 脚本 直接 执行 而 不 需 保存 要 怎么弄 ？wget wget -0 - https://a.b.c/trusted-script.sh | shcurl curl -o - https://a.b.c/trusted-script.sh | sh>  如果 是 其他 脚本 ， 后面 换成 相应 的 解释器 如 python 即可 ","title":"Shell 的 一些 实用技巧 ","oriTitle":"Shell的一些实用技巧","categories":["linux"],"date":"2020-11-27T08:29:38.000Z"},{"uri":"/post/mac-faster-key-repeat","tags":["key-repeat"],"content":"macOS 上 用 Vim 觉得 很 卡 顿 ， 不 流畅 ， 终于 找到 原因 了 。 有 两个 相关 设置 这 两个 把 Key Repeat 设置 到 最快 ， 把 Delay Until Repeat 设置 到 最 短 ， 但 实际上 这么 设置 之后 还是 不够 ， 再 小 就 不能 通过 配置 页面设置 了 ， 只能 通过 命令行 设置 了 。 我 觉得 合适 的 配置 是 这样 的 defaults write -g InitialKeyRepeat -int 10defaults write -g KeyRepeat -int 1 这样 之后 再 操作 就 明显 流畅 多 了 。","title":"macOS 设置 Key Repeat 和 Delay Until Repeat","oriTitle":"macOS设置Key Repeat和Delay Until Repeat","categories":["macOS"],"date":"2020-11-21T14:48:25.000Z"},{"uri":"/post/macos-service-management","tags":["homebrew","macOS"],"content":" 用 了 5 年 macOS 也 一直 没有 用 过 苹果 原生 的 服务 管理 、AppleSript 等等 ， 总 感觉 不够 直观 ， 好 在 还有 Homebrew 这个 神器 ， 帮 我 解决 了 很多 问题 。 对于 通过 homebrew 安装 的 服务 ， 可以 通过 其 提供 的 brew services 或者 服务 自带 的 命令 进行 管理 。 这里 只 记录 了 两种 ， 其他 需要 查看 启动 方法 的 可以 通过 brew info 命令 查看 。MySQLbrew install mysqlmysql.server startmysql.server stopZooKeeperbrew install zookeeperbrew services start zookeeper #  后台 启动 zkServer start #  前台 启动 `","title":" 使用 Homebrew 管理 macOS 上 的 服务 ","oriTitle":"使用Homebrew管理macOS上的服务","categories":["macOS"],"date":"2020-03-29T02:53:04.000Z"},{"uri":"/post/ryzentosh","tags":["amd","hackintosh","macOS"],"content":" 实在 是 受不了 MBP13 孱弱 的 性能 和 糟糕 的 发热 ， 终于 下定决心 组装 一台 台式机 。 最终 还是 真 香 。 本文 操作过程 基于 白 苹果 ，Windows 环境 的 小伙伴 可 参考 其他 教程 >  本次 操作 的 大部分 流程 都 基于 opencore-vanilla-desktop-guide， 感谢 国内外 友人 对 黑 苹果 作出 的 卓越贡献 。 用 过 两个 MacBookPro， 最大 的 感觉 就是 用 起来 很 方便 （ 我 是 一个 软件 开发者 ）， 但 性能 实在 是 太弱 鸡 了 ， 严重 影响 了 效率 。 以至于 黑 苹果 安装 完成 之后 我 发现 原来 的 过渡 动画 竟然 不见 了 。。。 对 ， 就是 这么 明显 。 准备 阶段 为了 这个 黑 苹果 ， 我 全新 配置 了 一台 台式机 ， 配置 也 是 改了又改 ， 最终 性能需求 战胜 了 便携性 ， 选择 了 一台 MATX 机箱 。 选择 配置 考虑 的 问题 如下 ：1. CPU 我 就是 需要 一个 性能 强劲 的 CPU 和 足够 的 内存 。 本来 想着 上 i7 9700KF， 但 如果 上 了 这个 CPU， 就 还 需要 配 一块 Z390 主板 ， 成本 太 高 了 就 失去 了 黑 苹果 的 意义 了 。 当然 AMD YES!!! 我 知道 AMD 的 黑 苹果 可能 遇到 更 多 的 问题 ， 本着 遇到 问题 解决问题 的 态度 ， 还是 硬着头皮 上 了 。2.  主板 主板 也 是 在 华硕 的 Tuf B450 Pro Gaming 和 微星 的 迫击炮 MAX 之间 纠结 了 很 久 ， 最终 还是 随大流 选择 了 迫击炮 。 这里 提个醒 ，3600 原装 的 CPU 散热器 和 内存 插槽 会 有 冲突 ， 如果 不让 它 和 内存 插槽 有 冲突 ， 它 就 会 和 朝 后 的 IO 接口 散热片 有 冲突 。 我 只 在 A2 和 B2 两个 位置 插 了 内存 ， 所以 还好 。 如果 你 用 塔式 散热器 可能 也 不 存在 这个 问题 ， 但 我 不 确定 会 不会 出现 其他 的 问题 。3.  显卡 推荐 的 最 多 的 就是 RX 580 2304SP， 但 现在 几乎 已经 买不到 全新 的 满血 版本 了 ， 一天 在 京东 看到 了 盈 通 的 RX 580  游戏 高手 ， 惊喜 的 发现 竟然 是 满血 版本 ， 而且 还是 三 风扇 设计 。 由于 我 对 显卡 的 性能 要求 不 高 ， 所以 一般 也 不会 满载 ， 功耗 什么 的 应该 也 没有 太 大 的 区别 。 虽然 1119 不是 什么 好 价格 （ 毕竟 听说 之前 有 蓝宝石 999 的 RX 590 OC）， 但 对比 价格 高 了 300 块 但 性能 差不多 的 RX  5500XT 还是 更 合适 一点 。4.  内存 16G 应该 足够 了 ， 尤其 是 现在 内存 涨价 那么 厉害 的 时候 ， 芝 奇 Snipper X 3200 8Gx2， 迷彩 马甲 ， 看起来 还 可以 。5.  其他 机箱 和 硬盘 就 没 啥 说 的 了 ， 硬盘 只要 不 选择 三星 PM981 就行了 。 而且 我 这次 也 没有 买 硬盘 。6.  机箱 风扇 本来 以为 机箱 风扇 并 不是 必须 用品 ， 而且 我 也 不 玩游戏 ， 想必 机器 的 负载 不会 很 高 ， 但 实际 使用 中 发现 玻璃 侧板 还是 有点 温热 的 。 想来 也 是 ， 因为 CPU 的 风扇 把 热风 吹 到 玻璃 侧板 上 ，GPU 的 风扇 往 下 吹 ， 不管 怎么样 都 没有 让 热空气 往 外 走 的 路径 。 于是 在 机箱 背部 和 上部 各 安装 了 一把 12 厘米 的 风扇 ， 效果 立竿见影 ， 玻璃 侧板 一直 冷冰冰 了 。 配置 单 |  配件      |  型号                                            |  价格  || -------- | ---------------------------------------------- | ---- || CPU+ 主板  | AMD 3600 + MSI Motar MAX                       | 1919 ||  显卡      |  盈 通 RX580 游戏 高手                               | 1119 ||  内存      |  芝 奇  Snipper X 3200 8GB x 2                    | 598  ||  机箱      |  先 马 平头 哥 M1                                   | 159  ||  硬盘      |  浦 科特 M6M（2014 年 的 存货 ）+ 一块 HGST 的 500G 机械 盘  | 0    ||  优盘      |  闪 迪 Cruzer Glide 3.0 32GB                      | 29.9 ||  机箱 风扇  |  追风 者 工 包 RGB 2 把 ， 型号 未知                     | 39.8 | 安装 过程 1.  制作 安装盘 格式化 优盘     虽然 这个 看起来 是 最 简单 的 ， 但 我 偏偏 是 在 这里 出 了 问题 。    注意 这 两个 选项 ， 如果 你 默认 选中 的 是 第一个 ， 则 在 抹掉 优盘 的 时候 就 找 不到 分区表 的 方式 ， 如下 图 所示     如果 选择 了 Show All Devices， 就 如下 图 所示 2.  下载 必备 软件包 1.  下载 操作系统 从 Mac AppStore 下载 最新 的 macOS Catalina 10.15.3， 然后 执行 sudo /Applications/Install\\ macOS\\ Catalina.app/Contents/Resources/createinstallmedia --volume /Volumes/MyVolume2.  下载 MountEFI 执行 ./MountEFI.command， 会 弹 出 正常 制作 完 USB 启动盘 之后 会 有 一个 上 图标 红 的 挂载 点 ， 选 它 就行了 。 然后 输入 密码 ， 这时 在 Finder 里 会 看到 有 一个 EFI 挂载 点 ， 正常 是 空 的 。 后面 配置 完 OpenCore 之后 把 EFI 目录 放在 里面 就行了 。3.  配置 config.plist 这 是 整个 过程 最 复杂 的 一步 了 ， 但 只要 按照 我 在 文章 开头 附上 的 链接 一步步 操作 ， 肯定 不会 有 问题 。 不得不 说 ， 那个 教程 真是 严谨 。 甚至 还有 一个 配置 检查 器 ， 如果 有 问题 可以 提前 发现 ， 避免 直接 上机 执行 反复 重启 浪费时间 。 不过 这里 我 就 不 详细描述 了 ， 只 把 最终 我 配置 好 的 EFI 目录 放在 这里 ， 供 大家 直接 使用 。 使用 优盘 启动 优盘 插 到 台式机 的 USB 上 ， 启动 时 按 F11 选择 启动项 ， 选择 那个 很 明显 是 优盘 的 选项 。 然后 就 开始 跑 代码 了 ， 之后 就 一步 一步 的 进行 安装 过程 。 进入 系统 之后 先 不要 做 任何 配置 ， 因为 你 可能 还 没有 安装 成功 。 这时候 系统 还 只能 从 优盘 启动 ， 如果 拔 了 优盘 ， 就 看不到 黑 苹果 的 启动项 了 。 免 优盘 启动 其实 仔细 想 下 就 知道 是因为 你 安装 了 黑 苹果 的 磁盘 没有 优盘 里面 的 那个 EFI 目录 （ 当然 不 只是 目录 ）。 所以 问题 也 就 迎刃而解 了 。 在 新 安装 的 黑 苹果 执行 MountEFI， 选择 优盘 ， 把 优盘 里 的 EFI 目录 整个 复制到 桌面上 。 然后 把 优盘 卸载掉 ， 再 挂载 你 安装 了 黑 苹果 的 系统盘 。 这时 就 看到 了 系统盘 里面 的 EFI 挂载 点 ， 然后 把 刚才 放在 桌面上 的 EFI 目录 放在 系统盘 的 EFI 挂载 点 里 。 这时 你 的 系统 就 可以 不用 优盘 启动 了 。 你 可能 会 问 ， 为什么 不能 同时 挂载 两个 ， 直接 拖 过去 呢 ？ 放在 桌面上 这 一步 看起来 很多 余 。 其实 上述 的 文档 里 专门 提到 了 这 一点 ， 因为 如果 系统 同时 有 两个 EFI 被 挂载 了 ， 它 可能 就 懵 逼 了 ， 为了 避免 不必要 的 麻烦 ， 还是 事先 麻烦 一点 好 。 不过 这时候 启动 还是 会 跑 代码 ， 我 觉得 无所谓 ， 就 还 没有 花 时间 研究 。 总结 现在 基本上 能 正常 使用 了 ， 几个 不 太 重要 的 问题 还 没有 解决 。iService 不能 用 ， 因为 没有 找到 合适 的 Serial Number， 也 就是 序列号 。 教程 中 的 序列号 生成器 生成 的 序列号 ， 去 苹果 官 网上 总是 验证 不 通过 ， 验证 不 通过 也 不 影响 使用 AppleID， 只是 无法 使用 iMessage 等 我 不用 的 服务 ， 所以 无所谓 了 。 启动 时 跑 代码 ， 这个 应该 就是 一个 DebugVerbose 模式 ， 我 还 没有 仔细 研究 ， 无关紧要 了 。 实际上 只要 在 config.plist 中 找到 boot-args， 把 后面 的 值 里面 的 -v 删掉 就 可以 了 。 我 用 的 是 有线 网络 ， 所以 蓝牙 、 无线 还 未 配置 ， 也 没有 计划 研究 了 。 补充 后来 发现 一些 比较 头疼 的 问题 无法 睡眠 、 休眠 ： 点击 睡眠 后 总是 黑屏 1 秒 后 重新 唤醒 ， 不 知道 是不是 什么 驱动 没有 装 好 的 问题 ， 而且 我 也 不 知道 台式机 睡眠 会 是 什么 样子 。。。 机箱 前面板 的 USB2.0 接口 无法 使用 ： 根本 不 通电 ， 检查 了 线缆 应该 是 插错 ， 由于 没有 Windows 系统 ， 也 就 无法 验证 。 不过 好 在 我 也 用 不到 这 两个 插口 ， 所以 无所谓 了 。","title":"AMD 黑 苹果 的 装机 经验 ","oriTitle":"AMD黑苹果的装机经验","categories":["ryzentosh"],"date":"2020-03-29T02:49:38.000Z"},{"uri":"/post/sed-in-a-nutshell","tags":["sed","linux"],"content":" 有时候 需要 批量 处理 一些 文件 ， 又 不 方便 打开 文件 ， 所以 sed 还是 很 有用 的 。 简单 记录 一下 常用 的 使用 方法 。 本文 介绍 的 用法 仅仅 针对 GNU/sed，BSD 的 版本 （macOS） 会 有 不同 ， 这里 不 涉及 简介 先 看 一下 手册 的 介绍 sed [OPTION]... {script-only-if-no-other-script} [input-file]... 选项 | 选项 | 解释 |---|---|-f|(file) 将 sed 命令 保存 到 文件 来 执行 ||-i|(in-place) 就 地 修改 ， 默认 是 将 修改 后 的 目标 文件 内容 输出 到 标准 输出 ， 而 不会 对 目标 文件 进行 修改 ||-n| 取消 默认 输出 ， 在 将 目标 文件 的 内容 输出 到 标准 输出 时 ， 只 输出 处理 过 的 行 ||-e| 接下 一个 sed 指令 ， 只有 在 指定 多个 sed 指令 时 需要 用到 | 编辑 命令 | 命令 | 解释 ---|---a|(append) 追加 c|(change) 更改 匹配 行 的 内容 i|(insert) 向 匹配 行前 插入 内容 d|(delete) 删除 匹配 的 行 s| 替换 掉 匹配 的 内容 p|(print) 打印 匹配 的 行 ， 通常 和 -n 选项 一起 使用 =| 用来 打印 被 匹配 的 行 的 行号 n|(next) 读取 下 一行 ， 遇到 n 时会 跳入 下 一行 r|(read) 将 内容 读入 文件 w|(write) 将 匹配 内容 写入 文件 示例 原始 文本 spongebobsquarepatrickstar 追加 在 指定 行 后面 追加 $ sed '3apants' test.txtspongebobsquarepantspatrickstar 其中 3 是 行号 ，a 是 追加 ， 后面 是 要 追加 的 内容 在 匹配 行 后面 追加 $ sed '/square/apants' test.txtspongebobsquarepantspatrickstar 其中 用 square 来 匹配 行 ， 第二个 / 后面 的 a 表示 追加 ， 后面 是 追加 的 内容 。 如果 有 多个 匹配 行 ， 则 会 在 每个 匹配 行 后面 都 追加 在 最后 一行 追加 $ sed '$abikini bottom' test.txtspongebobsquarepatrickstarbikini bottom$ 表示 最后 一行 ，a 表示 追加 ， 后面 是 追加 的 内容 插入 在 指定 行 插入 $ sed '4ipants' test.txtspongebobsquarepantspatrickstar 表示 在 第 4 行 前面 插入 一行 在 匹配 行前 插入 $ sed '/patrick/ipants' test.txtspongebobsquarepantspatrickstar 如果 有 多个 匹配 行 ， 则 每个 匹配 行 前面 都 会 插入 指定 的 内容 在 最后 一行 前 插入 $ sed '$iis a pink' test.txtspongebobsquarepatrickis a pinkstar 更改 更改 指定 的 行 $ sed '1c 海绵 ' test.txt 海绵 bobsquarepatrickstar 更改 匹配 的 行 $ sed '/sponge/c 海绵 ' test.txt 海绵 bobsquarepatrickstar 更改 最后 一行 $ sed '$c 派 大 星 ' test.txtspongebobsquarepatrick 派 大 星 删除 删除 指定 的 一行 $ sed '3d' test.txtspongebobpatrickstar 删除 指定 范围 行号 的 多行 $ sed '1,3d' test.txtpatrickstar 从 第 n 行 开始 ， 每隔 m 行 删除 一行 $ sed '1~3d' test.txtbobsquarestar 即 从 第一行 开始 ， 每隔 3 行 删除 一行 ， 所以 最终 是 删除 了 第 1 行 和 第 4 行 。 如果 是 1~2d 这样 会 更有意义 ， 也 就是 会 删除 奇数 行 ， 而 2~2d 则 会 删除 所有 的 偶数 行 删除 除 满足条件 的 行 之外 的 所有 行 frost@master:~/workspace/sed$ cat test.txtspongebobsquarepatrickstarfrost@master:~/workspace/sed$ sed '1~3d' test.txtbobsquarestarfrost@master:~/workspace/sed$ sed '1~3!d' test.txtspongepatrick 这个 比较复杂 ， 把 对应 的 几种 情况 放在 一起 看 。 删除 某 范围 之外 的 所有 行 frost@master:~/workspace/sed$ cat test.txtspongebobsquarepatrickstarfrost@master:~/workspace/sed$ sed '1,2d' test.txtsquarepatrickstarfrost@master:~/workspace/sed$ sed '1,2!d' test.txtspongebob 删除 匹配 的 行 $ sed '/patrick/d' test.txtspongebobsquarestar 删除 匹配 行 及其 后 的 n 行 $ sed '/square/,+1d' test.txtspongebobstar 删除 匹配 的 行 之后 的 所有 行 $ sed '/patrick/,$d' test.txtspongebobsquare 可以 和 上面 直接 指定 行号 的 对比 一下 ， 其实 /patrick/ 这部分 就是 为了 定位 到 这 一行 的 行号 ， 假如 这 行 在 第 2 行 ， 那么 这 就 等价 于 2,$d 删除 最后 一行 $ sed '$d' test.txtspongebobsquarepatrick 删除 所有 的 空行 frost@master:~/workspace/sed$ cat test.txtspongebobsquarepatrickstarfrost@master:~/workspace/sed$ sed '/^$/d' test.txtspongebobsquarepatrickstar 删除 匹配 多种 模式 的 行 $ sed '/sp\\|bob/d' test.txtsquarepatrickstar 删除 除 匹配 多种 模式 以外 的 所有 行 $ sed '/sp\\|bob/!d' test.txtspongebob 删除 指定 行 范围 内 满足条件 的 行 $ sed '1,4{/e/d}' test.txtbobpatrickstar 删除 了 从 第 1 行 到 第 4 行 中 包含 e 的 行 替换 指定 字符 终于 到 了 用 的 最 多 的 场景 了 。 替换 匹配 的 字符 frost@master:~/workspace/sed$ cat test.txtspongebob bob bobsquarepatrickstarfrost@master:~/workspace/sed$ sed 's/bob/ 宝宝 /' test.txtsponge 宝宝  bob bobsquarepatrickstar 默认 只 替换 第一个 ， 如果 要 替换 匹配 行 中 所有 满足条件 的 字符 ， 需要 加上 g 选项 （global) 修改 匹配 行 中 第 n 个 匹配 的 字符 $ sed 's/bob/ 宝宝 /2' test.txtspongebob  宝宝  bobsquarepatrickstar 替换 了 该行 第 2 个 匹配 的 字符 全局 替换 匹配 的 字符 frost@master:~/workspace/sed$ cat test.txtspongebob bob bobsquarepatrickstarfrost@master:~/workspace/sed$ sed 's/bob/ 宝宝 /g' test.txtsponge 宝宝   宝宝   宝宝 squarepatrickstar 将 修改 后 的 内容 输出 到 文件 $ sed 's/bob/ 宝宝 /gw 2.txt' test.txtsponge 宝宝   宝宝   宝宝 squarepatrickstarfrost@master:~/workspace/sed$ cat 2.txt 宝宝   宝宝   宝宝 将 每行 // 后 的 内容 删除 frost@master:~/workspace/sed$ cat a.php<?php$a = 20; // 这 是 一个 行内 注释 frost@master:~/workspace/sed$ sed 's#//.*##g' a.php<?php$a = 20; 这 是 全文 里 找到 符合条件 的 ， 还 可以 指定 符合 某个 前置条件 的 才 执行 符合 前置条件 的 行 中 ， 将 // 后面 的 内容 删除 frost@master:~/workspace/sed$ cat a.php<?php$a = 20; // 这 是 一个 行内 注释 define('IAMA_CONST', 20); //  这 是 一个 常量 frost@master:~/workspace/sed$ sed '/\\$/s/\\/\\/.*//g' a.php<?php$a = 20;define('IAMA_CONST', 20); //  这 是 一个 常量 这个 例子 把 有 变量 定义 的 行内 注释 给 删除 了 替换 匹配 行 倒数 n 个字符 frost@master:~/workspace/sed$ sed 's/..$//g' a.php<?p$a = 20; // 这 是 一个 行内 注 �define('IAMA_CONST', 20); //  这 是 一个 常 �frost@master:~/workspace/sed$ sed 's/....$//g' a.php<$a = 20; // 这 是 一个 行内 �define('IAMA_CONST', 20); //  这 是 一个 �frost@master:~/workspace/sed$ sed 's/...$//g' a.php<?$a = 20; // 这 是 一个 行内 注 define('IAMA_CONST', 20); //  这 是 一个 常 最终 目的 是 达成 了 ， 但是 要 注意 一个 汉字 其实 是 占 了 3 个字符 。 将 匹配 的 行 替换 为 空行 frost@master:~/workspace/sed$ cat a.php<?php$a = 20; // 这 是 一个 行内 注释 define('IAMA_CONST', 20); //  这 是 一个 常量 这 是 一个 不 符合规范 的 注释 frost@master:~/workspace/sed$ sed 's/^#.*//g' a.php<?php$a = 20; // 这 是 一个 行内 注释 define('IAMA_CONST', 20); //  这 是 一个 常量 frost@master:~/workspace/sed$ sed '/^#/d' a.php<?php$a = 20; // 这 是 一个 行内 注释 define('IAMA_CONST', 20); //  这 是 一个 常量 frost@master:~/workspace/sed 这里 有意 和 前面 讲 过 的 d 命令 做 一个 比较 ， 可以 看到 s 命令 做 的 是 替换 ， 将 这 行 的 字符 替换 为 空 （ 并 没有 替换 换行符 ）， 但 这 行 还 在 ， 但 d 是 删除 整行 。 总结 上面 这些 已经 能 满足 大部分 的 需求 了 ， 后面 遇到 偏门 的 场景 再 补充 。","title":"Sed 简单 用法 ","oriTitle":"Sed简单用法","categories":["in-action"],"date":"2020-08-01T08:38:23.000Z"},{"uri":"/post/setting-mailx-on-linux","tags":["linux","mailx"],"content":" 用 newman 搞了个 自动化 测试 脚本 ， 测试 出错 的 时候 需要 发邮件 提醒 ， 但 之前 尝试 配置 了 sendmail 有 各种 神奇 的 问题 ， 这次 换 了 思路 ， 尝试 用 mailx。 安装 软件包 yum install -y mailx 配置 发件人 信息 安装 完成 后 会 生成 一个 /etc/mail.rc 配置文件 ， 前面 的 那些 都 不用 看 ， 直接 无脑 在 最后 添加 以下内容 set from=\"myname@happyhacker.fun\"set smtp=\"mail.happyhacker.fun\"set smtp-auth-user=\"myname@happyhacker.fun\"set smtp-auth-password=\"this is a strong password\"set smtp-auth=login 测试 几种 不同 方式 不 带 附件 管道 echo \" 这 是 正文 \" | mail -s \" 这 是 标题 \" myname@happyhacker.fun 重定向 mail -s \" 这 是 标题 \" myname@happyhacker.fun < /path/to/a/text/file 这样 会 把 指定 的 文件 中 的 内容 当作 邮件 的 正文 发出 带 附件 mail -a  附件 .docx -s \" 这 是 标题 \" myname@happyhacker.fun < /path/to/a/text/file 这些 就 可以 应付 大部分 场景 了 。","title":" 最 简单 的 命令行 发邮件 方式 ","oriTitle":"最简单的命令行发邮件方式","categories":["in-action"],"date":"2020-07-20T09:10:43.000Z"},{"uri":"/post/spring-tomcat-tutorial","tags":["springboot","tomcat","java","in-action"],"content":" 本文 探讨 了 Springboot 应用 使用 jar 包 和 war 包 的 区别 ， 以及 使用 中 的 一些 思考 。 我 刚 开始 研究 Java， 一些 想法 可能 不 准确 ， 欢迎 提出 宝贵意见 。 在 开发 中 我们 会 使用 嵌入式 的 tomcat 容器 ， 但 实际 项目 部署 中 一般 不会 这么 做 ， 事实证明 大部分 都 是 这么 用 的 ， 独立 的 tomcat 部署 已经 被 淘汰 了 。 下面 在 macOS 环境 下 操作 以下 步骤 ： 由于 实验 用 的 黑 苹果 不 支持 docker， 以下 所有 操作 需要 的 应用 均 使用 macOS 下 的 homebrew 安装 。 创建 一个 简单 的 Springboot Web 应用 使用 Spring Initializr 创建 一个 基础 的 Springboot 应用 ， 只 选择 Web 组件 。 以上 就是 一个 最 简单 的 Springboot 应用 了 。 在 嵌入式 tomcat 容器 中 运行 Web 应用 可以 看到 ， 这个 应用 已经 可以 在 嵌入式 tomcat 容器 中 运行 了 。 注意 ， 这里 访问 的 路径 是 http://localhost:8080/v1/hello/world。 打包 编写 完成 的 war 包 在 Idea 中 执行 mvn pacakge， 然后 在 target 目录 中 检查 生成 的 war 包 。 将 war 包 部署 到 独立 的 tomcat 服务 中 这时候 就 可以 关闭 Idea 中 运行 的 嵌入式 tomcat 容器 了 ， 因为 启动 独立 tomcat 服务 时 默认 端口 也 是 8080， 会 有 冲突 导致 无法 启动 。 可以 执行 brew services start tomcat 来 启动 web 容器 。 这里 为了 观察 服务 的 输出 ， 使用 前台 运行 的 方式 catalina run。 可以 看到 tomcat 服务 已经 成功 启动 ， 并 监听 了 8080 端口 。 访问 独立 tomcat 服务 中 的 应用 将 前面 target 目录 中 的 war 包 部署 到 tomcat 的 webapps 目录 中 。 可以 看到 ， 服务 启动 后 ， 直接 将 war 包 复制到 tomcat 的 工作 目录 中 ， 服务 就 会 检测 到 新 war 包 的 加入 ， 并 自动 运行 相应 的 服务 。 这时 如果 我们 还 像 刚才 那样 访问 http://localhost:8080/v1/hello/world 会 怎样 呢 ？ 可以 看到 ， 是 不 存在 这个 路径 的 。 问题 出 在 哪儿 呢 ？ 我们 看 一下 webapps 目录 下 都 有 哪些 东西 。 可以 看到 ， 我们 是 把 应用 部署 在 了 web 容器 中 ， 但 web 容器 中 却是 有 多个 应用 的 ， 所以 ， 访问 应用 时 需要 带上 应用 的 名字 。 那 名字 是 什么 呢 ？ 当然 就是 spring-in-tomcat-0.0.1-SNAPSHOT， 试一下 果然 可以 了 。 访问 应用 的 不同 版本 刚才 是 应用 从不 存在 到 存在 ，tomcat 可以 自动检测 。 我们 再 测试 一下 是否 可以 检测 文件 的 变更 。 这里 做 了 一个 微小 的 变化 。 复制 完成 之后 tomcat 马上 就 检测 到 了 文件 的 更新 。 可以 看到 ， 应用 更新 也 无感 的 完成 了 。 是否 真的 是 无感 ？ 在 war 包 替换 期间 发生 了 什么 ？ 服务 有没有 中断 呢 ？ 再 做 一个 测试 首先 启动 30 秒 的 并发 请求 ， 然后 将 重新 编辑 并 打包 的 war 包 重新部署 ， 结果 发现 有 大量 的 非 200 的 返回值 。 这 就 证明 了 并 不是 “ 软 重启 ”， 而是 存在 服务 中断 。 那 怎么 证明 不是 wrk 发起 的 请求 太 多 ， 从而 导致 的 服务 繁忙 呢 ？ 在 正常 情况 下 再 跑 一次 测试 就行了 。 所以 ， 重新部署 服务 导致 服务 中断 的 结论 无误 。 从 这个 结论 萌生 了 另外 一个 想法 ， 这个 访问 的 路径 是 带 版本号 的 ， 这里 是 0.0.1-SNAPSHOT， 那 如果 我 直接 加 一个 0.0.2-SNAPSHOT 的 版本 进来 ， 不 就 两个 都 能 访问 了 ？ 然后 配合 Nginx 的 反向 代理 和 负载 均衡 ， 步进式 的 切 流量 ， 也 就 同时 实现 了 灰度 发布 。 在 tomcat 前 部署 nginx 反向 代理 添加 一个 如 图 的 配置文件 ， 这时 就 可以 通过 nginx 访问 spring 的 服务 了 。 不出意外 的话 ， 改变 nginx 的 配置 并 重新 reload nginx 的 过程 ， 服务 是 不会 中断 的 。 多次 实验 结果表明 ， 在 并发 请求 期间 reload nginx 的 server 配置 ， 对 服务 可用性 的 影响 非常 小 。 关于 Nginx 的 负载 均衡 相关 内容 这里 不再 过 多 涉及 。 总结 tomcat 会 自动 加载 新 加入 的 war 包 tomcat 更新 同名 的 新 war 包 时 服务 会 中断 可以 利用 tomcat 可 同时 运行 多个 war 包 的 特性 提供 不同 版本 的 服务 可以 利用 Nginx 反向 代理 实现 服务 不 中断 可以 利用 Nginx 的 负载 均衡 实现 灰度 发布 ","title":"Springboot 使用 内置 和 独立 tomcat 以及 其他 思考 ","oriTitle":"Springboot使用内置和独立tomcat以及其他思考","categories":["tech"],"date":"2020-03-28T04:56:22.000Z"},{"uri":"/post/springboot-profiles-active","tags":["springboot"],"content":"Springboot 的 这个 profiles 的 问题 真是 让 人 头疼 。 这个 问题 在 小 版本 之间 来 瞎 改 ， 又 没有 明确 的 说明 ， 不 知道 浪费 了 多少 人 的 时间 。 首先 明确 一点 ， 通过 export SPRINGPROFILESACTIVE=prod,web 这种 方式 从始至终 都 是 可行 的 。 而 改变 的 是 mvn spring-boot:run -Dspring.profiles.active=prod,web 这种 方式 。 亲 测 在 springboot 2.3.1 已经 完全 不起作用 了 。 所以 保险 的 方法 就是 前面 提到 的 第一种 。 可以 这么 做 export SPRINGPROFILESACTIVE=prod,web && mvn spring-boot:run","title":"Springboot Profiles Active","oriTitle":"Springboot Profiles Active","categories":["in-action"],"date":"2020-10-22T08:32:44.000Z"},{"uri":"/post/sshd-in-macos","tags":["macOS","ssh"],"content":"mac 本身 安装 了 ssh 服务 ， 默认 情况 下 不会 开机 自 启 。 本文 记录 了 开启 和 停止 sshd 服务 的 方法 。1.  启动 sshd 服务 ：sudo launchctl load -w /System/Library/LaunchDaemons/ssh.plist2.  停止 sshd 服务 ：sudo launchctl unload -w /System/Library/LaunchDaemons/ssh.plist3.  查看 是否 启动 ：sudo launchctl list | grep ssh 如果 看到 下面 的 输出 表示 成功 启动 了 ：$ sudo launchctl list | grep ssh0\tcom.openssh.sshd 为什么 需要 开启 macOS 上 的 sshd 服务 呢 ？ 是因为 在 本地 部署 flink 或者 其他 某些 集群 服务 时 ， 默认 是 要 通过 ssh 协议 发送 文件 的 。 对 ， 传输 到 本 机 也 是 用 ssh 服务 ， 所以 如果 没有 开通 服务 就 无法 正确 部署 。","title":"macOS 上 管理 SSH 服务 ","oriTitle":"macOS上管理SSH服务","categories":["in-action"],"date":"2020-03-29T02:57:10.000Z"},{"uri":"/post/turn-off-macos-update-notification","tags":["macOS","tips"],"content":" 作为 黑 苹果 用户 ， 不 知道 直接 更新 系统 会 发生 什么 不可 预知 的 问题 ， 所以 还是 尽量避免 升级 。 设置 方法 1.  在 系统 偏好 设置 中 关闭 自动更新 2.  在 终端 执行 以下 命令 sudo softwareupdate --ignore \"macOS Catalina\"defaults write com.apple.systempreferences AttentionPrefBundleIDs 0killall Dock3.  补充 最近 的 不 知道 哪 次 更新 又 带来 了 一个 问题 ， 执行 上面 的 命令 的 时候 会 报 Password:Ignored updates:()Software Update can only ignore updates that are eligible for installation.If the label provided to ignore is not in the above list, it is not eligibleto be ignored.Ignoring software updates is deprecated.The ability to ignore individual updates will be removed in a future release of macOS. 也就是说 苹果 以后 要 把 这个 选项 去掉 了 ， 可以 参考 一下 这个 文章 Apple’s has brought back the nagging — you can no longer ignore major macOS updates， 看起来 不光 是 我 反感 这个 事儿 ， 全世界 都 觉得 苹果 一点 都 不在乎 用户 的 感受 啊 ， 和 微 信 有点像 。 总结 macOS 和 iPhone 的 升级 速度 快 （ 指 最新 版本 的 更新 率 高 ） 的 原因 就是 这么 不停 提醒 吧 ， 太 讨厌 了 。 这种 方法 亲 测 有效 。","title":" 彻底 关闭 macOS 系统升级 提示 ","oriTitle":"彻底关闭macOS系统升级提示","categories":["in-action"],"date":"2020-06-10T02:52:37.000Z"},{"uri":"/post/update-boot-menu-for-ryzentosh","tags":["ryzentosh"],"content":" 更新 完 黑 苹果 之后 发现 进 BIOS 的 时候 多 了 一个 选项 ， 看起来 很 奇怪 。 其实 是因为 在 安装 Windows 或者 Windows 进行 系统 更新 时 ， 会 覆盖 /EFI/BOOT/BOOTx64.efi 文件 ， 这个 配置 就是 为了 保护 这个 文件 不 被 修改 的 ， 具体 的 原因 我 没有 研究 ， 因为 暂时 还 没有 安装 Windows。（ 其实 是因为 安装 不 上 ， 在 Mac 上 创建 的 WindowsInstaller 总是 无法 启动 ， 不是 刚 需 也 就 没有 再 继续 研究 了 ） 多 了 个 OpenCore， 经过 在 Reddit 上 发帖 求助 ， 发现 原因 可能 是 更新 到 0.5.9 的 时候 复制 了 一个 配置 来  Misc -> Security -> BootProtect， 现在 的 配置 是 Bootstrap， 改成 none 即可 ， 但 如果 安装 了 Windows 系统 ， 每当 windows 系统 更新 时 就 会 破坏 OpenCore 的 启动 顺序 。 所以 这 其实 是 OpenCore 的 保护 机制 ， 也 就 不难理解 它 是 一个 【 启动 安全 】 选项 的 原因 了 。 不过 我 暂时 没有 安装 Windows， 所以 也 用 不到 这个 选项 。 不过 明白 了 ， 也 就 不再 纠结 了 ， 暂时 就 不 改 它 了 ， 免得 将来 装 了 Windows 但 忘 了 这个 事儿 ， 净 是 给 自己 挖坑 。","title":" 黑 苹果 bootmenu","oriTitle":"黑苹果bootmenu","categories":["in-action"],"date":"2020-06-14T07:49:21.000Z"},{"uri":"/post/update-ryzentosh","tags":["ryzentosh"],"content":" 装 黑 苹果 的 时候 是 10.15.3， 后来 经历 了 两次 官方 的 更新 ， 但 我 又 不 太 清楚 需要 的 更新过程 ， 现在 更新 成功 之后 记录 一下 。1.  更新 EFI 下载 最新 的 OpenCorePkg， 参考 这里 把 主要 的 几个 文件 更新 一下 ， 把 EFI 更新 到 系统 硬盘 之后 重启 看看 能 不能 正常 启动 ， 能 正常 启动 后 再 进行 第二步 。 我 首次 安装 的 时候 是 OpenCore0.5.6， 更新 到 0.5.7 的 时候 有 一个 不 兼容 的 配置 ， 如下 图 所示 而 正好 重命名 的 这个 是 必须 项 ， 所以 就 需要 自己 把 FwRuntimeServices.efi 删除 ， 把 新 的 OpenRuntime.efi 放进来 ， 打开 ProperTree， 重新 加载 config.plist2.  更新 macOS 这 就是 上述 这里 没有 说 清楚 的 地方 ， 因为 实在 是 没什么 好 说 的 。 就 按 正常 的 系统 更新 流程 直接 点 更新 即可 ！3.  更新 成功 ","title":" 黑 苹果 更新 升级 ","oriTitle":"黑苹果更新升级","categories":["in-action"],"date":"2020-06-14T02:12:22.000Z"},{"uri":"/post/what-is-jar","tags":["java","jar"],"content":"jar 包 应该 是 java 应用 使用 最 多 的 分发 形式 了 ，jar 包 中 包含 什么 东西 ， 怎么 创建 和 执行 它 呢 ？jar 包 是 什么 Jar 包 全称 Java Archive File， 是 以 zip 格式 打包 的 一个 压缩包 ， 和 普通 的 压缩包 最 本质 的 区别 是 —— 后缀 不 一样 ， 一个 是 .jar， 一个 是 .zip。 但 区分 jar 包 和 其他 zip 包 的 本质区别 是 jar 包 包含 一个 META-INF/MANIFEST.MF 文件 ， 这个 清单 文件 是 包含 了 以下内容 jar 包 的 版本 创建人 Class-Path 类 搜索 路径 Main-Class 属性 （ 表示 Main 方法 的 入口 ） 为什么 要 用 jar 包 通常 我们 写 一个 HelloWord 类 之后 会 做 以下 操作 //  保存 为 HelloWorld.javapublic class HelloWorld {\tpublic static void main(String[] args) {\t\tSystem.out.println(\"Hello World!\");\t}}javac HelloWorld.java #  会 生成 一个 HelloWorld.class 文件 java HelloWorldoutputHello World! 这里 HelloWorld.class 其实 才 是 我们 需要 的 东西 ， 也 就是 Java 所谓 的 “ 字节 码 ”，Java 的 最大 卖点 Write Once, Run Anywhere 的 特点 就 来自 这里 了 。 需要 注意 的 是 ， 所谓 跨平台 ， 并 不是 指 Java（jdk） 本身 跨平台 ， 而是 由 jdk 编译 而 来 的 class 文件 跨平台 。 所以 也 就 需要 针对 不同 平台 的 jdk 了 。 当 我们 的 应用 只有 一个 文件 时 当然 可以 这样 发布 ， 但 这 肯定 是 不 可能 的 。 如果 应用 有 其他 的 依赖 ， 用 这种 原始 的 方式 将 会 很 难 维护 ， 因此 ，jar 包 就 应运而生 了 。 下面 简单 写 一个 带有 依赖 的 例子 ， 入口 类 App， 小狗 类 Dog。package entity;public class Dog {    private String name;    private int age;    public Dog(String name, int age) {        this.name = name;        this.age = age;    }    public String getName() {        return name;    }    public int getAge() {        return age;    }}import entity.Dog;public class App {    public static void main(String[] args) {        Dog aDog = new Dog(\"Bailey\", 11);        System.out.println(\"I am \" + aDog.getName() + \" and I am \" + aDog.getAge() + \" years old\");    }} 目录 结构 如下 ：.├── App.java└── entity    └── Dog.java 如果 没有 jar 包 ， 就 需要 执行 如下 命令 ➜  demo javac App.java entity/Dog.java➜  demo tree.├── App.class├── App.java└── entity    ├── Dog.class    └── Dog.java1 directory, 4 files➜  demo java AppI am Bailey and I am 11 years old 这时候 源码 (.java) 已经 不 需要 了 ， 删 了 它们 一样 可以 运行 。 为了 更 方便 的 分发 ， 可以 把 这些 .class 文件 打包 成 jar 包 ， 并 指定 运行 的 入口 类 ➜  demo jar cvfe App.jar App entity/*.class App.classadded manifestadding: entity/Dog.class(in = 442) (out= 286)(deflated 35%)adding: App.class(in = 784) (out= 476)(deflated 39%)➜  demo jar -tf App.jarMETA-INF/META-INF/MANIFEST.MFentity/Dog.classApp.class 这时候 执行 java -jar App.jar， 输出 如下 ➜  demo java -jar App.jarI am Bailey and I am 11 years old 这时候 把 这个 压缩包 发给 别人 ， 别人 就 可以 直接 这样 执行 了 。 添加 和 修改 清单 属性 如果 第一次 打包 的 时候 没有 添加 MANIFEST 文件 ，jar 会 自动 添加 一个 META-INF/MANIFEST.MF 文件 ， 但 其中 只 包含 Manifest-Version 和 Created-By 两个 属性 ， 在 执行 的 时候 还要 在 命令行 传入 入口 才 可以 执行 。 所以 这时 如果 要 给 MANIFEST 文件 添加 属性 ， 可以 这么 做 。 创建 一个 新 的 清单 文件 ， 比如 MANIFEST-ADDITION.MF 将 需要 添加 的 属性 假如 新 的 清单 文件 执行 jar ufvm App.jar MANIFEST-ADDITION.MFMain-Class: AppAuthor: happyhakcer 然后 通过 vim 打开 这个 jar 包 就 可以 看到 其中 的 清单 文件 已经 更新 了 。 另外 ， 如果 是 打包 前 就 已经 手动 写 好 了 完整 的 清单 文件 ， 也 可以 通过 jar cfvm 的 方式 直接 把 清单 文件 打包 进 jar 包 。 需要 注意 一点 ， 在 执行 jar vcfme 这种 命令 时 ，f m e 这 三个 选项 的 顺序 也 决定 了 后面 传入 的 参数 表示 的 含义 ，f 表示 目标 文件 （jar 包 的 名称 ），m 表示 清单 文件 ，e(entry) 则 表示 入口 点 。 比如 可以 是 jar vcfme app.jar MANIFEST.MF App App.class entity/*.class>  这里 是 为了 说明 问题 ， 如果 MANIFEST.MF 中 已经 指定 了 Main-Class 属性 ， 则 在 执行 上面 的 命令 时会 因为 又 通过 e 选项 指定 了 入口 点 而 执行 失败 。jar 包 的 官方 标准 现在 我们 已经 有 了 一个 标准 的 jar 包 了 ， 下面 打开 它 看看 这个 清单 文件 中 究竟 包含 了 什么 信息 Manifest-Version: 1.0Created-By: 1.8.0_252 (AdoptOpenJDK)Main-Class: App>  由于 entity 目录 位于 App.class 所在 目录 的 子目录 中 ， 所以 无需 指定 Class-Pathjar 包 的 其他 标准 本 节 其实 是 为了 说明 标准 的 jar 包 和 Springboot 打包 的 FAT JAR 的 区别 。 通常 一个 jar 包 只 包含 了 应用 代码 （ 区别 于 依赖 ）， 但 Springboot 的 jar 包 则 动辄 几百 MB， 其实 就是 因为 它 把 所有 的 依赖 全部 都 打 到 jar 包 里 了 。 一个 典型 的 Springboot 应用 的 jar 包 的 清单 文件 内容 如下 可以 看到 ， 下面 有 波浪 线 的 其实 就是 标准 的 清单 文件 中 不 包含 的 部分 。 而 Springboot 能 从 jar 包 启动 ， 核心 就 在于 Main-Class 配置 。 关于 org.springframework.boot.loader.JarLauncher 的 原理 ， 详见 Springboot 启动 jar 包 和 war 包 的 区别 最 本质 的 区别 就是 war 包 是 一个 典型 的 web 包 ， 所谓 典型 也 就是 早年间 把 接口 和 页面 等 其他 静态 资源 打包 到 一起 的 包 ，tomcat 就是 用来 运行 war 包 的 。 由于 现在 war 包 用 的 不 多 了 ， 这里 不再 赘述 。 总结 本文 简单 介绍 了 jar 包 的 结构 和 一些 简单 的 应用 ， 主要 帮助 初学者 理解 一些 概念 。","title":" 聊聊 jar 包 ","oriTitle":"聊聊jar包","categories":["research"],"date":"2020-05-18T14:18:51.000Z"}]